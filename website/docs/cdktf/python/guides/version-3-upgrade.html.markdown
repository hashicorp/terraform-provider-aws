---
subcategory: ""
layout: "aws"
page_title: "Terraform AWS Provider Version 3 Upgrade Guide"
description: |-
  Terraform AWS Provider Version 3 Upgrade Guide
---


<!-- Please do not edit this file, it is generated. -->
# Terraform AWS Provider Version 3 Upgrade Guide

Version 3.0.0 of the AWS provider for Terraform is a major release and includes some changes that you will need to consider when upgrading. This guide is intended to help with that process and focuses only on changes from version 2.X to version 3.0.0. See the [Version 2 Upgrade Guide](/docs/providers/aws/guides/version-2-upgrade.html) for information about upgrading from 1.X to version 2.0.0.

Most of the changes outlined in this guide have been previously marked as deprecated in the Terraform plan/apply output throughout previous provider releases. These changes, such as deprecation notices, can always be found in the [Terraform AWS Provider CHANGELOG](https://github.com/hashicorp/terraform-provider-aws/blob/main/CHANGELOG.md).

~> **NOTE:** Version 3.0.0 and later of the AWS Provider can only be automatically installed on Terraform 0.12 and later.

Upgrade topics:

<!-- TOC depthFrom:2 depthTo:2 -->

- [Provider Version Configuration](#provider-version-configuration)
- [Provider Authentication Updates](#provider-authentication-updates)
- [Provider Custom Service Endpoint Updates](#provider-custom-service-endpoint-updates)
- [Data Source: aws_availability_zones](#data-source-aws_availability_zones)
- [Data Source: aws_lambda_invocation](#data-source-aws_lambda_invocation)
- [Data Source: aws_launch_template](#data-source-aws_launch_template)
- [Data Source: aws_route53_resolver_rule](#data-source-aws_route53_resolver_rule)
- [Data Source: aws_route53_zone](#data-source-aws_route53_zone)
- [Resource: aws_acm_certificate](#resource-aws_acm_certificate)
- [Resource: aws_api_gateway_method_settings](#resource-aws_api_gateway_method_settings)
- [Resource: aws_autoscaling_group](#resource-aws_autoscaling_group)
- [Resource: aws_cloudfront_distribution](#resource-aws_cloudfront_distribution)
- [Resource: aws_cloudwatch_log_group](#resource-aws_cloudwatch_log_group)
- [Resource: aws_codepipeline](#resource-aws_codepipeline)
- [Resource: aws_cognito_user_pool](#resource-aws_cognito_user_pool)
- [Resource: aws_dx_gateway](#resource-aws_dx_gateway)
- [Resource: aws_dx_gateway_association](#resource-aws_dx_gateway_association)
- [Resource: aws_dx_gateway_association_proposal](#resource-aws_dx_gateway_association_proposal)
- [Resource: aws_ebs_volume](#resource-aws_ebs_volume)
- [Resource: aws_elastic_transcoder_preset](#resource-aws_elastic_transcoder_preset)
- [Resource: aws_emr_cluster](#resource-aws_emr_cluster)
- [Resource: aws_glue_job](#resource-aws_glue_job)
- [Resource: aws_iam_access_key](#resource-aws_iam_access_key)
- [Resource: aws_iam_instance_profile](#resource-aws_iam_instance_profile)
- [Resource: aws_iam_server_certificate](#resource-aws_iam_server_certificate)
- [Resource: aws_instance](#resource-aws_instance)
- [Resource: aws_lambda_alias](#resource-aws_lambda_alias)
- [Resource: aws_launch_template](#resource-aws_launch_template)
- [Resource: aws_lb_listener_rule](#resource-aws_lb_listener_rule)
- [Resource: aws_msk_cluster](#resource-aws_msk_cluster)
- [Resource: aws_rds_cluster](#resource-aws_rds_cluster)
- [Resource: aws_route53_resolver_rule](#resource-aws_route53_resolver_rule)
- [Resource: aws_route53_zone](#resource-aws_route53_zone)
- [Resource: aws_s3_bucket](#resource-aws_s3_bucket)
- [Resource: aws_s3_bucket_metric](#resource-aws_s3_bucket_metric)
- [Resource: aws_security_group](#resource-aws_security_group)
- [Resource: aws_sns_platform_application](#resource-aws_sns_platform_application)
- [Resource: aws_spot_fleet_request](#resource-aws_spot_fleet_request)

<!-- /TOC -->

## Provider Version Configuration

-> Before upgrading to version 3.0.0, it is recommended to upgrade to the most recent 2.X version of the provider and ensure that your environment successfully runs [`terraform plan`](https://www.terraform.io/docs/commands/plan.html) without unexpected changes or deprecation notices.

We recommend using [version constraints when configuring Terraform providers](https://www.terraform.io/docs/configuration/providers.html#provider-versions). If you are following that recommendation, update the version constraints in your Terraform configuration and run [`terraform init`](https://www.terraform.io/docs/commands/init.html) to download the new version.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.provider import AwsProvider
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        AwsProvider(self, "aws")
```

Update to latest 3.X version:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.provider import AwsProvider
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        AwsProvider(self, "aws")
```

## Provider Authentication Updates

### Authentication Ordering

Previously, the provider preferred credentials in the following order:

- Static credentials (those defined in the Terraform configuration)
- Environment variables (e.g., `AWS_ACCESS_KEY_ID` or `AWS_PROFILE`)
- Shared credentials file (e.g., `~/.aws/credentials`)
- EC2 Instance Metadata Service
- Default AWS Go SDK handling (shared configuration, CodeBuild/ECS/EKS)

The provider now prefers the following credential ordering:

- Static credentials (those defined in the Terraform configuration)
- Environment variables (e.g., `AWS_ACCESS_KEY_ID` or `AWS_PROFILE`)
- Shared credentials and/or configuration file (e.g., `~/.aws/credentials` and `~/.aws/config`)
- Default AWS Go SDK handling (shared configuration, CodeBuild/ECS/EKS, EC2 Instance Metadata Service)

This means workarounds of disabling the EC2 Instance Metadata Service handling to enable CodeBuild/ECS/EKS credentials or to enable other credential methods such as `credential_process` in the AWS shared configuration are no longer necessary.

### Shared Configuration File Automatically Enabled

The `AWS_SDK_LOAD_CONFIG` environment variable is no longer necessary for the provider to automatically load the AWS shared configuration file (e.g., `~/.aws/config`).

### Removal of AWS_METADATA_TIMEOUT Environment Variable Usage

The provider now relies on the default AWS Go SDK timeouts for interacting with the EC2 Instance Metadata Service.

## Provider Custom Service Endpoint Updates

### Removal of kinesis_analytics and r53 Arguments

The [custom service endpoints](custom-service-endpoints.html) for Kinesis Analytics and Route 53 now use the `kinesisanalytics` and `route53` argument names in the provider configuration.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.provider import AwsProvider
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        AwsProvider(self, "aws",
            endpoints=[AwsProviderEndpoints(
                kinesis_analytics="https://example.com",
                r53="https://example.com"
            )
            ]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.provider import AwsProvider
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        AwsProvider(self, "aws",
            endpoints=[AwsProviderEndpoints(
                kinesisanalytics="https://example.com",
                route53="https://example.com"
            )
            ]
        )
```

## Data Source: aws_availability_zones

### blacklisted_names Attribute Removal

Switch your Terraform configuration to the `exclude_names` attribute instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_availability_zones import DataAwsAvailabilityZones
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsAvailabilityZones(self, "example",
            blacklisted_names=["us-west-2d"]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_availability_zones import DataAwsAvailabilityZones
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsAvailabilityZones(self, "example",
            exclude_names=["us-west-2d"]
        )
```

### blacklisted_zone_ids Attribute Removal

Switch your Terraform configuration to the `exclude_zone_ids` attribute instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_availability_zones import DataAwsAvailabilityZones
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsAvailabilityZones(self, "example",
            blacklisted_zone_ids=["usw2-az4"]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_availability_zones import DataAwsAvailabilityZones
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsAvailabilityZones(self, "example",
            exclude_zone_ids=["usw2-az4"]
        )
```

## Data Source: aws_lambda_invocation

### result_map Attribute Removal

Switch your Terraform configuration to the `result` attribute with the [`jsondecode()` function](https://www.terraform.io/docs/configuration/functions/jsondecode.html) instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformOutput, Fn, TerraformStack
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        TerraformOutput(self, "lambda_result",
            value=Fn.lookup_nested(example.result_map, ["\"key1\""])
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformOutput, Fn, Token, TerraformStack
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        TerraformOutput(self, "lambda_result",
            value=Fn.lookup_nested(Fn.jsondecode(Token.as_string(example.result)), ["\"key1\""
            ])
        )
```

## Data Source: aws_launch_template

### Error raised if no matching launch template is found

Previously, when a launch template matching the criteria was not found the data source would have been `null`.
Now this could produce errors similar to the below:

```
data.aws_launch_template.current: Refreshing state...

Error: error reading launch template: empty output
```

Configuration that depend on the previous behavior will need to be updated.

## Data Source: aws_route53_resolver_rule

### Removal of trailing period in domain_name argument

Previously the data-source returned the Resolver Rule Domain Name directly from the API, which included a `.` suffix. This proves difficult when many other AWS services do not accept this trailing period (e.g., ACM Certificate). This period is now automatically removed. For example, when the attribute would previously return a Resolver Rule Domain Name such as `example.com.`, the attribute now will be returned as `example.com`.
While the returned value will omit the trailing period, use of configurations with trailing periods will not be interrupted.

## Data Source: aws_route53_zone

### Removal of trailing period in name argument

Previously the data-source returned the Hosted Zone Domain Name directly from the API, which included a `.` suffix. This proves difficult when many other AWS services do not accept this trailing period (e.g., ACM Certificate). This period is now automatically removed. For example, when the attribute would previously return a Hosted Zone Domain Name such as `example.com.`, the attribute now will be returned as `example.com`.
While the returned value will omit the trailing period, use of configurations with trailing periods will not be interrupted.

## Resource: aws_acm_certificate

### domain_validation_options Changed from List to Set

Previously, the `domain_validation_options` attribute was a list type and completely unknown until after an initial `terraform apply`. This generally required complicated configuration workarounds to properly create DNS validation records since referencing this attribute directly could produce errors similar to the below:

```
Error: Invalid for_each argument

  on main.tf line 16, in resource "aws_route53_record" "existing":
  16:   for_each = aws_acm_certificate.existing.domain_validation_options

The `for_each` value depends on resource attributes that cannot be determined
until apply, so Terraform cannot predict how many instances will be created.
To work around this, use the -target argument to first apply only the
resources that the for_each depends on.
```

The `domain_validation_options` attribute is now a set type and the resource will attempt to populate the information necessary during the planning phase to handle the above situation in most environments without workarounds. This change also prevents Terraform from showing unexpected differences if the API returns the results in varying order.

Configuration references to this attribute will likely require updates since sets cannot be indexed (e.g., `domain_validation_options[0]` or the older `domain_validation_options.0.` syntax will return errors).
If the `domain_validation_options` list previously contained only a single element like the two examples just shown,
it may be possible to wrap these references using the [`tolist()` function](https://www.terraform.io/docs/configuration/functions/tolist.html)
<!-- markdownlint-disable-next-line no-reversed-links -->
(e.g., `tolist(aws_acm_certificate.example.domain_validation_options)[0]`) as a quick configuration update.
However given the complexity and workarounds required with the previous `domain_validation_options` attribute implementation,
different environments will require different configuration updates and migration steps.
Below is a more advanced example.
Further questions on potential update steps can be submitted to the [community forums](https://discuss.hashicorp.com/c/terraform-providers/tf-aws/33).

For example, given this previous configuration using a `count` based resource approach that may have been used in certain environments:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Op, Token, TerraformCount, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.acm_certificate import AcmCertificate
from imports.aws.acm_certificate_validation import AcmCertificateValidation
from imports.aws.data_aws_route53_zone import DataAwsRoute53Zone
from imports.aws.route53_record import Route53Record
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        existing = AcmCertificate(self, "existing",
            domain_name="existing.${" + public_root_domain.value + "}",
            subject_alternative_names=["existing1.${" + public_root_domain.value + "}", "existing2.${" + public_root_domain.value + "}", "existing3.${" + public_root_domain.value + "}"
            ],
            validation_method="DNS"
        )
        data_aws_route53_zone_public_root_domain = DataAwsRoute53Zone(self, "public_root_domain",
            name=public_root_domain.string_value
        )
        # In most cases loops should be handled in the programming language context and
        #     not inside of the Terraform context. If you are looping over something external, e.g. a variable or a file input
        #     you should consider using a for loop. If you are looping over something only known to Terraform, e.g. a result of a data source
        #     you need to keep this like it is.
        existing_count = TerraformCount.of(
            Token.as_number(Op.add(Fn.length_of(existing.subject_alternative_names), 1)))
        aws_route53_record_existing = Route53Record(self, "existing_2",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing.domain_validation_options, [existing_count.index
                    ]), ["resource_record_name"])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(
                        Fn.lookup_nested(existing.domain_validation_options, [existing_count.index
                        ]), ["resource_record_value"]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing.domain_validation_options, [existing_count.index
                    ]), ["resource_record_type"])),
            zone_id=Token.as_string(data_aws_route53_zone_public_root_domain.zone_id),
            count=existing_count
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_route53_record_existing.override_logical_id("existing")
        aws_acm_certificate_validation_existing = AcmCertificateValidation(self, "existing_3",
            certificate_arn=existing.arn,
            validation_record_fqdns=Token.as_list(
                Fn.lookup_nested(aws_route53_record_existing, ["*", "fqdn"]))
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing.override_logical_id("existing")
```

It will receive errors like the below after upgrading:

```
Error: Invalid index

  on main.tf line 14, in resource "aws_route53_record" "existing":
  14:   name    = aws_acm_certificate.existing.domain_validation_options[count.index].resource_record_name
    |----------------
    | aws_acm_certificate.existing.domain_validation_options is set of object with 4 elements
    | count.index is 1

This value does not have any indices.
```

Since the `domain_validation_options` attribute changed from a list to a set and sets cannot be indexed in Terraform, the recommendation is to update the configuration to use the more stable [resource `for_each` support](https://www.terraform.io/docs/configuration/meta-arguments/for_each.html) instead of [`count`](https://www.terraform.io/docs/configuration/meta-arguments/count.html). Note the slight change in the `validation_record_fqdns` syntax as well.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformIterator, Fn, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.acm_certificate_validation import AcmCertificateValidation
from imports.aws.route53_record import Route53Record
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # In most cases loops should be handled in the programming language context and
        #     not inside of the Terraform context. If you are looping over something external, e.g. a variable or a file input
        #     you should consider using a for loop. If you are looping over something only known to Terraform, e.g. a result of a data source
        #     you need to keep this like it is.
        existing_for_each_iterator = TerraformIterator.from_list(
            Token.as_any("${{ for dvo in ${" + aws_acm_certificate_existing.domain_validation_options + "} : dvo.domain_name => {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }}}"))
        existing = Route53Record(self, "existing",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(existing_for_each_iterator.value, ["name"])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(existing_for_each_iterator.value, ["record"]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(existing_for_each_iterator.value, ["type"])),
            zone_id=Token.as_string(public_root_domain.zone_id),
            for_each=existing_for_each_iterator
        )
        aws_acm_certificate_validation_existing = AcmCertificateValidation(self, "existing_1",
            certificate_arn=Token.as_string(aws_acm_certificate_existing.arn),
            validation_record_fqdns=Token.as_list("${[ for record in ${" + existing.fqn + "} : record.fqdn]}")
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing.override_logical_id("existing")
```

After the configuration has been updated, a plan should no longer error and may look like the following:

```
------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
  - destroy
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # aws_acm_certificate_validation.existing must be replaced
-/+ resource "aws_acm_certificate_validation" "existing" {
        certificate_arn         = "arn:aws:acm:us-east-2:123456789012:certificate/ccbc58e8-061d-4443-9035-d3af0512e863"
      ~ id                      = "2020-07-16 00:01:19 +0000 UTC" -> (known after apply)
      ~ validation_record_fqdns = [
          - "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com",
          - "_812ddf11b781af1eec1643ec58f102d2.existing.example.com",
          - "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com",
          - "_d7112da809a40e848207c04399babcec.existing1.example.com",
        ] -> (known after apply) # forces replacement
    }

  # aws_route53_record.existing will be destroyed
  - resource "aws_route53_record" "existing" {
      - fqdn    = "_812ddf11b781af1eec1643ec58f102d2.existing.example.com" -> null
      - id      = "Z123456789012__812ddf11b781af1eec1643ec58f102d2.existing.example.com._CNAME" -> null
      - name    = "_812ddf11b781af1eec1643ec58f102d2.existing.example.com" -> null
      - records = [
          - "_bdeba72164eec216c55a32374bcceafd.jfrzftwwjs.acm-validations.aws.",
        ] -> null
      - ttl     = 60 -> null
      - type    = "CNAME" -> null
      - zone_id = "Z123456789012" -> null
    }

  # aws_route53_record.existing[1] will be destroyed
  - resource "aws_route53_record" "existing" {
      - fqdn    = "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com" -> null
      - id      = "Z123456789012__40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com._CNAME" -> null
      - name    = "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com" -> null
      - records = [
          - "_638532db1fa6a1b71aaf063c8ea29d52.jfrzftwwjs.acm-validations.aws.",
        ] -> null
      - ttl     = 60 -> null
      - type    = "CNAME" -> null
      - zone_id = "Z123456789012" -> null
    }

  # aws_route53_record.existing[2] will be destroyed
  - resource "aws_route53_record" "existing" {
      - fqdn    = "_d7112da809a40e848207c04399babcec.existing1.example.com" -> null
      - id      = "Z123456789012__d7112da809a40e848207c04399babcec.existing1.example.com._CNAME" -> null
      - name    = "_d7112da809a40e848207c04399babcec.existing1.example.com" -> null
      - records = [
          - "_6e1da5574ab46a6c782ed73438274181.jfrzftwwjs.acm-validations.aws.",
        ] -> null
      - ttl     = 60 -> null
      - type    = "CNAME" -> null
      - zone_id = "Z123456789012" -> null
    }

  # aws_route53_record.existing[3] will be destroyed
  - resource "aws_route53_record" "existing" {
      - fqdn    = "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com" -> null
      - id      = "Z123456789012__8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com._CNAME" -> null
      - name    = "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com" -> null
      - records = [
          - "_a419f8410d2e0720528a96c3506f3841.jfrzftwwjs.acm-validations.aws.",
        ] -> null
      - ttl     = 60 -> null
      - type    = "CNAME" -> null
      - zone_id = "Z123456789012" -> null
    }

  # aws_route53_record.existing["existing.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_812ddf11b781af1eec1643ec58f102d2.existing.example.com"
      + records         = [
          + "_bdeba72164eec216c55a32374bcceafd.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing1.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_d7112da809a40e848207c04399babcec.existing1.example.com"
      + records         = [
          + "_6e1da5574ab46a6c782ed73438274181.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing2.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com"
      + records         = [
          + "_638532db1fa6a1b71aaf063c8ea29d52.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing3.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com"
      + records         = [
          + "_a419f8410d2e0720528a96c3506f3841.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

Plan: 5 to add, 0 to change, 5 to destroy.
```

Due to the type of configuration change, Terraform does not know that the previous `aws_route53_record` resources (indexed by number in the existing state) and the new resources (indexed by domain names in the updated configuration) are equivalent. Typically in this situation, the [`terraform state mv` command](https://www.terraform.io/docs/commands/state/mv.html) can be used to reduce the plan to show no changes. This is done by associating the count index (e.g., `[1]`) with the equivalent domain name index (e.g., `["existing2.example.com"]`), making one of the four commands to fix the above example: `terraform state mv 'aws_route53_record.existing[1]' 'aws_route53_record.existing["existing2.example.com"]'`. We recommend using this `terraform state mv` update process where possible to reduce chances of unexpected behaviors or changes in an environment.

If using `terraform state mv` to reduce the plan to show no changes, no additional steps are required.

In larger or more complex environments though, this process can be tedius to match the old resource address to the new resource address and run all the necessary `terraform state mv` commands. Instead, since the `aws_route53_record` resource implements the `allow_overwrite = true` argument, it is possible to just remove the old `aws_route53_record` resources from the Terraform state using the [`terraform state rm` command](https://www.terraform.io/docs/commands/state/rm.html). In this case, Terraform will leave the existing records in Route 53 and plan to just overwrite the existing validation records with the same exact (previous) values.

-> This guide is showing the simpler `terraform state rm` option below as a potential shortcut in this specific situation, however in most other cases `terraform state mv` is required to change from `count` based resources to `for_each` based resources and properly match the existing Terraform state to the updated Terraform configuration.

```console
$ terraform state rm aws_route53_record.existing
Removed aws_route53_record.existing[0]
Removed aws_route53_record.existing[1]
Removed aws_route53_record.existing[2]
Removed aws_route53_record.existing[3]
Successfully removed 4 resource instance(s).
```

Now the Terraform plan will show only the additions of new Route 53 records (which are exactly the same as before the upgrade) and the proposed recreation of the `aws_acm_certificate_validation` resource. The `aws_acm_certificate_validation` resource recreation will have no effect as the certificate is already validated and issued.

```
An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
-/+ destroy and then create replacement

Terraform will perform the following actions:

  # aws_acm_certificate_validation.existing must be replaced
-/+ resource "aws_acm_certificate_validation" "existing" {
        certificate_arn         = "arn:aws:acm:us-east-2:123456789012:certificate/ccbc58e8-061d-4443-9035-d3af0512e863"
      ~ id                      = "2020-07-16 00:01:19 +0000 UTC" -> (known after apply)
      ~ validation_record_fqdns = [
          - "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com",
          - "_812ddf11b781af1eec1643ec58f102d2.existing.example.com",
          - "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com",
          - "_d7112da809a40e848207c04399babcec.existing1.example.com",
        ] -> (known after apply) # forces replacement
    }

  # aws_route53_record.existing["existing.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_812ddf11b781af1eec1643ec58f102d2.existing.example.com"
      + records         = [
          + "_bdeba72164eec216c55a32374bcceafd.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing1.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_d7112da809a40e848207c04399babcec.existing1.example.com"
      + records         = [
          + "_6e1da5574ab46a6c782ed73438274181.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing2.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_40b71647a8d88eb82d53fe988e8a3cc1.existing2.example.com"
      + records         = [
          + "_638532db1fa6a1b71aaf063c8ea29d52.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

  # aws_route53_record.existing["existing3.example.com"] will be created
  + resource "aws_route53_record" "existing" {
      + allow_overwrite = true
      + fqdn            = (known after apply)
      + id              = (known after apply)
      + name            = "_8dc56b6e35f699b8754afcdd79e9748d.existing3.example.com"
      + records         = [
          + "_a419f8410d2e0720528a96c3506f3841.jfrzftwwjs.acm-validations.aws.",
        ]
      + ttl             = 60
      + type            = "CNAME"
      + zone_id         = "Z123456789012"
    }

Plan: 5 to add, 0 to change, 1 to destroy.
```

Once applied, no differences should be shown and no additional steps should be necessary.

Alternatively, if you are referencing a subset of `domain_validation_options`, there is another method of upgrading from v2 to v3 without having to move state. Given the scenario below...

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.acm_certificate import AcmCertificate
from imports.aws.acm_certificate_validation import AcmCertificateValidation
from imports.aws.data_aws_route53_zone import DataAwsRoute53Zone
from imports.aws.route53_record import Route53Record
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        existing = AcmCertificate(self, "existing",
            domain_name="existing.${" + public_root_domain.value + "}",
            subject_alternative_names=["existing1.${" + public_root_domain.value + "}", "existing2.${" + public_root_domain.value + "}", "existing3.${" + public_root_domain.value + "}"
            ],
            validation_method="DNS"
        )
        data_aws_route53_zone_public_root_domain = DataAwsRoute53Zone(self, "public_root_domain",
            name=public_root_domain.string_value
        )
        existing1 = Route53Record(self, "existing_1",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(existing.domain_validation_options, ["0", "resource_record_name"
                ])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(existing.domain_validation_options, ["0", "resource_record_value"
                    ]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(existing.domain_validation_options, ["0", "resource_record_type"
                ])),
            zone_id=Token.as_string(data_aws_route53_zone_public_root_domain.zone_id)
        )
        existing3 = Route53Record(self, "existing_3",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(existing.domain_validation_options, ["2", "resource_record_name"
                ])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(existing.domain_validation_options, ["2", "resource_record_value"
                    ]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(existing.domain_validation_options, ["2", "resource_record_type"
                ])),
            zone_id=Token.as_string(data_aws_route53_zone_public_root_domain.zone_id)
        )
        aws_acm_certificate_validation_existing1 = AcmCertificateValidation(self, "existing_1_4",
            certificate_arn=existing.arn,
            validation_record_fqdns=Token.as_list(existing1.fqdn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing1.override_logical_id("existing_1")
        aws_acm_certificate_validation_existing3 = AcmCertificateValidation(self, "existing_3_5",
            certificate_arn=existing.arn,
            validation_record_fqdns=Token.as_list(existing3.fqdn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing3.override_logical_id("existing_3")
```

You can perform a conversion of the new `domain_validation_options` object into a map, to allow you to perform a lookup by the domain name in place of an index number.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.acm_certificate_validation import AcmCertificateValidation
from imports.aws.route53_record import Route53Record
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        existing_domain_validation_options = "${{ for dvo in ${" + cloudfront_cert.domain_validation_options + "} : dvo.domain_name => {\n      name   = dvo.resource_record_name\n      record = dvo.resource_record_value\n      type   = dvo.resource_record_type\n    }}}"
        existing1 = Route53Record(self, "existing_1",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing_domain_validation_options, ["existing1.${" + public_root_domain.value + "}"
                    ]), ["name"])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(
                        Fn.lookup_nested(existing_domain_validation_options, ["existing1.${" + public_root_domain.value + "}"
                        ]), ["record"]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing_domain_validation_options, ["existing1.${" + public_root_domain.value + "}"
                    ]), ["type"])),
            zone_id=Token.as_string(data_aws_route53_zone_public_root_domain.zone_id)
        )
        existing3 = Route53Record(self, "existing_3",
            allow_overwrite=True,
            name=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing_domain_validation_options, ["existing3.${" + public_root_domain.value + "}"
                    ]), ["name"])),
            records=[
                Token.as_string(
                    Fn.lookup_nested(
                        Fn.lookup_nested(existing_domain_validation_options, ["existing3.${" + public_root_domain.value + "}"
                        ]), ["record"]))
            ],
            ttl=60,
            type=Token.as_string(
                Fn.lookup_nested(
                    Fn.lookup_nested(existing_domain_validation_options, ["existing3.${" + public_root_domain.value + "}"
                    ]), ["type"])),
            zone_id=Token.as_string(data_aws_route53_zone_public_root_domain.zone_id)
        )
        aws_acm_certificate_validation_existing1 = AcmCertificateValidation(self, "existing_1_2",
            certificate_arn=existing.arn,
            validation_record_fqdns=Token.as_list(existing1.fqdn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing1.override_logical_id("existing_1")
        aws_acm_certificate_validation_existing3 = AcmCertificateValidation(self, "existing_3_3",
            certificate_arn=existing.arn,
            validation_record_fqdns=Token.as_list(existing3.fqdn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_acm_certificate_validation_existing3.override_logical_id("existing_3")
```

Performing a plan against these resources will not cause any change in state, since underlying resources have not changed.

### subject_alternative_names Changed from List to Set

Previously the `subject_alternative_names` argument was stored in the Terraform state as an ordered list while the API returned information in an unordered manner. The attribute is now configured as a set instead of a list. Certain Terraform configuration language features distinguish between these two attribute types such as not being able to index a set (e.g., `aws_acm_certificate.example.subject_alternative_names[0]` is no longer a valid reference). Depending on the implementation details of a particular configuration using `subject_alternative_names` as a reference, possible solutions include changing references to using `for`/`for_each` or using the `tolist()` function as a temporary workaround to keep the previous behavior until an appropriate configuration (properly using the unordered set) can be determined. Usage questions can be submitted to the [community forums](https://discuss.hashicorp.com/c/terraform-providers/tf-aws/33).

### certificate_body, certificate_chain, and private_key Arguments No Longer Stored as Hash

Previously when the `certificate_body`, `certificate_chain`, and `private_key` arguments were stored in state, they were stored as a hash of the actual value. This prevented Terraform from properly updating the resource when necessary and the hashing has been removed. The Terraform AWS Provider will show an update to these arguments on the first apply after upgrading to version 3.0.0, which is fixing the Terraform state to remove the hash. Since the `private_key` attribute is marked as sensitive, the values in the update will not be visible in the Terraform output. If the non-hashed values have not changed, then no update is occurring other than the Terraform state update. If these arguments are the only updates and they all match the hash removal, the apply will occur without submitting API calls.

## Resource: aws_api_gateway_method_settings

### throttling_burst_limit and throttling_rate_limit Arguments Now Default to -1

Previously when the `throttling_burst_limit` or `throttling_rate_limit` argument was not configured, the resource would enable throttling and set the limit value to the AWS API Gateway default. In addition, as these arguments were marked as `Computed`, Terraform ignored any subsequent changes made to these arguments in the resource. These behaviors have been removed and, by default, the `throttling_burst_limit` and `throttling_rate_limit` arguments will be disabled in the resource with a value of `-1`.

## Resource: aws_autoscaling_group

### availability_zones and vpc_zone_identifier Arguments Now Report Plan-Time Conflict

Specifying both the `availability_zones` and `vpc_zone_identifier` arguments previously led to confusing behavior and errors. Now this issue is reported at plan-time. Use the `null` value instead of `[]` (empty list) in conditionals to ensure this validation does not unexpectedly trigger.

### Drift detection enabled for `load_balancers` and `target_group_arns` arguments

If you previously set one of these arguments to an empty list to enable drift detection (e.g., when migrating an ASG from ELB to ALB), this can be updated as follows.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.autoscaling_group import AutoscalingGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, maxSize, minSize):
        super().__init__(scope, name)
        AutoscalingGroup(self, "example",
            load_balancers=[],
            target_group_arns=[Token.as_string(aws_lb_target_group_example.arn)],
            max_size=max_size,
            min_size=min_size
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.autoscaling_group import AutoscalingGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, maxSize, minSize):
        super().__init__(scope, name)
        AutoscalingGroup(self, "example",
            target_group_arns=[Token.as_string(aws_lb_target_group_example.arn)],
            max_size=max_size,
            min_size=min_size
        )
```

If `aws_autoscaling_attachment` resources reference your ASG configurations, you will need to add the [`lifecycle` configuration block](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html) with an `ignore_changes` argument to prevent Terraform non-empty plans (i.e., forcing resource update) during the next state refresh.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.autoscaling_attachment import AutoscalingAttachment
from imports.aws.autoscaling_group import AutoscalingGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, maxSize, minSize):
        super().__init__(scope, name)
        example = AutoscalingGroup(self, "example",
            max_size=max_size,
            min_size=min_size
        )
        aws_autoscaling_attachment_example = AutoscalingAttachment(self, "example_1",
            autoscaling_group_name=example.id,
            elb=Token.as_string(aws_elb_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_autoscaling_attachment_example.override_logical_id("example")
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from cdktf import TerraformResourceLifecycle
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.autoscaling_attachment import AutoscalingAttachment
from imports.aws.autoscaling_group import AutoscalingGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, maxSize, minSize):
        super().__init__(scope, name)
        example = AutoscalingGroup(self, "example",
            lifecycle=TerraformResourceLifecycle(
                ignore_changes=[load_balancers, target_group_arns]
            ),
            max_size=max_size,
            min_size=min_size
        )
        aws_autoscaling_attachment_example = AutoscalingAttachment(self, "example_1",
            autoscaling_group_name=example.id,
            elb=Token.as_string(aws_elb_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_autoscaling_attachment_example.override_logical_id("example")
```

## Resource: aws_cloudfront_distribution

### active_trusted_signers Attribute Name and Type Change

Previously, the `active_trusted_signers` computed attribute was implemented with a Map that did not support accessing its computed `items` attribute in Terraform 0.12 correctly.
To address this, the `active_trusted_signers` attribute has been renamed to `trusted_signers` and is now implemented as a List with a computed `items` List attribute and computed `enabled` boolean attribute.
The nested `items` attribute includes computed `aws_account_number` and `key_pair_ids` sub-fields, with the latter implemented as a List.
Thus, user configurations referencing the `active_trusted_signers` attribute and its sub-fields will need to be changed as follows.

Given these previous references:

```
aws_cloudfront_distribution.example.active_trusted_signers.enabled
aws_cloudfront_distribution.example.active_trusted_signers.items
```

Updated references:

```
aws_cloudfront_distribution.example.trusted_signers[0].enabled
aws_cloudfront_distribution.example.trusted_signers[0].items
```

## Resource: aws_cloudwatch_log_group

### Removal of arn Wildcard Suffix

Previously, the resource returned the ARN directly from the API, which included a `:*` suffix to denote all CloudWatch Log Streams under the CloudWatch Log Group. Most other AWS resources that return ARNs and many other AWS services do not use the `:*` suffix. The suffix is now automatically removed. For example, the resource previously returned an ARN such as `arn:aws:logs:us-east-1:123456789012:log-group:/example:*` but will now return `arn:aws:logs:us-east-1:123456789012:log-group:/example`.

Workarounds, such as using `replace()` as shown below, should be removed:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.datasync_task import DatasyncTask
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, destinationLocationArn, sourceLocationArn):
        super().__init__(scope, name)
        example = CloudwatchLogGroup(self, "example",
            name="example"
        )
        aws_datasync_task_example = DatasyncTask(self, "example_1",
            cloudwatch_log_group_arn=Token.as_string(Fn.replace(example.arn, ":*", "")),
            destination_location_arn=destination_location_arn,
            source_location_arn=source_location_arn
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_datasync_task_example.override_logical_id("example")
```

Removing the `:*` suffix is a breaking change for some configurations. Fix these configurations using string interpolations as demonstrated below. For example, this configuration is now broken:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsIamPolicyDocument(self, "ad-log-policy",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["logs:CreateLogStream", "logs:PutLogEvents"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["ds.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=[example.arn]
            )
            ]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DataAwsIamPolicyDocument(self, "ad-log-policy",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["logs:CreateLogStream", "logs:PutLogEvents"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["ds.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=["${" + example.arn + "}:*"]
            )
            ]
        )
```

## Resource: aws_codepipeline

### GITHUB_TOKEN environment variable removal

Switch your Terraform configuration to the `OAuthToken` element in the `action` `configuration` map instead.

For example, given this previous configuration:

```console
$ GITHUB_TOKEN=<token> terraform apply
```

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.codepipeline import Codepipeline
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, artifactStore, name, roleArn):
        super().__init__(scope, name)
        Codepipeline(self, "example",
            stage=[CodepipelineStage(
                action=[CodepipelineStageAction(
                    category="Source",
                    configuration={
                        "Branch": "main",
                        "Owner": "lifesum-terraform",
                        "Repo": "example"
                    },
                    name="Source",
                    output_artifacts=["example"],
                    owner="ThirdParty",
                    provider="GitHub",
                    version="1"
                )
                ],
                name="Source"
            )
            ],
            artifact_store=artifact_store,
            name=name,
            role_arn=role_arn
        )
```

The configuration could be updated as follows:

```console
$ TF_VAR_github_token=<token> terraform apply
```

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformVariable, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.codepipeline import Codepipeline
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, artifactStore, name, roleArn):
        super().__init__(scope, name)
        # Terraform Variables are not always the best fit for getting inputs in the context of Terraform CDK.
        #     You can read more about this at https://cdk.tf/variables
        github_token = TerraformVariable(self, "github_token")
        Codepipeline(self, "example",
            stage=[CodepipelineStage(
                action=[CodepipelineStageAction(
                    category="Source",
                    configuration={
                        "Branch": "main",
                        "OAuthToken": github_token.string_value,
                        "Owner": "lifesum-terraform",
                        "Repo": "example"
                    },
                    name="Source",
                    output_artifacts=["example"],
                    owner="ThirdParty",
                    provider="GitHub",
                    version="1"
                )
                ],
                name="Source"
            )
            ],
            artifact_store=artifact_store,
            name=name,
            role_arn=role_arn
        )
```

## Resource: aws_cognito_user_pool

### Removal of admin_create_user_config.unused_account_validity_days Argument

The Cognito API previously deprecated the `admin_create_user_config` configuration block `unused_account_validity_days` argument in preference of the `password_policy` configuration block `temporary_password_validity_days` argument. Configurations will need to be updated to use the API supported configuration.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cognito_user_pool import CognitoUserPool
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name):
        super().__init__(scope, name)
        CognitoUserPool(self, "example",
            admin_create_user_config=CognitoUserPoolAdminCreateUserConfig(
                unused_account_validity_days=7
            ),
            name=name
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cognito_user_pool import CognitoUserPool
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name):
        super().__init__(scope, name)
        CognitoUserPool(self, "example",
            password_policy=CognitoUserPoolPasswordPolicy(
                temporary_password_validity_days=7
            ),
            name=name
        )
```

## Resource: aws_dx_gateway

### Removal of Automatic aws_dx_gateway_association Import

Previously when importing the `aws_dx_gateway` resource with the [`terraform import` command](https://www.terraform.io/docs/commands/import.html), the Terraform AWS Provider would automatically attempt to import an associated `aws_dx_gateway_association` resource(s) as well. This automatic resource import has been removed. Use the [`aws_dx_gateway_association` resource import](/docs/providers/aws/r/dx_gateway_association.html#import) to import those resources separately.

## Resource: aws_dx_gateway_association

### vpn_gateway_id Argument Removal

Switch your Terraform configuration to the `associated_gateway_id` argument instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.dx_gateway_association import DxGatewayAssociation
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, dxGatewayId):
        super().__init__(scope, name)
        DxGatewayAssociation(self, "example",
            vpn_gateway_id=Token.as_string(aws_vpn_gateway_example.id),
            dx_gateway_id=dx_gateway_id
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.dx_gateway_association import DxGatewayAssociation
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, dxGatewayId):
        super().__init__(scope, name)
        DxGatewayAssociation(self, "example",
            associated_gateway_id=Token.as_string(aws_vpn_gateway_example.id),
            dx_gateway_id=dx_gateway_id
        )
```

## Resource: aws_dx_gateway_association_proposal

### vpn_gateway_id Argument Removal

Switch your Terraform configuration to the `associated_gateway_id` argument instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.dx_gateway_association_proposal import DxGatewayAssociationProposal
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, associatedGatewayId, dxGatewayId, dxGatewayOwnerAccountId):
        super().__init__(scope, name)
        DxGatewayAssociationProposal(self, "example",
            vpn_gateway_id=aws_vpn_gateway_example.id,
            associated_gateway_id=associated_gateway_id,
            dx_gateway_id=dx_gateway_id,
            dx_gateway_owner_account_id=dx_gateway_owner_account_id
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.dx_gateway_association_proposal import DxGatewayAssociationProposal
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, dxGatewayId, dxGatewayOwnerAccountId):
        super().__init__(scope, name)
        DxGatewayAssociationProposal(self, "example",
            associated_gateway_id=Token.as_string(aws_vpn_gateway_example.id),
            dx_gateway_id=dx_gateway_id,
            dx_gateway_owner_account_id=dx_gateway_owner_account_id
        )
```

## Resource: aws_ebs_volume

### iops Argument Apply-Time Validation

Previously when the `iops` argument was configured with a `type` other than `io1` (either explicitly or omitted, indicating the default type `gp2`), the Terraform AWS Provider would automatically disregard the value provided to `iops` as it is only configurable for the `io1` volume type per the AWS EC2 API. This behavior has changed such that the Terraform AWS Provider will instead return an error at apply time indicating an `iops` value is invalid for types other than `io1`.
Exceptions to this are in cases where `iops` is set to `null` or `0` such that the Terraform AWS Provider will continue to accept the value regardless of `type`.

## Resource: aws_elastic_transcoder_preset

### video Configuration Block max_frame_rate Argument No Longer Uses 30 Default

Previously when the `max_frame_rate` argument was not configured, the resource would default to 30. This behavior has been removed and allows for auto frame rate presets to automatically set the appropriate value.

## Resource: aws_emr_cluster

### core_instance_count Argument Removal

Switch your Terraform configuration to the `core_instance_group` configuration block instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            core_instance_count=2,
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, instanceType, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            core_instance_group=EmrClusterCoreInstanceGroup(
                instance_count=2,
                instance_type=instance_type
            ),
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

### core_instance_type Argument Removal

Switch your Terraform configuration to the `core_instance_group` configuration block instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            core_instance_type="m4.large",
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            core_instance_group=EmrClusterCoreInstanceGroup(
                instance_type="m4.large"
            ),
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

### instance_group Configuration Block Removal

Switch your Terraform configuration to the `master_instance_group` and `core_instance_group` configuration blocks instead. For any task instance groups, use the `aws_emr_instance_group` resource.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            instance_group=[{
                "instance_role": "MASTER",
                "instance_type": "m4.large"
            }, {
                "instance_count": 1,
                "instance_role": "CORE",
                "instance_type": "c4.large"
            }, {
                "instance_count": 2,
                "instance_role": "TASK",
                "instance_type": "c4.xlarge"
            }
            ],
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
from imports.aws.emr_instance_group import EmrInstanceGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        example = EmrCluster(self, "example",
            core_instance_group=EmrClusterCoreInstanceGroup(
                instance_count=1,
                instance_type="c4.large"
            ),
            master_instance_group=EmrClusterMasterInstanceGroup(
                instance_type="m4.large"
            ),
            name=name,
            release_label=release_label,
            service_role=service_role
        )
        aws_emr_instance_group_example = EmrInstanceGroup(self, "example_1",
            cluster_id=example.id,
            instance_count=2,
            instance_type="c4.xlarge"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_emr_instance_group_example.override_logical_id("example")
```

### master_instance_type Argument Removal

Switch your Terraform configuration to the `master_instance_group` configuration block instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            master_instance_type="m4.large",
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.emr_cluster import EmrCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, name, releaseLabel, serviceRole):
        super().__init__(scope, name)
        EmrCluster(self, "example",
            master_instance_group=EmrClusterMasterInstanceGroup(
                instance_type="m4.large"
            ),
            name=name,
            release_label=release_label,
            service_role=service_role
        )
```

## Resource: aws_glue_job

### allocated_capacity Argument Removal

The Glue API has deprecated the `allocated_capacity` argument. Switch your Terraform configuration to the `max_capacity` argument instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.glue_job import GlueJob
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, command, name, roleArn):
        super().__init__(scope, name)
        GlueJob(self, "example",
            allocated_capacity=2,
            command=command,
            name=name,
            role_arn=role_arn
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.glue_job import GlueJob
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, command, name, roleArn):
        super().__init__(scope, name)
        GlueJob(self, "example",
            max_capacity=2,
            command=command,
            name=name,
            role_arn=role_arn
        )
```

## Resource: aws_iam_access_key

### ses_smtp_password Attribute Removal

In many regions today and in all regions after October 1, 2020, the [SES API will only accept version 4 signatures](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/using-ses-api-authentication.html). If referencing the `ses_smtp_password` attribute, switch your Terraform configuration to the `ses_smtp_password_v4` attribute instead. Please note that this signature is based on the region of the Terraform AWS Provider. If you need the SES v4 password in multiple regions, it may require using [multiple provider instances](https://www.terraform.io/docs/configuration/providers.html#alias-multiple-provider-configurations).

Depending on when the `aws_iam_access_key` resource was created, it may not have a `ses_smtp_password_v4` attribute for you to use. If this is the case you will need to [taint](/docs/commands/taint.html) the resource so that it can be recreated with the new value.

Alternatively, you can stage the change by creating a new `aws_iam_access_key` resource and change any downstream dependencies to use the new `ses_smtp_password_v4` attribute. Once dependents have been updated with the new resource you can remove the old one.

## Resource: aws_iam_instance_profile

### roles Argument Removal

Switch your Terraform configuration to the `role` argument instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.iam_instance_profile import IamInstanceProfile
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        IamInstanceProfile(self, "example",
            roles=[aws_iam_role_example.id]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.iam_instance_profile import IamInstanceProfile
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        IamInstanceProfile(self, "example",
            role=Token.as_string(aws_iam_role_example.id)
        )
```

## Resource: aws_iam_server_certificate

### certificate_body, certificate_chain, and private_key Arguments No Longer Stored as Hash

Previously when the `certificate_body`, `certificate_chain`, and `private_key` arguments were stored in state, they were stored as a hash of the actual value. This hashing has been removed for new or recreated resources to prevent lifecycle issues.

## Resource: aws_instance

### ebs_block_device.iops and root_block_device.iops Argument Apply-Time Validations

Previously when the `iops` argument was configured in either the `ebs_block_device` or `root_block_device` configuration block, the Terraform AWS Provider would automatically disregard the value provided to `iops` if the `type` argument was also configured with a value other than `io1` (either explicitly or omitted, indicating the default type `gp2`) as `iops` are only configurable for the `io1` volume type per the AWS EC2 API. This behavior has changed such that the Terraform AWS Provider will instead return an error at apply time indicating an `iops` value is invalid for volume types other than `io1`.
Exceptions to this are in cases where `iops` is set to `null` or `0` such that the Terraform AWS Provider will continue to accept the value regardless of `type`.

## Resource: aws_lambda_alias

### Import No Longer Converts Function Name to ARN

Previously the resource import would always convert the `function_name` portion of the import identifier into the ARN format. Configurations using the Lambda Function name would show this as an unexpected difference after import. Now this will passthrough the given value on import whether its a Lambda Function name or ARN.

## Resource: aws_launch_template

### network_interfaces.delete_on_termination Argument type change

The `network_interfaces.delete_on_termination` argument is now of type `string`, allowing an unspecified value for the argument since the previous `bool` type only allowed for `true/false` and defaulted to `false` when no value was set. Now to enforce `delete_on_termination` to `false`, the string `"false"` or bare `false` value must be used.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.launch_template import LaunchTemplate
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        LaunchTemplate(self, "example",
            network_interfaces=[LaunchTemplateNetworkInterfaces(
                delete_on_termination=[null]
            )
            ]
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.launch_template import LaunchTemplate
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        LaunchTemplate(self, "example",
            network_interfaces=[LaunchTemplateNetworkInterfaces(
                delete_on_termination=Token.as_string(False)
            )
            ]
        )
```

## Resource: aws_lb_listener_rule

### condition.field and condition.values Arguments Removal

Switch your Terraform configuration to use the `host_header` or `path_pattern` configuration block instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lb_listener_rule import LbListenerRule
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, action, listenerArn):
        super().__init__(scope, name)
        LbListenerRule(self, "example",
            condition=[LbListenerRuleCondition(
                field="path-pattern",
                values=["/static/*"]
            )
            ],
            action=action,
            listener_arn=listener_arn
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lb_listener_rule import LbListenerRule
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, action, listenerArn):
        super().__init__(scope, name)
        LbListenerRule(self, "example",
            condition=[LbListenerRuleCondition(
                path_pattern=LbListenerRuleConditionPathPattern(
                    values=["/static/*"]
                )
            )
            ],
            action=action,
            listener_arn=listener_arn
        )
```

## Resource: aws_msk_cluster

### encryption_info.encryption_in_transit.client_broker Default Updated to Match API

A few weeks after general availability launch and initial release of the `aws_msk_cluster` resource, the MSK API default for client broker encryption switched from `TLS_PLAINTEXT` to `TLS`. The attribute default has now been updated to match the more secure API default, however existing Terraform configurations may show a difference if this setting is not configured.

To continue using the old default when it was previously not configured, add or modify this configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.msk_cluster import MskCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, brokerNodeGroupInfo, clusterName, kafkaVersion, numberOfBrokerNodes):
        super().__init__(scope, name)
        MskCluster(self, "example",
            encryption_info=MskClusterEncryptionInfo(
                encryption_in_transit=MskClusterEncryptionInfoEncryptionInTransit(
                    client_broker="TLS_PLAINTEXT"
                )
            ),
            broker_node_group_info=broker_node_group_info,
            cluster_name=cluster_name,
            kafka_version=kafka_version,
            number_of_broker_nodes=number_of_broker_nodes
        )
```

## Resource: aws_rds_cluster

### scaling_configuration.min_capacity Now Defaults to 1

Previously when the `min_capacity` argument in a `scaling_configuration` block was not configured, the resource would default to 2. This behavior has been updated to align with the AWS RDS Cluster API default of 1.

## Resource: aws_route53_resolver_rule

### Removal of trailing period in domain_name argument

Previously the resource returned the Resolver Rule Domain Name directly from the API, which included a `.` suffix. This proves difficult when many other AWS services do not accept this trailing period (e.g., ACM Certificate). This period is now automatically removed. For example, when the attribute would previously return a Resolver Rule Domain Name such as `example.com.`, the attribute now will be returned as `example.com`.
While the returned value will omit the trailing period, use of configurations with trailing periods will not be interrupted.

## Resource: aws_route53_zone

### Removal of trailing period in name argument

Previously the resource returned the Hosted Zone Domain Name directly from the API, which included a `.` suffix. This proves difficult when many other AWS services do not accept this trailing period (e.g., ACM Certificate). This period is now automatically removed. For example, when the attribute would previously return a Hosted Zone Domain Name such as `example.com.`, the attribute now will be returned as `example.com`.
While the returned value will omit the trailing period, use of configurations with trailing periods will not be interrupted.

## Resource: aws_s3_bucket

### Removal of Automatic aws_s3_bucket_policy Import

Previously when importing the `aws_s3_bucket` resource with the [`terraform import` command](https://www.terraform.io/docs/commands/import.html), the Terraform AWS Provider would automatically attempt to import an associated `aws_s3_bucket_policy` resource as well. This automatic resource import has been removed. Use the [`aws_s3_bucket_policy` resource import](/docs/providers/aws/r/s3_bucket_policy.html#import) to import that resource separately.

### region Attribute Is Now Read-Only

The `region` attribute is no longer configurable, but it remains as a read-only attribute. The region of the `aws_s3_bucket` resource is determined by the region of the Terraform AWS Provider, similar to all other resources.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        S3Bucket(self, "example",
            region="us-west-2"
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        S3Bucket(self, "example")
```

## Resource: aws_s3_bucket_metric

### filter configuration block Plan-Time Validation Change

The `filter` configuration block no longer supports the empty block `{}` and requires at least one of the `prefix` or `tags` attributes to be specified.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket_metric import S3BucketMetric
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, bucket, name):
        super().__init__(scope, name)
        S3BucketMetric(self, "example",
            filter=S3BucketMetricFilter(),
            bucket=bucket,
            name=name
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket_metric import S3BucketMetric
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, bucket, name):
        super().__init__(scope, name)
        S3BucketMetric(self, "example",
            bucket=bucket,
            name=name
        )
```

## Resource: aws_security_group

### Removal of Automatic aws_security_group_rule Import

Previously when importing the `aws_security_group` resource with the [`terraform import` command](https://www.terraform.io/docs/commands/import.html), the Terraform AWS Provider would automatically attempt to import an associated `aws_security_group_rule` resource(s) as well. This automatic resource import has been removed. Use the [`aws_security_group_rule` resource import](/docs/providers/aws/r/security_group_rule.html#import) to import those resources separately.

## Resource: aws_sns_platform_application

### platform_credential and platform_principal Arguments No Longer Stored as SHA256 Hash

Previously when the `platform_credential` and `platform_principal` arguments were stored in state, they were stored as a SHA256 hash of the actual value. This prevented Terraform from properly updating the resource when necessary and the hashing has been removed. The Terraform AWS Provider will show an update to these arguments on the first apply after upgrading to version 3.0.0, which is fixing the Terraform state to remove the hash. Since the attributes are marked as sensitive, the values in the update will not be visible in the Terraform output. If the non-hashed values have not changed, then no update is occurring other than the Terraform state update. If these arguments are the only two updates and they both match the SHA256 removal, the apply will occur without submitting an actual `SetPlatformApplicationAttributes` API call.

## Resource: aws_spot_fleet_request

### valid_until Argument No Longer Uses 24 Hour Default

Previously when the `valid_until` argument was not configured, the resource would default to a 24 hour request. This behavior has been removed and allows for non-expiring requests. To recreate the old behavior, the [`time_offset` resource](https://registry.terraform.io/providers/hashicorp/time/latest/docs/resources/offset) can potentially be used.

## Resource: aws_ssm_maintenance_window_task

### logging_info Configuration Block Removal

Switch your Terraform configuration to the `task_invocation_parameters` configuration block `run_command_parameters` configuration block `output_s3_bucket` and `output_s3_key_prefix` arguments instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.ssm_maintenance_window_task import SsmMaintenanceWindowTask
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, taskArn, taskType, windowId):
        super().__init__(scope, name)
        SsmMaintenanceWindowTask(self, "example",
            logging_info=[{
                "s3_bucket_key_prefix": "example",
                "s3_bucket_name": aws_s3_bucket_example.id
            }
            ],
            task_arn=task_arn,
            task_type=task_type,
            window_id=window_id
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.ssm_maintenance_window_task import SsmMaintenanceWindowTask
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, taskArn, taskType, windowId):
        super().__init__(scope, name)
        SsmMaintenanceWindowTask(self, "example",
            task_invocation_parameters=SsmMaintenanceWindowTaskTaskInvocationParameters(
                run_command_parameters=SsmMaintenanceWindowTaskTaskInvocationParametersRunCommandParameters(
                    output_s3_bucket=Token.as_string(aws_s3_bucket_example.id),
                    output_s3_key_prefix="example"
                )
            ),
            task_arn=task_arn,
            task_type=task_type,
            window_id=window_id
        )
```

### task_parameters Configuration Block Removal

Switch your Terraform configuration to the `task_invocation_parameters` configuration block `run_command_parameters` configuration block `parameter` configuration blocks instead.

For example, given this previous configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.ssm_maintenance_window_task import SsmMaintenanceWindowTask
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, taskArn, taskType, windowId):
        super().__init__(scope, name)
        SsmMaintenanceWindowTask(self, "example",
            task_parameters=[{
                "name": "commands",
                "values": ["date"]
            }
            ],
            task_arn=task_arn,
            task_type=task_type,
            window_id=window_id
        )
```

An updated configuration:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.ssm_maintenance_window_task import SsmMaintenanceWindowTask
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, taskArn, taskType, windowId):
        super().__init__(scope, name)
        SsmMaintenanceWindowTask(self, "example",
            task_invocation_parameters=SsmMaintenanceWindowTaskTaskInvocationParameters(
                run_command_parameters=SsmMaintenanceWindowTaskTaskInvocationParametersRunCommandParameters(
                    parameter=[SsmMaintenanceWindowTaskTaskInvocationParametersRunCommandParametersParameter(
                        name="commands",
                        values=["date"]
                    )
                    ]
                )
            ),
            task_arn=task_arn,
            task_type=task_type,
            window_id=window_id
        )
```

<!-- cache-key: cdktf-0.20.1 input-fedd1760b9754507e4a21a87fc167b34be2073f23cf84a5f4c3f209428295c89 -->