---
subcategory: "S3 (Simple Storage)"
layout: "aws"
page_title: "AWS: aws_s3_bucket_notification"
description: |-
  Manages a S3 Bucket Notification Configuration
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_s3_bucket_notification

Manages a S3 Bucket Notification Configuration. For additional information, see the [Configuring S3 Event Notifications section in the Amazon S3 Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html).

~> **NOTE:** S3 Buckets only support a single notification configuration. Declaring multiple `aws_s3_bucket_notification` resources to the same S3 Bucket will cause a perpetual difference in configuration. See the example "Trigger multiple Lambda functions" for an option.

## Example Usage

### Add notification configuration to SNS Topic

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sns_topic import SnsTopic
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        topic = DataAwsIamPolicyDocument(self, "topic",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["SNS:Publish"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnLike",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["s3.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=["arn:aws:sns:*:*:s3-event-notification-topic"]
            )
            ]
        )
        aws_sns_topic_topic = SnsTopic(self, "topic_2",
            name="s3-event-notification-topic",
            policy=Token.as_string(topic.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sns_topic_topic.override_logical_id("topic")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            topic=[S3BucketNotificationTopic(
                events=["s3:ObjectCreated:*"],
                filter_suffix=".log",
                topic_arn=Token.as_string(aws_sns_topic_topic.arn)
            )
            ]
        )
```

### Add notification configuration to SQS Queue

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sqs_queue import SqsQueue
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        queue = DataAwsIamPolicyDocument(self, "queue",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sqs:SendMessage"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnEquals",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["*"],
                    type="*"
                )
                ],
                resources=["arn:aws:sqs:*:*:s3-event-notification-queue"]
            )
            ]
        )
        aws_sqs_queue_queue = SqsQueue(self, "queue_2",
            name="s3-event-notification-queue",
            policy=Token.as_string(queue.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sqs_queue_queue.override_logical_id("queue")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            queue=[S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_suffix=".log",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            )
            ]
        )
```

### Add notification configuration to Lambda Function

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_permission import LambdaPermission
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["lambda.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        iam_for_lambda = IamRole(self, "iam_for_lambda",
            assume_role_policy=Token.as_string(assume_role.json),
            name="iam_for_lambda"
        )
        func = LambdaFunction(self, "func",
            filename="your-function.zip",
            function_name="example_lambda_name",
            handler="exports.example",
            role=iam_for_lambda.arn,
            runtime="go1.x"
        )
        allow_bucket = LambdaPermission(self, "allow_bucket",
            action="lambda:InvokeFunction",
            function_name=func.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            depends_on=[allow_bucket],
            lambda_function=[S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="AWSLogs/",
                filter_suffix=".log",
                lambda_function_arn=func.arn
            )
            ]
        )
```

### Trigger multiple Lambda functions

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_permission import LambdaPermission
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            actions=["sts:AssumeRole"],
            effect="Allow",
            principals=[{
                "identifiers": ["lambda.amazonaws.com"],
                "type": "Service"
            }
            ]
        )
        iam_for_lambda = IamRole(self, "iam_for_lambda",
            assume_role_policy=Token.as_string(assume_role.json),
            name="iam_for_lambda"
        )
        func1 = LambdaFunction(self, "func1",
            filename="your-function1.zip",
            function_name="example_lambda_name1",
            handler="exports.example",
            role=iam_for_lambda.arn,
            runtime="go1.x"
        )
        func2 = LambdaFunction(self, "func2",
            filename="your-function2.zip",
            function_name="example_lambda_name2",
            handler="exports.example",
            role=iam_for_lambda.arn
        )
        allow_bucket1 = LambdaPermission(self, "allow_bucket1",
            action="lambda:InvokeFunction",
            function_name=func1.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket1"
        )
        allow_bucket2 = LambdaPermission(self, "allow_bucket2",
            action="lambda:InvokeFunction",
            function_name=func2.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket2"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            depends_on=[allow_bucket1, allow_bucket2],
            lambda_function=[S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="AWSLogs/",
                filter_suffix=".log",
                lambda_function_arn=func1.arn
            ), S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="OtherLogs/",
                filter_suffix=".log",
                lambda_function_arn=func2.arn
            )
            ]
        )
```

### Add multiple notification configurations to SQS Queue

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sqs_queue import SqsQueue
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        queue = DataAwsIamPolicyDocument(self, "queue",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sqs:SendMessage"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnEquals",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["*"],
                    type="*"
                )
                ],
                resources=["arn:aws:sqs:*:*:s3-event-notification-queue"]
            )
            ]
        )
        aws_sqs_queue_queue = SqsQueue(self, "queue_2",
            name="s3-event-notification-queue",
            policy=Token.as_string(queue.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sqs_queue_queue.override_logical_id("queue")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            queue=[S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_prefix="images/",
                id="image-upload-event",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            ), S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_prefix="videos/",
                id="video-upload-event",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            )
            ]
        )
```

For Terraform's [JSON syntax](https://www.terraform.io/docs/configuration/syntax.html), use an array instead of defining the `queue` key twice.

```json
{
	"bucket": "${aws_s3_bucket.bucket.id}",
	"queue": [
		{
			"id": "image-upload-event",
			"queue_arn": "${aws_sqs_queue.queue.arn}",
			"events": ["s3:ObjectCreated:*"],
			"filter_prefix": "images/"
		},
		{
			"id": "video-upload-event",
			"queue_arn": "${aws_sqs_queue.queue.arn}",
			"events": ["s3:ObjectCreated:*"],
			"filter_prefix": "videos/"
		}
	]
}
```

### Emit events to EventBridge

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            eventbridge=True
        )
```

## Argument Reference

The following arguments are required:

* `bucket` - (Required) Name of the bucket for notification configuration.

The following arguments are optional:

* `eventbridge` - (Optional) Whether to enable Amazon EventBridge notifications. Defaults to `false`.
* `lambda_function` - (Optional, Multiple) Used to configure notifications to a Lambda Function. See below.
* `queue` - (Optional) Notification configuration to SQS Queue. See below.
* `topic` - (Optional) Notification configuration to SNS Topic. See below.

### `lambda_function`

* `events` - (Required) [Event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `lambda_function_arn` - (Required) Lambda function ARN.

### `queue`

* `events` - (Required) Specifies [event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `queue_arn` - (Required) SQS queue ARN.

### `topic`

* `events` - (Required) [Event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `topic_arn` - (Required) SNS topic ARN.

## Attribute Reference

This resource exports no additional attributes.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import S3 bucket notification using the `bucket`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
```

Using `terraform import`, import S3 bucket notification using the `bucket`. For example:

```console
% terraform import aws_s3_bucket_notification.bucket_notification bucket-name
```

<!-- cache-key: cdktf-0.19.0 input-2b3d5922ed8d8483ab9bf6365c4cf548c1d93fbe385ee90435be6dfab425db07 -->