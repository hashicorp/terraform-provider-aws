---
subcategory: "S3 (Simple Storage)"
layout: "aws"
page_title: "AWS: aws_s3_bucket_notification"
description: |-
  Manages a S3 Bucket Notification Configuration
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_s3_bucket_notification

Manages a S3 Bucket Notification Configuration. For additional information, see the [Configuring S3 Event Notifications section in the Amazon S3 Developer Guide](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html).

~> **NOTE:** S3 Buckets only support a single notification configuration resource. Declaring multiple `aws_s3_bucket_notification` resources to the same S3 Bucket will cause a perpetual difference in configuration. This resource will overwrite any existing event notifications configured for the S3 bucket it's associated with. See the example "Trigger multiple Lambda functions" for an option of how to configure multiple triggers within this resource.

-> This resource cannot be used with S3 directory buckets.

## Example Usage

### Add notification configuration to SNS Topic

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sns_topic import SnsTopic
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        topic = DataAwsIamPolicyDocument(self, "topic",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["SNS:Publish"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnLike",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["s3.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=["arn:aws:sns:*:*:s3-event-notification-topic"]
            )
            ]
        )
        aws_sns_topic_topic = SnsTopic(self, "topic_2",
            name="s3-event-notification-topic",
            policy=Token.as_string(topic.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sns_topic_topic.override_logical_id("topic")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            topic=[S3BucketNotificationTopic(
                events=["s3:ObjectCreated:*"],
                filter_suffix=".log",
                topic_arn=Token.as_string(aws_sns_topic_topic.arn)
            )
            ]
        )
```

### Add notification configuration to SQS Queue

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sqs_queue import SqsQueue
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        queue = DataAwsIamPolicyDocument(self, "queue",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sqs:SendMessage"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnEquals",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["*"],
                    type="*"
                )
                ],
                resources=["arn:aws:sqs:*:*:s3-event-notification-queue"]
            )
            ]
        )
        aws_sqs_queue_queue = SqsQueue(self, "queue_2",
            name="s3-event-notification-queue",
            policy=Token.as_string(queue.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sqs_queue_queue.override_logical_id("queue")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            queue=[S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_suffix=".log",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            )
            ]
        )
```

### Add notification configuration to Lambda Function

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_permission import LambdaPermission
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["lambda.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        iam_for_lambda = IamRole(self, "iam_for_lambda",
            assume_role_policy=Token.as_string(assume_role.json),
            name="iam_for_lambda"
        )
        func = LambdaFunction(self, "func",
            filename="your-function.zip",
            function_name="example_lambda_name",
            handler="exports.example",
            role=iam_for_lambda.arn,
            runtime="go1.x"
        )
        allow_bucket = LambdaPermission(self, "allow_bucket",
            action="lambda:InvokeFunction",
            function_name=func.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            depends_on=[allow_bucket],
            lambda_function=[S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="AWSLogs/",
                filter_suffix=".log",
                lambda_function_arn=func.arn
            )
            ]
        )
```

### Trigger multiple Lambda functions

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_permission import LambdaPermission
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["lambda.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        iam_for_lambda = IamRole(self, "iam_for_lambda",
            assume_role_policy=Token.as_string(assume_role.json),
            name="iam_for_lambda"
        )
        func1 = LambdaFunction(self, "func1",
            filename="your-function1.zip",
            function_name="example_lambda_name1",
            handler="exports.example",
            role=iam_for_lambda.arn,
            runtime="go1.x"
        )
        func2 = LambdaFunction(self, "func2",
            filename="your-function2.zip",
            function_name="example_lambda_name2",
            handler="exports.example",
            role=iam_for_lambda.arn
        )
        allow_bucket1 = LambdaPermission(self, "allow_bucket1",
            action="lambda:InvokeFunction",
            function_name=func1.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket1"
        )
        allow_bucket2 = LambdaPermission(self, "allow_bucket2",
            action="lambda:InvokeFunction",
            function_name=func2.arn,
            principal="s3.amazonaws.com",
            source_arn=bucket.arn,
            statement_id="AllowExecutionFromS3Bucket2"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            depends_on=[allow_bucket1, allow_bucket2],
            lambda_function=[S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="AWSLogs/",
                filter_suffix=".log",
                lambda_function_arn=func1.arn
            ), S3BucketNotificationLambdaFunction(
                events=["s3:ObjectCreated:*"],
                filter_prefix="OtherLogs/",
                filter_suffix=".log",
                lambda_function_arn=func2.arn
            )
            ]
        )
```

### Add multiple notification configurations to SQS Queue

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
from imports.aws.sqs_queue import SqsQueue
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        queue = DataAwsIamPolicyDocument(self, "queue",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sqs:SendMessage"],
                condition=[DataAwsIamPolicyDocumentStatementCondition(
                    test="ArnEquals",
                    values=[bucket.arn],
                    variable="aws:SourceArn"
                )
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["*"],
                    type="*"
                )
                ],
                resources=["arn:aws:sqs:*:*:s3-event-notification-queue"]
            )
            ]
        )
        aws_sqs_queue_queue = SqsQueue(self, "queue_2",
            name="s3-event-notification-queue",
            policy=Token.as_string(queue.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_sqs_queue_queue.override_logical_id("queue")
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            queue=[S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_prefix="images/",
                id="image-upload-event",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            ), S3BucketNotificationQueue(
                events=["s3:ObjectCreated:*"],
                filter_prefix="videos/",
                id="video-upload-event",
                queue_arn=Token.as_string(aws_sqs_queue_queue.arn)
            )
            ]
        )
```

For Terraform's [JSON syntax](https://www.terraform.io/docs/configuration/syntax.html), use an array instead of defining the `queue` key twice.

```json
{
	"bucket": "${aws_s3_bucket.bucket.id}",
	"queue": [
		{
			"id": "image-upload-event",
			"queue_arn": "${aws_sqs_queue.queue.arn}",
			"events": ["s3:ObjectCreated:*"],
			"filter_prefix": "images/"
		},
		{
			"id": "video-upload-event",
			"queue_arn": "${aws_sqs_queue.queue.arn}",
			"events": ["s3:ObjectCreated:*"],
			"filter_prefix": "videos/"
		}
	]
}
```

### Emit events to EventBridge

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        bucket = S3Bucket(self, "bucket",
            bucket="your-bucket-name"
        )
        S3BucketNotification(self, "bucket_notification",
            bucket=bucket.id,
            eventbridge=True
        )
```

## Argument Reference

The following arguments are required:

* `bucket` - (Required) Name of the bucket for notification configuration.

The following arguments are optional:

* `eventbridge` - (Optional) Whether to enable Amazon EventBridge notifications. Defaults to `false`.
* `lambda_function` - (Optional, Multiple) Used to configure notifications to a Lambda Function. See below.
* `queue` - (Optional) Notification configuration to SQS Queue. See below.
* `topic` - (Optional) Notification configuration to SNS Topic. See below.

### `lambda_function`

* `events` - (Required) [Event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `lambda_function_arn` - (Required) Lambda function ARN.

### `queue`

* `events` - (Required) Specifies [event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `queue_arn` - (Required) SQS queue ARN.

### `topic`

* `events` - (Required) [Event](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html#notification-how-to-event-types-and-destinations) for which to send notifications.
* `filter_prefix` - (Optional) Object key name prefix.
* `filter_suffix` - (Optional) Object key name suffix.
* `id` - (Optional) Unique identifier for each of the notification configurations.
* `topic_arn` - (Required) SNS topic ARN.

## Attribute Reference

This resource exports no additional attributes.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import S3 bucket notification using the `bucket`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket_notification import S3BucketNotification
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        S3BucketNotification.generate_config_for_import(self, "bucketNotification", "bucket-name")
```

Using `terraform import`, import S3 bucket notification using the `bucket`. For example:

```console
% terraform import aws_s3_bucket_notification.bucket_notification bucket-name
```

<!-- cache-key: cdktf-0.20.1 input-ffc8a3d834243776f095d91cbf1034f45496ca04ecab5cc652f8eef56b45e134 -->