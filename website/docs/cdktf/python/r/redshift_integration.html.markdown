---
subcategory: "Redshift"
layout: "aws"
page_title: "AWS: aws_redshift_integration"
description: |-
  Terraform resource for managing a DynamoDB zero-ETL integration or S3 event integration with Amazon Redshift.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_redshift_integration

Terraform resource for managing a DynamoDB zero-ETL integration or S3 event integration with Amazon Redshift. You can refer to the [User Guide](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/RedshiftforDynamoDB-zero-etl.html) for a DynamoDB zero-ETL integration or the [User Guide](https://docs.aws.amazon.com/redshift/latest/dg/loading-data-copy-job.html) for a S3 event integration.

## Example Usage

### Basic Usage

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.dynamodb_table import DynamodbTable
from imports.aws.redshift_integration import RedshiftIntegration
from imports.aws.redshiftserverless_namespace import RedshiftserverlessNamespace
from imports.aws.redshiftserverless_workgroup import RedshiftserverlessWorkgroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = DynamodbTable(self, "example",
            attribute=[DynamodbTableAttribute(
                name="example",
                type="S"
            )
            ],
            hash_key="example",
            name="dynamodb-table-example",
            point_in_time_recovery=DynamodbTablePointInTimeRecovery(
                enabled=True
            ),
            read_capacity=1,
            write_capacity=1
        )
        aws_redshiftserverless_namespace_example =
        RedshiftserverlessNamespace(self, "example_1",
            namespace_name="redshift-example"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_redshiftserverless_namespace_example.override_logical_id("example")
        aws_redshiftserverless_workgroup_example =
        RedshiftserverlessWorkgroup(self, "example_2",
            base_capacity=8,
            config_parameter=[RedshiftserverlessWorkgroupConfigParameter(
                parameter_key="enable_case_sensitive_identifier",
                parameter_value="true"
            )
            ],
            namespace_name=Token.as_string(aws_redshiftserverless_namespace_example.namespace_name),
            publicly_accessible=False,
            subnet_ids=[example1.id, example2.id, example3.id],
            workgroup_name="example-workgroup"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_redshiftserverless_workgroup_example.override_logical_id("example")
        aws_redshift_integration_example = RedshiftIntegration(self, "example_3",
            integration_name="example",
            source_arn=example.arn,
            target_arn=Token.as_string(aws_redshiftserverless_namespace_example.arn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_redshift_integration_example.override_logical_id("example")
```

### Use own KMS key

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, Fn, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_caller_identity import DataAwsCallerIdentity
from imports.aws.kms_key import KmsKey
from imports.aws.kms_key_policy import KmsKeyPolicy
from imports.aws.redshift_integration import RedshiftIntegration
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = KmsKey(self, "example",
            deletion_window_in_days=10,
            description="example"
        )
        aws_redshift_integration_example = RedshiftIntegration(self, "example_1",
            additional_encryption_context={
                "example": "test"
            },
            integration_name="example",
            kms_key_id=example.arn,
            source_arn=Token.as_string(aws_dynamodb_table_example.arn),
            target_arn=Token.as_string(aws_redshiftserverless_namespace_example.arn)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_redshift_integration_example.override_logical_id("example")
        current = DataAwsCallerIdentity(self, "current")
        aws_kms_key_policy_example = KmsKeyPolicy(self, "example_3",
            key_id=example.id,
            policy=Token.as_string(
                Fn.jsonencode({
                    "Statement": [{
                        "Action": "kms:*",
                        "Effect": "Allow",
                        "Principal": {
                            "AWS": "arn:aws:iam::${" + current.account_id + "}:root"
                        },
                        "Resource": "*"
                    }, {
                        "Action": ["kms:Decrypt", "kms:CreateGrant"],
                        "Condition": {
                            "ArnEquals": {
                                "aws:_source_arn": "arn:aws:redshift:*:${" + current.account_id + "}:integration:*"
                            },
                            "StringEquals": {
                                "aws:_source_account": current.account_id
                            }
                        },
                        "Effect": "Allow",
                        "Principal": {
                            "Service": "redshift.amazonaws.com"
                        },
                        "Resource": "*"
                    }
                    ],
                    "Version": "2008-10-17"
                }))
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_kms_key_policy_example.override_logical_id("example")
```

## Argument Reference

The following arguments are required:

* `integration_name` - (Required) Name of the integration.
* `source_arn` - (Required, Forces new resources) ARN of the database to use as the source for replication. You can specify a DynamoDB table or an S3 bucket.
* `target_arn` - (Required, Forces new resources) ARN of the Redshift data warehouse to use as the target for replication.

The following arguments are optional:

* `additional_encryption_context` - (Optional, Forces new resources) Set of non-secret keyâ€“value pairs that contains additional contextual information about the data.
For more information, see the [User Guide](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#encrypt_context).
You can only include this parameter if you specify the `kms_key_id` parameter.
* `description` - (Optional) Description of the integration.
* `kms_key_id` - (Optional, Forces new resources) KMS key identifier for the key to use to encrypt the integration.
If you don't specify an encryption key, Redshift uses a default AWS owned key.
You can only include this parameter if `source_arn` references a DynamoDB table.
* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

For more detailed documentation about each argument, refer to the [AWS official documentation](https://docs.aws.amazon.com/cli/latest/reference/redshift/create-integration.html).

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN of the Integration.
* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `30m`)
* `update` - (Default `30m`)
* `delete` - (Default `30m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Redshift Integration using the `arn`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.redshift_integration import RedshiftIntegration
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        RedshiftIntegration.generate_config_for_import(self, "example", "arn:aws:redshift:us-west-2:123456789012:integration:abcdefgh-0000-1111-2222-123456789012")
```

Using `terraform import`, import Redshift Integration using the `arn`. For example:

```console
% terraform import aws_redshift_integration.example arn:aws:redshift:us-west-2:123456789012:integration:abcdefgh-0000-1111-2222-123456789012
```

<!-- cache-key: cdktf-0.20.8 input-5a220be4e5e1b82a9911a62ad39cafe74cb1cb67c8462441650d8ed8ff83f207 -->