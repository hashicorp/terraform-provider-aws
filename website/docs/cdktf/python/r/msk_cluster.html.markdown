---
subcategory: "Managed Streaming for Kafka"
layout: "aws"
page_title: "AWS: aws_msk_cluster"
description: |-
  Terraform resource for managing an AWS Managed Streaming for Kafka cluster.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_msk_cluster

Manages an Amazon MSK cluster.

-> **Note:** This resource manages _provisioned_ clusters. To manage a _serverless_ Amazon MSK cluster, use the [`aws_msk_serverless_cluster`](/docs/providers/aws/r/msk_serverless_cluster.html) resource.

## Example Usage

### Basic

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from cdktf import TerraformResourceLifecycle
from constructs import Construct
from cdktf import Token, Fn, TerraformOutput, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.data_aws_availability_zones import DataAwsAvailabilityZones
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.kinesis_firehose_delivery_stream import KinesisFirehoseDeliveryStream
from imports.aws.kms_key import KmsKey
from imports.aws.msk_cluster import MskCluster
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_acl import S3BucketAcl
from imports.aws.security_group import SecurityGroup
from imports.aws.subnet import Subnet
from imports.aws.vpc import Vpc
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        test = CloudwatchLogGroup(self, "test",
            name="msk_broker_logs"
        )
        kms = KmsKey(self, "kms",
            description="example"
        )
        bucket = S3Bucket(self, "bucket",
            bucket="msk-broker-logs-bucket"
        )
        S3BucketAcl(self, "bucket_acl",
            acl="private",
            bucket=bucket.id
        )
        vpc = Vpc(self, "vpc",
            cidr_block="192.168.0.0/22"
        )
        azs = DataAwsAvailabilityZones(self, "azs",
            state="available"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["firehose.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        firehose_role = IamRole(self, "firehose_role",
            assume_role_policy=Token.as_string(assume_role.json),
            name="firehose_test_role"
        )
        test_stream = KinesisFirehoseDeliveryStream(self, "test_stream",
            destination="extended_s3",
            extended_s3_configuration=KinesisFirehoseDeliveryStreamExtendedS3Configuration(
                bucket_arn=bucket.arn,
                role_arn=firehose_role.arn
            ),
            lifecycle=TerraformResourceLifecycle(
                ignore_changes=["logDeliveryEnabled"]
            ),
            name="terraform-kinesis-firehose-msk-broker-logs-stream",
            tags={
                "LogDeliveryEnabled": "placeholder"
            }
        )
        sg = SecurityGroup(self, "sg",
            vpc_id=vpc.id
        )
        subnet_az1 = Subnet(self, "subnet_az1",
            availability_zone=Token.as_string(Fn.lookup_nested(azs.names, ["0"])),
            cidr_block="192.168.0.0/24",
            vpc_id=vpc.id
        )
        subnet_az2 = Subnet(self, "subnet_az2",
            availability_zone=Token.as_string(Fn.lookup_nested(azs.names, ["1"])),
            cidr_block="192.168.1.0/24",
            vpc_id=vpc.id
        )
        subnet_az3 = Subnet(self, "subnet_az3",
            availability_zone=Token.as_string(Fn.lookup_nested(azs.names, ["2"])),
            cidr_block="192.168.2.0/24",
            vpc_id=vpc.id
        )
        example = MskCluster(self, "example",
            broker_node_group_info=MskClusterBrokerNodeGroupInfo(
                client_subnets=[subnet_az1.id, subnet_az2.id, subnet_az3.id],
                instance_type="kafka.m5.large",
                security_groups=[sg.id],
                storage_info=MskClusterBrokerNodeGroupInfoStorageInfo(
                    ebs_storage_info=MskClusterBrokerNodeGroupInfoStorageInfoEbsStorageInfo(
                        volume_size=1000
                    )
                )
            ),
            cluster_name="example",
            encryption_info=MskClusterEncryptionInfo(
                encryption_at_rest_kms_key_arn=kms.arn
            ),
            kafka_version="3.2.0",
            logging_info=MskClusterLoggingInfo(
                broker_logs=MskClusterLoggingInfoBrokerLogs(
                    cloudwatch_logs=MskClusterLoggingInfoBrokerLogsCloudwatchLogs(
                        enabled=True,
                        log_group=test.name
                    ),
                    firehose=MskClusterLoggingInfoBrokerLogsFirehose(
                        delivery_stream=test_stream.name,
                        enabled=True
                    ),
                    s3=MskClusterLoggingInfoBrokerLogsS3(
                        bucket=bucket.id,
                        enabled=True,
                        prefix="logs/msk-"
                    )
                )
            ),
            number_of_broker_nodes=3,
            open_monitoring=MskClusterOpenMonitoring(
                prometheus=MskClusterOpenMonitoringPrometheus(
                    jmx_exporter=MskClusterOpenMonitoringPrometheusJmxExporter(
                        enabled_in_broker=True
                    ),
                    node_exporter=MskClusterOpenMonitoringPrometheusNodeExporter(
                        enabled_in_broker=True
                    )
                )
            ),
            tags={
                "foo": "bar"
            }
        )
        TerraformOutput(self, "bootstrap_brokers_tls",
            value=example.bootstrap_brokers_tls,
            description="TLS connection host:port pairs"
        )
        TerraformOutput(self, "zookeeper_connect_string",
            value=example.zookeeper_connect_string
        )
```

### With volume_throughput argument

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.msk_cluster import MskCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        MskCluster(self, "example",
            broker_node_group_info=MskClusterBrokerNodeGroupInfo(
                client_subnets=[subnet_az1.id, subnet_az2.id, subnet_az3.id],
                instance_type="kafka.m5.4xlarge",
                security_groups=[sg.id],
                storage_info=MskClusterBrokerNodeGroupInfoStorageInfo(
                    ebs_storage_info=MskClusterBrokerNodeGroupInfoStorageInfoEbsStorageInfo(
                        provisioned_throughput=MskClusterBrokerNodeGroupInfoStorageInfoEbsStorageInfoProvisionedThroughput(
                            enabled=True,
                            volume_throughput=250
                        ),
                        volume_size=1000
                    )
                )
            ),
            cluster_name="example",
            kafka_version="2.7.1",
            number_of_broker_nodes=3
        )
```

## Argument Reference

This resource supports the following arguments:

* `broker_node_group_info` - (Required) Configuration block for the broker nodes of the Kafka cluster.
* `cluster_name` - (Required) Name of the MSK cluster.
* `kafka_version` - (Required) Specify the desired Kafka software version.
* `number_of_broker_nodes` - (Required) The desired total number of broker nodes in the kafka cluster.  It must be a multiple of the number of specified client subnets.
* `client_authentication` - (Optional) Configuration block for specifying a client authentication. See below.
* `configuration_info` - (Optional) Configuration block for specifying a MSK Configuration to attach to Kafka brokers. See below.
* `encryption_info` - (Optional) Configuration block for specifying encryption. See below.
* `enhanced_monitoring` - (Optional) Specify the desired enhanced MSK CloudWatch monitoring level. See [Monitoring Amazon MSK with Amazon CloudWatch](https://docs.aws.amazon.com/msk/latest/developerguide/monitoring.html)
* `open_monitoring` - (Optional) Configuration block for JMX and Node monitoring for the MSK cluster. See below.
* `logging_info` - (Optional) Configuration block for streaming broker logs to Cloudwatch/S3/Kinesis Firehose. See below.
* `storage_mode` - (Optional) Controls storage mode for supported storage tiers. Valid values are: `LOCAL` or `TIERED`.
* `tags` - (Optional) A map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### broker_node_group_info Argument Reference

* `client_subnets` - (Required) A list of subnets to connect to in client VPC ([documentation](https://docs.aws.amazon.com/msk/1.0/apireference/clusters.html#clusters-prop-brokernodegroupinfo-clientsubnets)).
* `instance_type` - (Required) Specify the instance type to use for the kafka brokersE.g., kafka.m5.large. ([Pricing info](https://aws.amazon.com/msk/pricing/))
* `security_groups` - (Required) A list of the security groups to associate with the elastic network interfaces to control who can communicate with the cluster.
* `az_distribution` - (Optional) The distribution of broker nodes across availability zones ([documentation](https://docs.aws.amazon.com/msk/1.0/apireference/clusters.html#clusters-model-brokerazdistribution)). Currently the only valid value is `DEFAULT`.
* `connectivity_info` - (Optional) Information about the cluster access configuration. See below. For security reasons, you can't turn on public access while creating an MSK cluster. However, you can update an existing cluster to make it publicly accessible. You can also create a new cluster and then update it to make it publicly accessible ([documentation](https://docs.aws.amazon.com/msk/latest/developerguide/public-access.html)).
* `storage_info` - (Optional) A block that contains information about storage volumes attached to MSK broker nodes. See below.

### broker_node_group_info connectivity_info Argument Reference

* `public_access` - (Optional) Access control settings for brokers. See below.
* `vpc_connectivity` - (Optional) VPC connectivity access control for brokers. See below.

### connectivity_info public_access Argument Reference

* `type` - (Optional) Public access type. Valid values: `DISABLED`, `SERVICE_PROVIDED_EIPS`.

### connectivity_info vpc_connectivity Argument Reference

* `client_authentication` - (Optional) Includes all client authentication information for VPC connectivity. See below.

### vpc_connectivity client_authentication Argument Reference

* `sasl` - (Optional) SASL authentication type details for VPC connectivity. See below.
* `tls` - (Optional) Enables TLS authentication for VPC connectivity.

### vpc_connectivity client_authentication sasl Argument Reference

* `iam` - (Optional) Enables SASL/IAM authentication for VPC connectivity.
* `scram` - (Optional) Enables SASL/SCRAM authentication for VPC connectivity.

### broker_node_group_info storage_info Argument Reference

* `ebs_storage_info` - (Optional) A block that contains EBS volume information. See below.

### storage_info ebs_storage_info Argument Reference

* `provisioned_throughput` - (Optional) A block that contains EBS volume provisioned throughput information. To provision storage throughput, you must choose broker type kafka.m5.4xlarge or larger. See below.
* `volume_size` - (Optional) The size in GiB of the EBS volume for the data drive on each broker node. Minimum value of `1` and maximum value of `16384`.

### ebs_storage_info provisioned_throughput Argument Reference

* `enabled` - (Optional) Controls whether provisioned throughput is enabled or not. Default value: `false`.
* `volume_throughput` - (Optional) Throughput value of the EBS volumes for the data drive on each kafka broker node in MiB per second. The minimum value is `250`. The maximum value varies between broker type. You can refer to the valid values for the maximum volume throughput at the following [documentation on throughput bottlenecks](https://docs.aws.amazon.com/msk/latest/developerguide/msk-provision-throughput.html#throughput-bottlenecks)

### client_authentication Argument Reference

* `sasl` - (Optional) Configuration block for specifying SASL client authentication. See below.
* `tls` - (Optional) Configuration block for specifying TLS client authentication. See below.
* `unauthenticated` - (Optional) Enables unauthenticated access.

#### client_authentication sasl Argument Reference

* `iam` - (Optional) Enables IAM client authentication. Defaults to `false`.
* `scram` - (Optional) Enables SCRAM client authentication via AWS Secrets Manager. Defaults to `false`.

#### client_authentication tls Argument Reference

* `certificate_authority_arns` - (Optional) List of ACM Certificate Authority Amazon Resource Names (ARNs).

### configuration_info Argument Reference

* `arn` - (Required) Amazon Resource Name (ARN) of the MSK Configuration to use in the cluster.
* `revision` - (Required) Revision of the MSK Configuration to use in the cluster.

### encryption_info Argument Reference

* `encryption_in_transit` - (Optional) Configuration block to specify encryption in transit. See below.
* `encryption_at_rest_kms_key_arn` - (Optional) You may specify a KMS key short ID or ARN (it will always output an ARN) to use for encrypting your data at rest.  If no key is specified, an AWS managed KMS ('aws/msk' managed service) key will be used for encrypting the data at rest.

#### encryption_info encryption_in_transit Argument Reference

* `client_broker` - (Optional) Encryption setting for data in transit between clients and brokers. Valid values: `TLS`, `TLS_PLAINTEXT`, and `PLAINTEXT`. Default value is `TLS`.
* `in_cluster` - (Optional) Whether data communication among broker nodes is encrypted. Default value: `true`.

#### open_monitoring Argument Reference

* `prometheus` - (Required) Configuration block for Prometheus settings for open monitoring. See below.

#### open_monitoring prometheus Argument Reference

* `jmx_exporter` - (Optional) Configuration block for JMX Exporter. See below.
* `node_exporter` - (Optional) Configuration block for Node Exporter. See below.

#### open_monitoring prometheus jmx_exporter Argument Reference

* `enabled_in_broker` - (Required) Indicates whether you want to enable or disable the JMX Exporter.

#### open_monitoring prometheus node_exporter Argument Reference

* `enabled_in_broker` - (Required) Indicates whether you want to enable or disable the Node Exporter.

#### logging_info Argument Reference

* `broker_logs` - (Required) Configuration block for Broker Logs settings for logging info. See below.

#### logging_info broker_logs cloudwatch_logs Argument Reference

* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to Cloudwatch Logs.
* `log_group` - (Optional) Name of the Cloudwatch Log Group to deliver logs to.

#### logging_info broker_logs firehose Argument Reference

* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to Kinesis Data Firehose.
* `delivery_stream` - (Optional) Name of the Kinesis Data Firehose delivery stream to deliver logs to.

#### logging_info broker_logs s3 Argument Reference

* `enabled` - (Optional) Indicates whether you want to enable or disable streaming broker logs to S3.
* `bucket` - (Optional) Name of the S3 bucket to deliver logs to.
* `prefix` - (Optional) Prefix to append to the folder name.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - Amazon Resource Name (ARN) of the MSK cluster.
* `bootstrap_brokers` - Comma separated list of one or more hostname:port pairs of kafka brokers suitable to bootstrap connectivity to the kafka cluster. Contains a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `PLAINTEXT` or `TLS_PLAINTEXT`. The resource sorts values alphabetically. AWS may not always return all endpoints so this value is not guaranteed to be stable across applies.
* `bootstrap_brokers_public_sasl_iam` - One or more DNS names (or IP addresses) and SASL IAM port pairs. For example, `b-1-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9198,b-2-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9198,b-3-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9198`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.iam` is set to `true` and `broker_node_group_info.0.connectivity_info.0.public_access.0.type` is set to `SERVICE_PROVIDED_EIPS` and the cluster fulfill all other requirements for public access. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_public_sasl_scram` - One or more DNS names (or IP addresses) and SASL SCRAM port pairs. For example, `b-1-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9196,b-2-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9196,b-3-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9196`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.scram` is set to `true` and `broker_node_group_info.0.connectivity_info.0.public_access.0.type` is set to `SERVICE_PROVIDED_EIPS` and the cluster fulfill all other requirements for public access. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_public_tls` - One or more DNS names (or IP addresses) and TLS port pairs. For example, `b-1-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9194,b-2-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9194,b-3-public.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9194`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `broker_node_group_info.0.connectivity_info.0.public_access.0.type` is set to `SERVICE_PROVIDED_EIPS` and the cluster fulfill all other requirements for public access. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_sasl_iam` - One or more DNS names (or IP addresses) and SASL IAM port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9098`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.iam` is set to `true`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_sasl_scram` - One or more DNS names (or IP addresses) and SASL SCRAM port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9096`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS` and `client_authentication.0.sasl.0.scram` is set to `true`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_tls` - One or more DNS names (or IP addresses) and TLS port pairs. For example, `b-1.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094,b-2.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094,b-3.exampleClusterName.abcde.c2.kafka.us-east-1.amazonaws.com:9094`. This attribute will have a value if `encryption_info.0.encryption_in_transit.0.client_broker` is set to `TLS_PLAINTEXT` or `TLS`. The resource sorts the list alphabetically. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_vpc_connectivity_sasl_iam` - A string containing one or more DNS names (or IP addresses) and SASL IAM port pairs for VPC connectivity. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_vpc_connectivity_sasl_scram` - A string containing one or more DNS names (or IP addresses) and SASL SCRAM port pairs for VPC connectivity. AWS may not always return all endpoints so the values may not be stable across applies.
* `bootstrap_brokers_vpc_connectivity_tls` - A string containing one or more DNS names (or IP addresses) and TLS port pairs for VPC connectivity. AWS may not always return all endpoints so the values may not be stable across applies.
* `cluster_uuid` - UUID of the MSK cluster, for use in IAM policies.
* `current_version` - Current version of the MSK Cluster used for updates, e.g., `K13V1IB3VIYZZH`
* `encryption_info.0.encryption_at_rest_kms_key_arn` - The ARN of the KMS key used for encryption at rest of the broker data volumes.
* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).
* `zookeeper_connect_string` - A comma separated list of one or more hostname:port pairs to use to connect to the Apache Zookeeper cluster. The returned values are sorted alphabetically. The AWS API may not return all endpoints, so this value is not guaranteed to be stable across applies.
* `zookeeper_connect_string_tls` - A comma separated list of one or more hostname:port pairs to use to connect to the Apache Zookeeper cluster via TLS. The returned values are sorted alphabetically. The AWS API may not return all endpoints, so this value is not guaranteed to be stable across applies.

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `120m`)
* `update` - (Default `120m`)
Note that the `update` timeout is used separately for `storage_info`, `instance_type`, `number_of_broker_nodes`, `configuration_info`, `kafka_version` and monitoring and logging update timeouts.
* `delete` - (Default `120m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import MSK clusters using the cluster `arn`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.msk_cluster import MskCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        MskCluster.generate_config_for_import(self, "example", "arn:aws:kafka:us-west-2:123456789012:cluster/example/279c0212-d057-4dba-9aa9-1c4e5a25bfc7-3")
```

Using `terraform import`, import MSK clusters using the cluster `arn`. For example:

```console
% terraform import aws_msk_cluster.example arn:aws:kafka:us-west-2:123456789012:cluster/example/279c0212-d057-4dba-9aa9-1c4e5a25bfc7-3
```

<!-- cache-key: cdktf-0.20.1 input-c8989fe83c9321b1629c7a505f58852b9ced96b6455e8404c0eb7b4f5b8f3426 -->