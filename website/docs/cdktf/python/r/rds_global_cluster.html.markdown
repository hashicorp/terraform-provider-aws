---
subcategory: "RDS (Relational Database)"
layout: "aws"
page_title: "AWS: aws_rds_global_cluster"
description: |-
  Manages an RDS Global Cluster
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_rds_global_cluster

Manages an RDS Global Cluster, which is an Aurora global database spread across multiple regions. The global database contains a single primary cluster with read-write capability, and a read-only secondary cluster that receives data from the primary cluster through high-speed replication performed by the Aurora storage subsystem.

More information about Aurora global databases can be found in the [Aurora User Guide](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html#aurora-global-database-creating).

## Example Usage

### New MySQL Global Cluster

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.rds_cluster import RdsCluster
from imports.aws.rds_cluster_instance import RdsClusterInstance
from imports.aws.rds_global_cluster import RdsGlobalCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = RdsGlobalCluster(self, "example",
            database_name="example_db",
            engine="aurora",
            engine_version="5.6.mysql_aurora.1.22.2",
            global_cluster_identifier="global-test"
        )
        primary = RdsCluster(self, "primary",
            cluster_identifier="test-primary-cluster",
            database_name="example_db",
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            global_cluster_identifier=example.id,
            master_password="somepass123",
            master_username="username",
            provider=aws_primary
        )
        aws_rds_cluster_instance_primary = RdsClusterInstance(self, "primary_2",
            cluster_identifier=primary.id,
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            identifier="test-primary-cluster-instance",
            instance_class="db.r4.large",
            provider=aws_primary
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_cluster_instance_primary.override_logical_id("primary")
        secondary = RdsCluster(self, "secondary",
            cluster_identifier="test-secondary-cluster",
            db_subnet_group_name="default",
            depends_on=[aws_rds_cluster_instance_primary],
            engine=example.engine,
            engine_version=example.engine_version,
            global_cluster_identifier=example.id,
            provider=aws_secondary
        )
        aws_rds_cluster_instance_secondary = RdsClusterInstance(self, "secondary_4",
            cluster_identifier=secondary.id,
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            identifier="test-secondary-cluster-instance",
            instance_class="db.r4.large",
            provider=aws_secondary
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_cluster_instance_secondary.override_logical_id("secondary")
```

### New PostgreSQL Global Cluster

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.provider import AwsProvider
from imports.aws.rds_cluster import RdsCluster
from imports.aws.rds_cluster_instance import RdsClusterInstance
from imports.aws.rds_global_cluster import RdsGlobalCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        primary = AwsProvider(self, "aws",
            alias="primary",
            region="us-east-2"
        )
        secondary = AwsProvider(self, "aws_1",
            alias="secondary",
            region="us-east-1"
        )
        example = RdsGlobalCluster(self, "example",
            database_name="example_db",
            engine="aurora-postgresql",
            engine_version="11.9",
            global_cluster_identifier="global-test"
        )
        aws_rds_cluster_primary = RdsCluster(self, "primary",
            cluster_identifier="test-primary-cluster",
            database_name="example_db",
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            global_cluster_identifier=example.id,
            master_password="somepass123",
            master_username="username",
            provider=primary
        )
        aws_rds_cluster_instance_primary = RdsClusterInstance(self, "primary_4",
            cluster_identifier=Token.as_string(aws_rds_cluster_primary.id),
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            identifier="test-primary-cluster-instance",
            instance_class="db.r4.large",
            provider=primary
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_cluster_instance_primary.override_logical_id("primary")
        aws_rds_cluster_secondary = RdsCluster(self, "secondary",
            cluster_identifier="test-secondary-cluster",
            db_subnet_group_name="default",
            depends_on=[aws_rds_cluster_instance_primary],
            engine=example.engine,
            engine_version=example.engine_version,
            global_cluster_identifier=example.id,
            provider=secondary,
            skip_final_snapshot=True
        )
        aws_rds_cluster_instance_secondary = RdsClusterInstance(self, "secondary_6",
            cluster_identifier=Token.as_string(aws_rds_cluster_secondary.id),
            db_subnet_group_name="default",
            engine=example.engine,
            engine_version=example.engine_version,
            identifier="test-secondary-cluster-instance",
            instance_class="db.r4.large",
            provider=secondary
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_cluster_instance_secondary.override_logical_id("secondary")
```

### New Global Cluster From Existing DB Cluster

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from cdktf import TerraformResourceLifecycle
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.rds_cluster import RdsCluster
from imports.aws.rds_global_cluster import RdsGlobalCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, engine):
        super().__init__(scope, name)
        example = RdsCluster(self, "example",
            lifecycle=TerraformResourceLifecycle(
                ignore_changes=[global_cluster_identifier]
            ),
            engine=engine
        )
        aws_rds_global_cluster_example = RdsGlobalCluster(self, "example_1",
            force_destroy=True,
            global_cluster_identifier="example",
            source_db_cluster_identifier=example.arn
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_global_cluster_example.override_logical_id("example")
```

### Upgrading Engine Versions

When you upgrade the version of an `aws_rds_global_cluster`, Terraform will attempt to in-place upgrade the engine versions of all associated clusters. Since the `aws_rds_cluster` resource is being updated through the `aws_rds_global_cluster`, you are likely to get an error (`Provider produced inconsistent final plan`). To avoid this, use the `lifecycle` `ignore_changes` meta argument as shown below on the `aws_rds_cluster`.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from cdktf import TerraformResourceLifecycle
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.rds_cluster import RdsCluster
from imports.aws.rds_cluster_instance import RdsClusterInstance
from imports.aws.rds_global_cluster import RdsGlobalCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = RdsGlobalCluster(self, "example",
            engine="aurora-mysql",
            engine_version="5.7.mysql_aurora.2.07.5",
            global_cluster_identifier="kyivkharkiv"
        )
        primary = RdsCluster(self, "primary",
            allow_major_version_upgrade=True,
            apply_immediately=True,
            cluster_identifier="odessadnipro",
            database_name="totoro",
            engine=example.engine,
            engine_version=example.engine_version,
            global_cluster_identifier=example.id,
            lifecycle=TerraformResourceLifecycle(
                ignore_changes=[engine_version]
            ),
            master_password="satsukimae",
            master_username="maesatsuki",
            skip_final_snapshot=True
        )
        aws_rds_cluster_instance_primary = RdsClusterInstance(self, "primary_2",
            apply_immediately=True,
            cluster_identifier=primary.id,
            engine=primary.engine,
            engine_version=primary.engine_version,
            identifier="donetsklviv",
            instance_class="db.r4.large"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_rds_cluster_instance_primary.override_logical_id("primary")
```

## Argument Reference

This resource supports the following arguments:

* `global_cluster_identifier` - (Required, Forces new resources) Global cluster identifier.
* `database_name` - (Optional, Forces new resources) Name for an automatically created database on cluster creation.
* `deletion_protection` - (Optional) If the Global Cluster should have deletion protection enabled. The database can't be deleted when this value is set to `true`. The default is `false`.
* `engine` - (Optional, Forces new resources) Name of the database engine to be used for this DB cluster. Terraform will only perform drift detection if a configuration value is provided. Valid values: `aurora`, `aurora-mysql`, `aurora-postgresql`. Defaults to `aurora`. Conflicts with `source_db_cluster_identifier`.
* `engine_version` - (Optional) Engine version of the Aurora global database. The `engine`, `engine_version`, and `instance_class` (on the `aws_rds_cluster_instance`) must together support global databases. See [Using Amazon Aurora global databases](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html) for more information. By upgrading the engine version, Terraform will upgrade cluster members. **NOTE:** To avoid an `inconsistent final plan` error while upgrading, use the `lifecycle` `ignore_changes` for `engine_version` meta argument on the associated `aws_rds_cluster` resource as shown above in [Upgrading Engine Versions](#upgrading-engine-versions) example.
* `force_destroy` - (Optional) Enable to remove DB Cluster members from Global Cluster on destroy. Required with `source_db_cluster_identifier`.
* `source_db_cluster_identifier` - (Optional) Amazon Resource Name (ARN) to use as the primary DB Cluster of the Global Cluster on creation. Terraform cannot perform drift detection of this value.
* `storage_encrypted` - (Optional, Forces new resources) Specifies whether the DB cluster is encrypted. The default is `false` unless `source_db_cluster_identifier` is specified and encrypted. Terraform will only perform drift detection if a configuration value is provided.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - RDS Global Cluster Amazon Resource Name (ARN)
* `global_cluster_members` - Set of objects containing Global Cluster members.
    * `db_cluster_arn` - Amazon Resource Name (ARN) of member DB Cluster
    * `is_writer` - Whether the member is the primary DB Cluster
* `global_cluster_resource_id` - AWS Region-unique, immutable identifier for the global database cluster. This identifier is found in AWS CloudTrail log entries whenever the AWS KMS key for the DB cluster is accessed
* `id` - RDS Global Cluster identifier

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

- `create` - (Default `30m`)
- `update` - (Default `90m`)
- `delete` - (Default `30m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import `aws_rds_global_cluster` using the RDS Global Cluster identifier. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
```

Using `terraform import`, import `aws_rds_global_cluster` using the RDS Global Cluster identifier. For example:

```console
% terraform import aws_rds_global_cluster.example example
```

Certain resource arguments, like `force_destroy`, only exist within Terraform. If the argument is set in the Terraform configuration on an imported resource, Terraform will show a difference on the first plan after import to update the state value. This change is safe to apply immediately so the state matches the desired configuration.

Certain resource arguments, like `source_db_cluster_identifier`, do not have an API method for reading the information after creation. If the argument is set in the Terraform configuration on an imported resource, Terraform will always show a difference. To workaround this behavior, either omit the argument from the Terraform configuration or use [`ignore_changes`](https://www.terraform.io/docs/configuration/meta-arguments/lifecycle.html#ignore_changes) to hide the difference. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from cdktf import TerraformResourceLifecycle
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.rds_global_cluster import RdsGlobalCluster
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, globalClusterIdentifier):
        super().__init__(scope, name)
        RdsGlobalCluster(self, "example",
            lifecycle=TerraformResourceLifecycle(
                ignore_changes=[source_db_cluster_identifier]
            ),
            global_cluster_identifier=global_cluster_identifier
        )
```

<!-- cache-key: cdktf-0.19.0 input-fa44dd874493ca45cccbd24a626a6b3f65869bfad4964390e5844ded01172f4f -->