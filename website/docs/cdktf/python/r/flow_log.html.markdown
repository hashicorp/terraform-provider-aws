---
subcategory: "VPC (Virtual Private Cloud)"
layout: "aws"
page_title: "AWS: aws_flow_log"
description: |-
  Provides a VPC/Subnet/ENI Flow Log
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_flow_log

Provides a VPC/Subnet/ENI/Transit Gateway/Transit Gateway Attachment Flow Log to capture IP traffic for a specific network
interface, subnet, or VPC. Logs are sent to a CloudWatch Log Group, a S3 Bucket, or Amazon Kinesis Data Firehose

## Example Usage

### CloudWatch Logging

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.flow_log import FlowLog
from imports.aws.iam_role import IamRole
from imports.aws.iam_role_policy import IamRolePolicy
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = CloudwatchLogGroup(self, "example",
            name="example"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["vpc-flow-logs.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        data_aws_iam_policy_document_example = DataAwsIamPolicyDocument(self, "example_2",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["logs:CreateLogGroup", "logs:CreateLogStream", "logs:PutLogEvents", "logs:DescribeLogGroups", "logs:DescribeLogStreams"
                ],
                effect="Allow",
                resources=["*"]
            )
            ]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_iam_policy_document_example.override_logical_id("example")
        aws_iam_role_example = IamRole(self, "example_3",
            assume_role_policy=Token.as_string(assume_role.json),
            name="example"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_example.override_logical_id("example")
        aws_iam_role_policy_example = IamRolePolicy(self, "example_4",
            name="example",
            policy=Token.as_string(data_aws_iam_policy_document_example.json),
            role=Token.as_string(aws_iam_role_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_policy_example.override_logical_id("example")
        aws_flow_log_example = FlowLog(self, "example_5",
            iam_role_arn=Token.as_string(aws_iam_role_example.arn),
            log_destination=example.arn,
            traffic_type="ALL",
            vpc_id=Token.as_string(aws_vpc_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_flow_log_example.override_logical_id("example")
```

### Amazon Kinesis Data Firehose logging

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.flow_log import FlowLog
from imports.aws.iam_role import IamRole
from imports.aws.iam_role_policy import IamRolePolicy
from imports.aws.kinesis_firehose_delivery_stream import KinesisFirehoseDeliveryStream
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_acl import S3BucketAcl
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = S3Bucket(self, "example",
            bucket="example"
        )
        aws_s3_bucket_acl_example = S3BucketAcl(self, "example_1",
            acl="private",
            bucket=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_s3_bucket_acl_example.override_logical_id("example")
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["firehose.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        data_aws_iam_policy_document_example = DataAwsIamPolicyDocument(self, "example_3",
            actions=["logs:CreateLogDelivery", "logs:DeleteLogDelivery", "logs:ListLogDeliveries", "logs:GetLogDelivery", "firehose:TagDeliveryStream"
            ],
            effect="Allow",
            resources=["*"]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_iam_policy_document_example.override_logical_id("example")
        aws_iam_role_example = IamRole(self, "example_4",
            assume_role_policy=Token.as_string(assume_role.json),
            name="firehose_test_role"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_example.override_logical_id("example")
        aws_iam_role_policy_example = IamRolePolicy(self, "example_5",
            name="test",
            policy=Token.as_string(data_aws_iam_policy_document_example.json),
            role=Token.as_string(aws_iam_role_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_policy_example.override_logical_id("example")
        aws_kinesis_firehose_delivery_stream_example =
        KinesisFirehoseDeliveryStream(self, "example_6",
            destination="extended_s3",
            extended_s3_configuration=KinesisFirehoseDeliveryStreamExtendedS3Configuration(
                bucket_arn=example.arn,
                role_arn=Token.as_string(aws_iam_role_example.arn)
            ),
            name="kinesis_firehose_test",
            tags={
                "LogDeliveryEnabled": "true"
            }
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_kinesis_firehose_delivery_stream_example.override_logical_id("example")
        aws_flow_log_example = FlowLog(self, "example_7",
            log_destination=Token.as_string(aws_kinesis_firehose_delivery_stream_example.arn),
            log_destination_type="kinesis-data-firehose",
            traffic_type="ALL",
            vpc_id=Token.as_string(aws_vpc_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_flow_log_example.override_logical_id("example")
```

### S3 Logging

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.flow_log import FlowLog
from imports.aws.s3_bucket import S3Bucket
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = S3Bucket(self, "example",
            bucket="example"
        )
        aws_flow_log_example = FlowLog(self, "example_1",
            log_destination=example.arn,
            log_destination_type="s3",
            traffic_type="ALL",
            vpc_id=Token.as_string(aws_vpc_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_flow_log_example.override_logical_id("example")
```

### S3 Logging in Apache Parquet format with per-hour partitions

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.flow_log import FlowLog
from imports.aws.s3_bucket import S3Bucket
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = S3Bucket(self, "example",
            bucket="example"
        )
        aws_flow_log_example = FlowLog(self, "example_1",
            destination_options=FlowLogDestinationOptions(
                file_format="parquet",
                per_hour_partition=True
            ),
            log_destination=example.arn,
            log_destination_type="s3",
            traffic_type="ALL",
            vpc_id=Token.as_string(aws_vpc_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_flow_log_example.override_logical_id("example")
```

## Argument Reference

~> **NOTE:** One of `eni_id`, `subnet_id`, `transit_gateway_id`, `transit_gateway_attachment_id`, or `vpc_id` must be specified.

This resource supports the following arguments:

* `traffic_type` - (Required) The type of traffic to capture. Valid values: `ACCEPT`,`REJECT`, `ALL`.
* `deliver_cross_account_role` - (Optional) ARN of the IAM role that allows Amazon EC2 to publish flow logs across accounts.
* `eni_id` - (Optional) Elastic Network Interface ID to attach to
* `iam_role_arn` - (Optional) The ARN for the IAM role that's used to post flow logs to a CloudWatch Logs log group
* `log_destination_type` - (Optional) The type of the logging destination. Valid values: `cloud-watch-logs`, `s3`, `kinesis-data-firehose`. Default: `cloud-watch-logs`.
* `log_destination` - (Optional) The ARN of the logging destination. Either `log_destination` or `log_group_name` must be set.
* `log_group_name` - (Optional) **Deprecated:** Use `log_destination` instead. The name of the CloudWatch log group. Either `log_group_name` or `log_destination` must be set.
* `subnet_id` - (Optional) Subnet ID to attach to
* `transit_gateway_id` - (Optional) Transit Gateway ID to attach to
* `transit_gateway_attachment_id` - (Optional) Transit Gateway Attachment ID to attach to
* `vpc_id` - (Optional) VPC ID to attach to
* `log_format` - (Optional) The fields to include in the flow log record. Accepted format example: `"$${interface-id} $${srcaddr} $${dstaddr} $${srcport} $${dstport}"`.
* `max_aggregation_interval` - (Optional) The maximum interval of time
  during which a flow of packets is captured and aggregated into a flow
  log record. Valid Values: `60` seconds (1 minute) or `600` seconds (10
  minutes). Default: `600`. When `transit_gateway_id` or `transit_gateway_attachment_id` is specified, `max_aggregation_interval` *must* be 60 seconds (1 minute).
* `destination_options` - (Optional) Describes the destination options for a flow log. More details below.
* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### destination_options

Describes the destination options for a flow log.

* `file_format` - (Optional) The format for the flow log. Default value: `plain-text`. Valid values: `plain-text`, `parquet`.
* `hive_compatible_partitions` - (Optional) Indicates whether to use Hive-compatible prefixes for flow logs stored in Amazon S3. Default value: `false`.
* `per_hour_partition` - (Optional) Indicates whether to partition the flow log per hour. This reduces the cost and response time for queries. Default value: `false`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - The Flow Log ID
* `arn` - The ARN of the Flow Log.
* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Flow Logs using the `id`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.flow_log import FlowLog
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        FlowLog.generate_config_for_import(self, "testFlowLog", "fl-1a2b3c4d")
```

Using `terraform import`, import Flow Logs using the `id`. For example:

```console
% terraform import aws_flow_log.test_flow_log fl-1a2b3c4d
```

<!-- cache-key: cdktf-0.20.1 input-2797f56a05abcc1992507bec694e30f058033f687a9d4a1c3b765cbb1123e5ee -->