---
subcategory: "Elasticsearch"
layout: "aws"
page_title: "AWS: aws_elasticsearch_domain"
description: |-
  Terraform resource for managing an AWS Elasticsearch Domain.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_elasticsearch_domain

Manages an AWS Elasticsearch Domain.

## Example Usage

### Basic Usage

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.elasticsearch_domain import ElasticsearchDomain
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        ElasticsearchDomain(self, "example",
            cluster_config=ElasticsearchDomainClusterConfig(
                instance_type="r4.large.elasticsearch"
            ),
            domain_name="example",
            elasticsearch_version="7.10",
            tags={
                "Domain": "TestDomain"
            }
        )
```

### Access Policy

-> See also: [`aws_elasticsearch_domain_policy` resource](/docs/providers/aws/r/elasticsearch_domain_policy.html)

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformVariable, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_caller_identity import DataAwsCallerIdentity
from imports.aws.data_aws_region import DataAwsRegion
from imports.aws.elasticsearch_domain import ElasticsearchDomain
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # Terraform Variables are not always the best fit for getting inputs in the context of Terraform CDK.
        #     You can read more about this at https://cdk.tf/variables
        domain = TerraformVariable(self, "domain",
            default="tf-test"
        )
        current = DataAwsCallerIdentity(self, "current")
        data_aws_region_current = DataAwsRegion(self, "current_2")
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_region_current.override_logical_id("current")
        ElasticsearchDomain(self, "example",
            access_policies="{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"es:*\",\n      \"Principal\": \"*\",\n      \"Effect\": \"Allow\",\n      \"Resource\": \"arn:aws:es:${" + data_aws_region_current.name + "}:${" + current.account_id + "}:domain/${" + domain.value + "}/*\",\n      \"Condition\": {\n        \"IpAddress\": {\"aws:SourceIp\": [\"66.193.100.22/32\"]}\n      }\n    }\n  ]\n}\n\n",
            domain_name=domain.string_value
        )
```

### Log Publishing to CloudWatch Logs

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.cloudwatch_log_resource_policy import CloudwatchLogResourcePolicy
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.elasticsearch_domain import ElasticsearchDomain
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name, *, domainName):
        super().__init__(scope, name)
        example = CloudwatchLogGroup(self, "example",
            name="example"
        )
        aws_elasticsearch_domain_example = ElasticsearchDomain(self, "example_1",
            log_publishing_options=[ElasticsearchDomainLogPublishingOptions(
                cloudwatch_log_group_arn=example.arn,
                log_type="INDEX_SLOW_LOGS"
            )
            ],
            domain_name=domain_name
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_elasticsearch_domain_example.override_logical_id("example")
        data_aws_iam_policy_document_example = DataAwsIamPolicyDocument(self, "example_2",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["logs:PutLogEvents", "logs:PutLogEventsBatch", "logs:CreateLogStream"
                ],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["es.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=["arn:aws:logs:*"]
            )
            ]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_iam_policy_document_example.override_logical_id("example")
        aws_cloudwatch_log_resource_policy_example =
        CloudwatchLogResourcePolicy(self, "example_3",
            policy_document=Token.as_string(data_aws_iam_policy_document_example.json),
            policy_name="example"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_cloudwatch_log_resource_policy_example.override_logical_id("example")
```

### VPC based ES

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformVariable, Token, Fn, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_caller_identity import DataAwsCallerIdentity
from imports.aws.data_aws_region import DataAwsRegion
from imports.aws.data_aws_subnets import DataAwsSubnets
from imports.aws.data_aws_vpc import DataAwsVpc
from imports.aws.elasticsearch_domain import ElasticsearchDomain
from imports.aws.iam_service_linked_role import IamServiceLinkedRole
from imports.aws.security_group import SecurityGroup
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # Terraform Variables are not always the best fit for getting inputs in the context of Terraform CDK.
        #     You can read more about this at https://cdk.tf/variables
        domain = TerraformVariable(self, "domain",
            default="tf-test"
        )
        vpc = TerraformVariable(self, "vpc")
        es = IamServiceLinkedRole(self, "es",
            aws_service_name="opensearchservice.amazonaws.com"
        )
        current = DataAwsCallerIdentity(self, "current")
        data_aws_region_current = DataAwsRegion(self, "current_4")
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_region_current.override_logical_id("current")
        selected = DataAwsVpc(self, "selected",
            tags={
                "Name": vpc.string_value
            }
        )
        aws_security_group_es = SecurityGroup(self, "es_6",
            description="Managed by Terraform",
            ingress=[SecurityGroupIngress(
                cidr_blocks=[Token.as_string(selected.cidr_block)],
                from_port=443,
                protocol="tcp",
                to_port=443
            )
            ],
            name="${" + vpc.value + "}-elasticsearch-${" + domain.value + "}",
            vpc_id=Token.as_string(selected.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_security_group_es.override_logical_id("es")
        data_aws_subnets_selected = DataAwsSubnets(self, "selected_7",
            filter=[DataAwsSubnetsFilter(
                name="vpc-id",
                values=[Token.as_string(selected.id)]
            )
            ],
            tags={
                "Tier": "private"
            }
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_subnets_selected.override_logical_id("selected")
        aws_elasticsearch_domain_es = ElasticsearchDomain(self, "es_8",
            access_policies="{\n\t\"Version\": \"2012-10-17\",\n\t\"Statement\": [\n\t\t{\n\t\t\t\"Action\": \"es:*\",\n\t\t\t\"Principal\": \"*\",\n\t\t\t\"Effect\": \"Allow\",\n\t\t\t\"Resource\": \"arn:aws:es:${" + data_aws_region_current.name + "}:${" + current.account_id + "}:domain/${" + domain.value + "}/*\"\n\t\t}\n\t]\n}\n\n",
            advanced_options={
                "rest.action.multi.allow_explicit_index": "true"
            },
            cluster_config=ElasticsearchDomainClusterConfig(
                instance_type="m4.large.elasticsearch",
                zone_awareness_enabled=True
            ),
            depends_on=[es],
            domain_name=domain.string_value,
            elasticsearch_version="6.3",
            tags={
                "Domain": "TestDomain"
            },
            vpc_options=ElasticsearchDomainVpcOptions(
                security_group_ids=[Token.as_string(aws_security_group_es.id)],
                subnet_ids=[
                    Token.as_string(Fn.lookup_nested(data_aws_subnets_selected.ids, ["0"])),
                    Token.as_string(Fn.lookup_nested(data_aws_subnets_selected.ids, ["1"]))
                ]
            )
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_elasticsearch_domain_es.override_logical_id("es")
```

## Argument Reference

The following arguments are required:

* `domain_name` - (Required) Name of the domain.

The following arguments are optional:

* `access_policies` - (Optional) IAM policy document specifying the access policies for the domain.
* `advanced_options` - (Optional) Key-value string pairs to specify advanced configuration options. Note that the values for these configuration options must be strings (wrapped in quotes) or they may be wrong and cause a perpetual diff, causing Terraform to want to recreate your Elasticsearch domain on every apply.
* `advanced_security_options` - (Optional) Configuration block for [fine-grained access control](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/fgac.html). Detailed below.
* `auto_tune_options` - (Optional) Configuration block for the Auto-Tune options of the domain. Detailed below.
* `cluster_config` - (Optional) Configuration block for the cluster of the domain. Detailed below.
* `cognito_options` - (Optional) Configuration block for authenticating Kibana with Cognito. Detailed below.
* `domain_endpoint_options` - (Optional) Configuration block for domain endpoint HTTP(S) related options. Detailed below.
* `ebs_options` - (Optional) Configuration block for EBS related options, may be required based on chosen [instance size](https://aws.amazon.com/elasticsearch-service/pricing/). Detailed below.
* `elasticsearch_version` - (Optional) Version of Elasticsearch to deploy. Defaults to `1.5`.
* `encrypt_at_rest` - (Optional) Configuration block for encrypt at rest options. Only available for [certain instance types](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/aes-supported-instance-types.html). Detailed below.
* `log_publishing_options` - (Optional) Configuration block for publishing slow and application logs to CloudWatch Logs. This block can be declared multiple times, for each log_type, within the same resource. Detailed below.
* `node_to_node_encryption` - (Optional) Configuration block for node-to-node encryption options. Detailed below.
* `snapshot_options` - (Optional) Configuration block for snapshot related options. Detailed below. DEPRECATED. For domains running Elasticsearch 5.3 and later, Amazon ES takes hourly automated snapshots, making this setting irrelevant. For domains running earlier versions of Elasticsearch, Amazon ES takes daily automated snapshots.
* `tags` - (Optional) Map of tags to assign to the resource. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.
* `vpc_options` - (Optional) Configuration block for VPC related options. Adding or removing this configuration forces a new resource ([documentation](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html#es-vpc-limitations)). Detailed below.

### advanced_security_options

* `enabled` - (Required, Forces new resource) Whether advanced security is enabled.
* `internal_user_database_enabled` - (Optional, Default: false) Whether the internal user database is enabled. If not set, defaults to `false` by the AWS API.
* `master_user_options` - (Optional) Configuration block for the main user. Detailed below.

#### master_user_options

* `master_user_arn` - (Optional) ARN for the main user. Only specify if `internal_user_database_enabled` is not set or set to `false`.
* `master_user_name` - (Optional) Main user's username, which is stored in the Amazon Elasticsearch Service domain's internal database. Only specify if `internal_user_database_enabled` is set to `true`.
* `master_user_password` - (Optional) Main user's password, which is stored in the Amazon Elasticsearch Service domain's internal database. Only specify if `internal_user_database_enabled` is set to `true`.

### auto_tune_options

* `desired_state` - (Required) The Auto-Tune desired state for the domain. Valid values: `ENABLED` or `DISABLED`.
* `maintenance_schedule` - (Required if `rollback_on_disable` is set to `DEFAULT_ROLLBACK`) Configuration block for Auto-Tune maintenance windows. Can be specified multiple times for each maintenance window. Detailed below.
* `rollback_on_disable` - (Optional) Whether to roll back to default Auto-Tune settings when disabling Auto-Tune. Valid values: `DEFAULT_ROLLBACK` or `NO_ROLLBACK`.

#### maintenance_schedule

* `start_at` - (Required) Date and time at which to start the Auto-Tune maintenance schedule in [RFC3339 format](https://tools.ietf.org/html/rfc3339#section-5.8).
* `duration` - (Required) Configuration block for the duration of the Auto-Tune maintenance window. Detailed below.
* `cron_expression_for_recurrence` - (Required) A cron expression specifying the recurrence pattern for an Auto-Tune maintenance schedule.

##### duration

* `value` - (Required) An integer specifying the value of the duration of an Auto-Tune maintenance window.
* `unit` - (Required) The unit of time specifying the duration of an Auto-Tune maintenance window. Valid values: `HOURS`.

### cluster_config

* `cold_storage_options` - (Optional) Configuration block containing cold storage configuration. Detailed below.
* `dedicated_master_count` - (Optional) Number of dedicated main nodes in the cluster.
* `dedicated_master_enabled` - (Optional) Whether dedicated main nodes are enabled for the cluster.
* `dedicated_master_type` - (Optional) Instance type of the dedicated main nodes in the cluster.
* `instance_count` - (Optional) Number of instances in the cluster.
* `instance_type` - (Optional) Instance type of data nodes in the cluster.
* `warm_count` - (Optional) Number of warm nodes in the cluster. Valid values are between `2` and `150`. `warm_count` can be only and must be set when `warm_enabled` is set to `true`.
* `warm_enabled` - (Optional) Whether to enable warm storage.
* `warm_type` - (Optional) Instance type for the Elasticsearch cluster's warm nodes. Valid values are `ultrawarm1.medium.elasticsearch`, `ultrawarm1.large.elasticsearch` and `ultrawarm1.xlarge.elasticsearch`. `warm_type` can be only and must be set when `warm_enabled` is set to `true`.
* `zone_awareness_config` - (Optional) Configuration block containing zone awareness settings. Detailed below.
* `zone_awareness_enabled` - (Optional) Whether zone awareness is enabled, set to `true` for multi-az deployment. To enable awareness with three Availability Zones, the `availability_zone_count` within the `zone_awareness_config` must be set to `3`.

#### cold_storage_options

* `enabled` - (Optional) Boolean to enable cold storage for an Elasticsearch domain. Defaults to `false`. Master and ultrawarm nodes must be enabled for cold storage.

#### zone_awareness_config

* `availability_zone_count` - (Optional) Number of Availability Zones for the domain to use with `zone_awareness_enabled`. Defaults to `2`. Valid values: `2` or `3`.

### cognito_options

AWS documentation: [Amazon Cognito Authentication for Kibana](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-cognito-auth.html)

* `enabled` - (Optional, Default: false) Whether Amazon Cognito authentication with Kibana is enabled or not.
* `identity_pool_id` - (Required) ID of the Cognito Identity Pool to use.
* `role_arn` - (Required) ARN of the IAM role that has the AmazonESCognitoAccess policy attached.
* `user_pool_id` - (Required) ID of the Cognito User Pool to use.

### domain_endpoint_options

* `custom_endpoint_certificate_arn` - (Optional) ACM certificate ARN for your custom endpoint.
* `custom_endpoint_enabled` - (Optional) Whether to enable custom endpoint for the Elasticsearch domain.
* `custom_endpoint` - (Optional) Fully qualified domain for your custom endpoint.
* `enforce_https` - (Optional) Whether or not to require HTTPS. Defaults to `true`.
* `tls_security_policy` - (Optional) Name of the TLS security policy that needs to be applied to the HTTPS endpoint. Valid values:  `Policy-Min-TLS-1-0-2019-07`, `Policy-Min-TLS-1-2-2019-07`, and `Policy-Min-TLS-1-2-PFS-2023-10`. Terraform will only perform drift detection if a configuration value is provided.

### ebs_options

* `ebs_enabled` - (Required) Whether EBS volumes are attached to data nodes in the domain.
* `iops` - (Optional) Baseline input/output (I/O) performance of EBS volumes attached to data nodes. Applicable only for the GP3 and Provisioned IOPS EBS volume types.
* `throughput` - (Required if `volume_type` is set to `gp3`) Specifies the throughput (in MiB/s) of the EBS volumes attached to data nodes. Applicable only for the gp3 volume type.
* `volume_size` - (Required if `ebs_enabled` is set to `true`.) Size of EBS volumes attached to data nodes (in GiB).
* `volume_type` - (Optional) Type of EBS volumes attached to data nodes.

### encrypt_at_rest

~> **Note:** You can enable `encrypt_at_rest` _in place_ for an existing, unencrypted domain only if your Elasticsearch version is 6.7 or greater. For lower versions, if you enable `encrypt_at_rest`, Terraform with recreate the domain, potentially causing data loss. For any version, if you disable `encrypt_at_rest` for an existing, encrypted domain, Terraform will recreate the domain, potentially causing data loss. If you change the `kms_key_id`, Terraform will also recreate the domain, potentially causing data loss.

* `enabled` - (Required) Whether to enable encryption at rest. If the `encrypt_at_rest` block is not provided then this defaults to `false`. Enabling encryption on new domains requires `elasticsearch_version` 5.1 or greater.
* `kms_key_id` - (Optional) KMS key ARN to encrypt the Elasticsearch domain with. If not specified then it defaults to using the `aws/es` service KMS key. Note that KMS will accept a KMS key ID but will return the key ARN. To prevent Terraform detecting unwanted changes, use the key ARN instead.

### log_publishing_options

* `cloudwatch_log_group_arn` - (Required) ARN of the Cloudwatch log group to which log needs to be published.
* `enabled` - (Optional, Default: true) Whether given log publishing option is enabled or not.
* `log_type` - (Required) Type of Elasticsearch log. Valid values: `INDEX_SLOW_LOGS`, `SEARCH_SLOW_LOGS`, `ES_APPLICATION_LOGS`, `AUDIT_LOGS`.

### node_to_node_encryption

~> **Note:** You can enable `node_to_node_encryption` _in place_ for an existing, unencrypted domain only if your Elasticsearch version is 6.7 or greater. For lower versions, if you enable `node_to_node_encryption`, Terraform will recreate the domain, potentially causing data loss. For any version, if you disable `node_to_node_encryption` for an existing, node-to-node encrypted domain, Terraform will recreate the domain, potentially causing data loss.

* `enabled` - (Required) Whether to enable node-to-node encryption. If the `node_to_node_encryption` block is not provided then this defaults to `false`. Enabling node-to-node encryption of a new domain requires an `elasticsearch_version` of `6.0` or greater.

### snapshot_options

* `automated_snapshot_start_hour` - (Required) Hour during which the service takes an automated daily snapshot of the indices in the domain.

### vpc_options

AWS documentation: [VPC Support for Amazon Elasticsearch Service Domains](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-vpc.html)

~> **Note:** You must have created the service linked role for the Elasticsearch service to use `vpc_options`. If you need to create the service linked role at the same time as the Elasticsearch domain then you must use `depends_on` to make sure that the role is created before the Elasticsearch domain. See the [VPC based ES domain example](#vpc-based-es) above.

-> Security Groups and Subnets referenced in these attributes must all be within the same VPC. This determines what VPC the endpoints are created in.

* `security_group_ids` - (Optional) List of VPC Security Group IDs to be applied to the Elasticsearch domain endpoints. If omitted, the default Security Group for the VPC will be used.
* `subnet_ids` - (Required) List of VPC Subnet IDs for the Elasticsearch domain endpoints to be created in.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN of the domain.
* `domain_id` - Unique identifier for the domain.
* `domain_name` - Name of the Elasticsearch domain.
* `endpoint` - Domain-specific endpoint used to submit index, search, and data upload requests.
* `kibana_endpoint` - Domain-specific endpoint for kibana without https scheme.
* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).
* `vpc_options.0.availability_zones` - If the domain was created inside a VPC, the names of the availability zones the configured `subnet_ids` were created inside.
* `vpc_options.0.vpc_id` - If the domain was created inside a VPC, the ID of the VPC.

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `60m`)
* `update` - (Default `60m`)
* `delete` - (Default `90m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Elasticsearch domains using the `domain_name`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.elasticsearch_domain import ElasticsearchDomain
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        ElasticsearchDomain.generate_config_for_import(self, "example", "domain_name")
```

Using `terraform import`, import Elasticsearch domains using the `domain_name`. For example:

```console
% terraform import aws_elasticsearch_domain.example domain_name
```

<!-- cache-key: cdktf-0.20.8 input-60dfcf11c5c8eac949444d5d799ae6ac9b5ba88c6982adad1d54ec9eee35c2b4 -->