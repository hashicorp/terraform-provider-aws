---
subcategory: "S3 (Simple Storage)"
layout: "aws"
page_title: "AWS: aws_s3_bucket_analytics_configuration"
description: |-
  Provides a S3 bucket analytics configuration resource.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_s3_bucket_analytics_configuration

Provides a S3 bucket [analytics configuration](https://docs.aws.amazon.com/AmazonS3/latest/dev/analytics-storage-class.html) resource.

-> This resource cannot be used with S3 directory buckets.

## Example Usage

### Add analytics configuration for entire S3 bucket and export results to a second S3 bucket

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_analytics_configuration import S3BucketAnalyticsConfiguration
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        analytics = S3Bucket(self, "analytics",
            bucket="analytics destination"
        )
        example = S3Bucket(self, "example",
            bucket="example"
        )
        S3BucketAnalyticsConfiguration(self, "example-entire-bucket",
            bucket=example.id,
            name="EntireBucket",
            storage_class_analysis=S3BucketAnalyticsConfigurationStorageClassAnalysis(
                data_export=S3BucketAnalyticsConfigurationStorageClassAnalysisDataExport(
                    destination=S3BucketAnalyticsConfigurationStorageClassAnalysisDataExportDestination(
                        s3_bucket_destination=S3BucketAnalyticsConfigurationStorageClassAnalysisDataExportDestinationS3BucketDestination(
                            bucket_arn=analytics.arn
                        )
                    )
                )
            )
        )
```

### Add analytics configuration with S3 object filter

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_analytics_configuration import S3BucketAnalyticsConfiguration
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = S3Bucket(self, "example",
            bucket="example"
        )
        S3BucketAnalyticsConfiguration(self, "example-filtered",
            bucket=example.id,
            filter=S3BucketAnalyticsConfigurationFilter(
                prefix="documents/",
                tags={
                    "class": "blue",
                    "priority": "high"
                }
            ),
            name="ImportantBlueDocuments"
        )
```

## Argument Reference

This resource supports the following arguments:

* `bucket` - (Required) Name of the bucket this analytics configuration is associated with.
* `name` - (Required) Unique identifier of the analytics configuration for the bucket.
* `filter` - (Optional) Object filtering that accepts a prefix, tags, or a logical AND of prefix and tags (documented below).
* `storage_class_analysis` - (Optional) Configuration for the analytics data export (documented below).

The `filter` configuration supports the following:

* `prefix` - (Optional) Object prefix for filtering.
* `tags` - (Optional) Set of object tags for filtering.

The `storage_class_analysis` configuration supports the following:

* `data_export` - (Required) Data export configuration (documented below).

The `data_export` configuration supports the following:

* `output_schema_version` - (Optional) Schema version of exported analytics data. Allowed values: `V_1`. Default value: `V_1`.
* `destination` - (Required) Specifies the destination for the exported analytics data (documented below).

The `destination` configuration supports the following:

* `s3_bucket_destination` - (Required) Analytics data export currently only supports an S3 bucket destination (documented below).

The `s3_bucket_destination` configuration supports the following:

* `bucket_arn` - (Required) ARN of the destination bucket.
* `bucket_account_id` - (Optional) Account ID that owns the destination bucket.
* `format` - (Optional) Output format of exported analytics data. Allowed values: `CSV`. Default value: `CSV`.
* `prefix` - (Optional) Prefix to append to exported analytics data.

## Attribute Reference

This resource exports no additional attributes.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import S3 bucket analytics configurations using `bucket:analytics`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.s3_bucket_analytics_configuration import S3BucketAnalyticsConfiguration
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        S3BucketAnalyticsConfiguration.generate_config_for_import(self, "myBucketEntireBucket", "my-bucket:EntireBucket")
```

Using `terraform import`, import S3 bucket analytics configurations using `bucket:analytics`. For example:

```console
% terraform import aws_s3_bucket_analytics_configuration.my-bucket-entire-bucket my-bucket:EntireBucket
```

<!-- cache-key: cdktf-0.20.1 input-2728c65e9310b798db450f104ac4301a6651e13ee77566ae83bf71307930d0dd -->