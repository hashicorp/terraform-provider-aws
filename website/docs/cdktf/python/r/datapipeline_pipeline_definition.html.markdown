---
subcategory: "Data Pipeline"
layout: "aws"
page_title: "AWS: aws_datapipeline_pipeline_definition"
description: |-
  Provides a DataPipeline Definition.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_datapipeline_pipeline_definition

Provides a DataPipeline Pipeline Definition resource.

## Example Usage

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.datapipeline_pipeline import DatapipelinePipeline
from imports.aws.datapipeline_pipeline_definition import DatapipelinePipelineDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        default_var = DatapipelinePipeline(self, "default",
            name="tf-pipeline-default"
        )
        DatapipelinePipelineDefinition(self, "example",
            pipeline_id=default_var.id,
            pipeline_object=[DatapipelinePipelineDefinitionPipelineObject(
                field=[DatapipelinePipelineDefinitionPipelineObjectField(
                    key="workerGroup",
                    string_value="workerGroup"
                )
                ],
                id="Default",
                name="Default"
            ), DatapipelinePipelineDefinitionPipelineObject(
                field=[DatapipelinePipelineDefinitionPipelineObjectField(
                    key="startDateTime",
                    string_value="2012-12-12T00:00:00"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="type",
                    string_value="Schedule"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="period",
                    string_value="1 hour"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="endDateTime",
                    string_value="2012-12-21T18:00:00"
                )
                ],
                id="Schedule",
                name="Schedule"
            ), DatapipelinePipelineDefinitionPipelineObject(
                field=[DatapipelinePipelineDefinitionPipelineObjectField(
                    key="type",
                    string_value="ShellCommandActivity"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="command",
                    string_value="echo hello"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="parent",
                    string_value="Default"
                ), DatapipelinePipelineDefinitionPipelineObjectField(
                    key="schedule",
                    string_value="Schedule"
                )
                ],
                id="SayHello",
                name="SayHello"
            )
            ]
        )
```

## Argument Reference

The following arguments are required:

* `pipeline_id` - (Required) ID of the pipeline.
* `pipeline_object` - (Required) Configuration block for the objects that define the pipeline. See below

The following arguments are optional:

* `parameter_object` - (Optional) Configuration block for the parameter objects used in the pipeline definition. See below
* `parameter_value` - (Optional) Configuration block for the parameter values used in the pipeline definition. See below

### `pipeline_object`

* `field` - (Required) Configuration block for Key-value pairs that define the properties of the object. See below
* `id` - (Required) ID of the object.
* `name` - (Required) ARN of the storage connector.

### `field`

* `key` - (Required) Field identifier.
* `ref_value` - (Optional) Field value, expressed as the identifier of another object
* `string_value` - (Optional) Field value, expressed as a String.

### `parameter_object`

* `attribute` - (Required) Configuration block for attributes of the parameter object. See below
* `id` - (Required) ID of the parameter object.

### `attribute`

* `key` - (Required) Field identifier.
* `string_value` - (Required) Field value, expressed as a String.

### `parameter_value`

* `id` - (Required) ID of the parameter value.
* `string_value` - (Required) Field value, expressed as a String.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - Unique ID of the datapipeline definition.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import `aws_datapipeline_pipeline_definition` using the id. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.datapipeline_pipeline_definition import DatapipelinePipelineDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        DatapipelinePipelineDefinition.generate_config_for_import(self, "example", "df-1234567890")
```

Using `terraform import`, import `aws_datapipeline_pipeline_definition` using the id. For example:

```console
% terraform import aws_datapipeline_pipeline_definition.example df-1234567890
```

<!-- cache-key: cdktf-0.20.1 input-513fb767241e4c9deb0e2e131aa76eae7629b4160098b9555deea889ccb98bd7 -->