---
subcategory: "BCM Data Exports"
layout: "aws"
page_title: "AWS: aws_bcmdataexports_export"
description: |-
  Terraform resource for managing an AWS BCM Data Exports Export.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_bcmdataexports_export

Terraform resource for managing an AWS BCM Data Exports Export.

## Example Usage

### Basic Usage

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.bcmdataexports_export import BcmdataexportsExport
from imports.aws.data_aws_caller_identity import DataAwsCallerIdentity
from imports.aws.data_aws_partition import DataAwsPartition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        current = DataAwsCallerIdentity(self, "current")
        data_aws_partition_current = DataAwsPartition(self, "current_1")
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_partition_current.override_logical_id("current")
        BcmdataexportsExport(self, "test",
            export=[BcmdataexportsExportExport(
                data_query=[BcmdataexportsExportExportDataQuery(
                    query_statement="SELECT identity_line_item_id, identity_time_interval, line_item_product_code,line_item_unblended_cost FROM COST_AND_USAGE_REPORT",
                    table_configurations={
                        "COST_AND_USAGE_REPORT": {
                            "BILLING_VIEW_ARN": "arn:${" + data_aws_partition_current.partition + "}:billing::${" + current.account_id + "}:billingview/primary",
                            "INCLUDE_MANUAL_DISCOUNT_COMPATIBILITY": "FALSE",
                            "INCLUDE_RESOURCES": "FALSE",
                            "INCLUDE_SPLIT_COST_ALLOCATION_DATA": "FALSE",
                            "TIME_GRANULARITY": "HOURLY"
                        }
                    }
                )
                ],
                destination_configurations=[BcmdataexportsExportExportDestinationConfigurations(
                    s3_destination=[BcmdataexportsExportExportDestinationConfigurationsS3Destination(
                        s3_bucket=Token.as_string(aws_s3_bucket_test.bucket),
                        s3_output_configurations=[BcmdataexportsExportExportDestinationConfigurationsS3DestinationS3OutputConfigurations(
                            compression="GZIP",
                            format="TEXT_OR_CSV",
                            output_type="CUSTOM",
                            overwrite="OVERWRITE_REPORT"
                        )
                        ],
                        s3_prefix=Token.as_string(aws_s3_bucket_test.bucket_prefix),
                        s3_region=Token.as_string(aws_s3_bucket_test.region)
                    )
                    ]
                )
                ],
                name="testexample",
                refresh_cadence=[BcmdataexportsExportExportRefreshCadence(
                    frequency="SYNCHRONOUS"
                )
                ]
            )
            ]
        )
```

## Argument Reference

The following arguments are required:

* `export` - (Required) The details of the export, including data query, name, description, and destination configuration.  See the [`export` argument reference](#export-argument-reference) below.

### `export` Argument Reference

* `data_query` - (Required) Data query for this specific data export. See the [`data_query` argument reference](#data_query-argument-reference) below.
* `destination_configurations` - (Required) Destination configuration for this specific data export. See the [`destination_configurations` argument reference](#destination_configurations-argument-reference) below.
* `name` - (Required) Name of this specific data export.
* `refresh_cadence` - (Required) Cadence for Amazon Web Services to update the export in your S3 bucket. See the [`refresh_cadence` argument reference](#refresh_cadence-argument-reference) below.
* `description` - (Optional) Description for this specific data export.

### `data_query` Argument Reference

* `query_statement` - (Required) Query statement. The SQL table name for CUR 2.0 is `COST_AND_USAGE_REPORT`. See the [AWS documentation](https://docs.aws.amazon.com/cur/latest/userguide/table-dictionary-cur2.html) for a list of available columns.
* `table_configurations` - (Optional) Table configuration. See the [AWS documentation](https://docs.aws.amazon.com/cur/latest/userguide/table-dictionary-cur2.html#cur2-table-configurations) for the available configurations. In addition to those listed in the documentation, `BILLING_VIEW_ARN` must also be included, as shown in the example above.

### `destination_configurations` Argument Reference

* `s3_destination` - (Required) Object that describes the destination of the data exports file. See the [`s3_destination` argument reference](#s3_destination-argument-reference) below.

### `s3_destination` Argument Reference

* `s3_bucket` - (Required) Name of the Amazon S3 bucket used as the destination of a data export file.
* `s3_output_configurations` - (Required) Output configuration for the data export. See the [`s3_output_configurations` argument reference](#s3_output_configurations-argument-reference) below.
* `s3_prefix` - (Required) S3 path prefix you want prepended to the name of your data export.
* `s3_region` - (Required) S3 bucket region.

### `s3_output_configurations` Argument Reference

* `compression` - (Required) Compression type for the data export. Valid values `GZIP`, `PARQUET`.
* `format` - (Required) File format for the data export. Valid values `TEXT_OR_CSV` or `PARQUET`.
* `output_type` - (Required) Output type for the data export. Valid value `CUSTOM`.
* `overwrite` - (Required) The rule to follow when generating a version of the data export file. You have the choice to overwrite the previous version or to be delivered in addition to the previous versions. Overwriting exports can save on Amazon S3 storage costs. Creating new export versions allows you to track the changes in cost and usage data over time. Valid values `CREATE_NEW_REPORT` or `OVERWRITE_REPORT`.

### `refresh_cadence` Argument Reference

* `frequency` - (Required) Frequency that data exports are updated. The export refreshes each time the source data updates, up to three times daily. Valid values `SYNCHRONOUS`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - Amazon Resource Name (ARN) for this export.
* `export[0].export_arn` - Amazon Resource Name (ARN) for this export.

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `30m`)
* `update` - (Default `30m`)

## Import

In Terraform v1.12.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `identity` attribute. For example:

```terraform
import {
  to = aws_bcmdataexports_export.example
  identity = {
    "arn" = "arn:aws:bcm-data-exports:us-east-1:123456789012:export/example-export"
  }
}

resource "aws_bcmdataexports_export" "example" {
  ### Configuration omitted for brevity ###
}
```

### Identity Schema

#### Required

- `arn` (String) Amazon Resource Name (ARN) of the BCM Data Exports export.

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import BCM Data Exports Export using the export ARN. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.bcmdataexports_export import BcmdataexportsExport
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        BcmdataexportsExport.generate_config_for_import(self, "example", "arn:aws:bcm-data-exports:us-east-1:123456789012:export/CostUsageReport-9f1c75f3-f982-4d9a-b936-1e7ecab814b7")
```

Using `terraform import`, import BCM Data Exports Export using the export ARN. For example:

```console
% terraform import aws_bcmdataexports_export.example arn:aws:bcm-data-exports:us-east-1:123456789012:export/CostUsageReport-9f1c75f3-f982-4d9a-b936-1e7ecab814b7
```

<!-- cache-key: cdktf-0.20.8 input-038fd0ca0bfd8a2b65e6caad433b1dbf6d39d770bb2ec2ce5fef6a1727ea1041 -->