---
subcategory: "Lambda"
layout: "aws"
page_title: "AWS: aws_lambda_function"
description: |-
  Manages an AWS Lambda Function.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_lambda_function

Manages an AWS Lambda Function. Use this resource to create serverless functions that run code in response to events without provisioning or managing servers.

For information about Lambda and how to use it, see [What is AWS Lambda?](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html). For a detailed example of setting up Lambda and API Gateway, see [Serverless Applications with AWS Lambda and API Gateway](https://learn.hashicorp.com/terraform/aws/lambda-api-gateway).

~> **Note:** Due to [AWS Lambda improved VPC networking changes that began deploying in September 2019](https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/), EC2 subnets and security groups associated with Lambda Functions can take up to 45 minutes to successfully delete. Terraform AWS Provider version 2.31.0 and later automatically handles this increased timeout, however prior versions require setting the customizable deletion timeouts of those Terraform resources to 45 minutes (`delete = "45m"`). AWS and HashiCorp are working together to reduce the amount of time required for resource deletion and updates can be tracked in this [GitHub issue](https://github.com/hashicorp/terraform-provider-aws/issues/10329).

~> **Note:** If you get a `KMSAccessDeniedException: Lambda was unable to decrypt the environment variables because KMS access was denied` error when invoking an `aws_lambda_function` with environment variables, the IAM role associated with the function may have been deleted and recreated after the function was created. You can fix the problem two ways: 1) updating the function's role to another role and then updating it back again to the recreated role, or 2) by using Terraform to `taint` the function and `apply` your configuration again to recreate the function. (When you create a function, Lambda grants permissions on the KMS key to the function's IAM role. If the IAM role is recreated, the grant is no longer valid. Changing the function's role or recreating the function causes Lambda to update the grant.)

-> **Tip:** To give an external source (like an EventBridge Rule, SNS, or S3) permission to access the Lambda function, use the [`aws_lambda_permission`](lambda_permission.html) resource. See [Lambda Permission Model](https://docs.aws.amazon.com/lambda/latest/dg/intro-permission-model.html) for more details. On the other hand, the `role` argument of this resource is the function's execution role for identity and access to AWS services and resources.

## Example Usage

### Basic Function with Node.js

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.archive.data_archive_file import DataArchiveFile
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # The following providers are missing schema information and might need manual adjustments to synthesize correctly: archive.
        #     For a more precise conversion please use the --provider flag in convert.
        example = DataArchiveFile(self, "example",
            output_path="${path.module}/lambda/function.zip",
            source_file="${path.module}/lambda/index.js",
            type="zip"
        )
        assume_role = DataAwsIamPolicyDocument(self, "assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["lambda.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        aws_iam_role_example = IamRole(self, "example_2",
            assume_role_policy=Token.as_string(assume_role.json),
            name="lambda_execution_role"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_example.override_logical_id("example")
        aws_lambda_function_example = LambdaFunction(self, "example_3",
            environment=LambdaFunctionEnvironment(
                variables={
                    "ENVIRONMENT": "production",
                    "LOG_LEVEL": "info"
                }
            ),
            filename=Token.as_string(example.output_path),
            function_name="example_lambda_function",
            handler="index.handler",
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x",
            source_code_hash=Token.as_string(example.output_base64_sha256),
            tags={
                "Application": "example",
                "Environment": "production"
            }
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_example.override_logical_id("example")
```

### Container Image Function

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        LambdaFunction(self, "example",
            architectures=["arm64"],
            function_name="example_container_function",
            image_config=LambdaFunctionImageConfig(
                command=["app.handler"],
                entry_point=["/lambda-entrypoint.sh"]
            ),
            image_uri="${" + aws_ecr_repository_example.repository_url + "}:latest",
            memory_size=512,
            package_type="Image",
            role=Token.as_string(aws_iam_role_example.arn),
            timeout=30
        )
```

### Function with Lambda Layers

~> **Note:** The `aws_lambda_layer_version` attribute values for `arn` and `layer_arn` were swapped in version 2.0.0 of the Terraform AWS Provider. For version 2.x, use `arn` references.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_layer_version import LambdaLayerVersion
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = LambdaLayerVersion(self, "example",
            compatible_architectures=["x86_64", "arm64"],
            compatible_runtimes=["nodejs20.x", "python3.12"],
            description="Common dependencies for Lambda functions",
            filename="layer.zip",
            layer_name="example_dependencies_layer"
        )
        aws_lambda_function_example = LambdaFunction(self, "example_1",
            filename="function.zip",
            function_name="example_layered_function",
            handler="index.handler",
            layers=[example.arn],
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x",
            tracing_config=LambdaFunctionTracingConfig(
                mode="Active"
            )
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_example.override_logical_id("example")
```

### VPC Function with Enhanced Networking

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        LambdaFunction(self, "example",
            ephemeral_storage=LambdaFunctionEphemeralStorage(
                size=5120
            ),
            filename="function.zip",
            function_name="example_vpc_function",
            handler="app.handler",
            memory_size=1024,
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="python3.12",
            snap_start=LambdaFunctionSnapStart(
                apply_on="PublishedVersions"
            ),
            timeout=30,
            vpc_config=LambdaFunctionVpcConfig(
                ipv6_allowed_for_dual_stack=True,
                security_group_ids=[example_lambda.id],
                subnet_ids=[example_private1.id, example_private2.id]
            )
        )
```

### Function with EFS Integration

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import VariableType, TerraformVariable, Fn, Token, TerraformCount, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.efs_access_point import EfsAccessPoint
from imports.aws.efs_file_system import EfsFileSystem
from imports.aws.efs_mount_target import EfsMountTarget
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # Terraform Variables are not always the best fit for getting inputs in the context of Terraform CDK.
        #     You can read more about this at https://cdk.tf/variables
        subnet_ids = TerraformVariable(self, "subnet_ids",
            default=["subnet-12345678", "subnet-87654321"],
            description="List of subnet IDs for EFS mount targets",
            type=VariableType.list(VariableType.STRING)
        )
        example = EfsFileSystem(self, "example",
            encrypted=True,
            tags={
                "Name": "lambda-efs"
            }
        )
        # In most cases loops should be handled in the programming language context and
        #     not inside of the Terraform context. If you are looping over something external, e.g. a variable or a file input
        #     you should consider using a for loop. If you are looping over something only known to Terraform, e.g. a result of a data source
        #     you need to keep this like it is.
        example_count = TerraformCount.of(
            Token.as_number(Fn.length_of(subnet_ids.value)))
        aws_efs_mount_target_example = EfsMountTarget(self, "example_2",
            file_system_id=example.id,
            security_groups=[efs.id],
            subnet_id=Token.as_string(
                Fn.lookup_nested(subnet_ids.value, [example_count.index])),
            count=example_count
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_efs_mount_target_example.override_logical_id("example")
        aws_efs_access_point_example = EfsAccessPoint(self, "example_3",
            file_system_id=example.id,
            posix_user=EfsAccessPointPosixUser(
                gid=1000,
                uid=1000
            ),
            root_directory=EfsAccessPointRootDirectory(
                creation_info=EfsAccessPointRootDirectoryCreationInfo(
                    owner_gid=1000,
                    owner_uid=1000,
                    permissions="755"
                ),
                path="/lambda"
            )
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_efs_access_point_example.override_logical_id("example")
        aws_lambda_function_example = LambdaFunction(self, "example_4",
            depends_on=[aws_efs_mount_target_example],
            file_system_config=LambdaFunctionFileSystemConfig(
                arn=Token.as_string(aws_efs_access_point_example.arn),
                local_mount_path="/mnt/data"
            ),
            filename="function.zip",
            function_name="example_efs_function",
            handler="index.handler",
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x",
            vpc_config=LambdaFunctionVpcConfig(
                security_group_ids=[lambda_.id],
                subnet_ids=subnet_ids.list_value
            )
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_example.override_logical_id("example")
```

### Function with Advanced Logging

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = CloudwatchLogGroup(self, "example",
            name="/aws/lambda/example_function",
            retention_in_days=14,
            tags={
                "Application": "example",
                "Environment": "production"
            }
        )
        aws_lambda_function_example = LambdaFunction(self, "example_1",
            depends_on=[example],
            filename="function.zip",
            function_name="example_function",
            handler="index.handler",
            logging_config=LambdaFunctionLoggingConfig(
                application_log_level="INFO",
                log_format="JSON",
                system_log_level="WARN"
            ),
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_example.override_logical_id("example")
```

### Function with logging to S3 or Data Firehose

#### Required Resources

* An S3 bucket or Data Firehose delivery stream to store the logs.
* A CloudWatch Log Group with:

    * `log_group_class = "DELIVERY"`
    * A subscription filter whose `destination_arn` points to the S3 bucket or the Data Firehose delivery stream.

* IAM roles:

    * Assumed by the `logs.amazonaws.com` service to deliver logs to the S3 bucket or Data Firehose delivery stream.
    * Assumed by the `lambda.amazonaws.com` service to send logs to CloudWatch Logs

* A Lambda function:

    * In the `logging_configuration`, specify the name of the Log Group created above using the `log_group` field
    * No special configuration is required to use S3 or Firehose as the log destination

For more details, see [Sending Lambda function logs to Amazon S3](https://docs.aws.amazon.com/lambda/latest/dg/logging-with-s3.html).

#### Example: Exporting Lambda Logs to S3 Bucket

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.cloudwatch_log_subscription_filter import CloudwatchLogSubscriptionFilter
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.iam_role_policy import IamRolePolicy
from imports.aws.lambda_function import LambdaFunction
from imports.aws.s3_bucket import S3Bucket
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        lambda_function_name = "lambda-log-export-example"
        export_var = CloudwatchLogGroup(self, "export",
            log_group_class="DELIVERY",
            name="/aws/lambda/${" + lambda_function_name + "}"
        )
        LambdaFunction(self, "log_export",
            depends_on=[export_var],
            filename="function.zip",
            function_name=lambda_function_name,
            handler="index.lambda_handler",
            logging_config=LambdaFunctionLoggingConfig(
                log_format="Text",
                log_group=export_var.name
            ),
            role=example.arn,
            runtime="python3.13"
        )
        lambda_log_export = S3Bucket(self, "lambda_log_export",
            bucket="${" + lambda_function_name + "}-bucket"
        )
        data_aws_iam_policy_document_lambda_log_export =
        DataAwsIamPolicyDocument(self, "lambda_log_export_3",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["s3:PutObject"],
                effect="Allow",
                resources=["${" + lambda_log_export.arn + "}/*"]
            )
            ]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_iam_policy_document_lambda_log_export.override_logical_id("lambda_log_export")
        logs_assume_role = DataAwsIamPolicyDocument(self, "logs_assume_role",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                effect="Allow",
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["logs.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        logs_log_export = IamRole(self, "logs_log_export",
            assume_role_policy=Token.as_string(logs_assume_role.json),
            name="${" + lambda_function_name + "}-lambda-log-export-role"
        )
        aws_iam_role_policy_lambda_log_export = IamRolePolicy(self, "lambda_log_export_6",
            policy=Token.as_string(data_aws_iam_policy_document_lambda_log_export.json),
            role=logs_log_export.name
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_policy_lambda_log_export.override_logical_id("lambda_log_export")
        aws_cloudwatch_log_subscription_filter_lambda_log_export =
        CloudwatchLogSubscriptionFilter(self, "lambda_log_export_7",
            destination_arn=lambda_log_export.arn,
            filter_pattern="",
            log_group_name=export_var.name,
            name="${" + lambda_function_name + "}-filter",
            role_arn=logs_log_export.arn
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_cloudwatch_log_subscription_filter_lambda_log_export.override_logical_id("lambda_log_export")
```

### Function with Error Handling

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lambda_function import LambdaFunction
from imports.aws.lambda_function_event_invoke_config import LambdaFunctionEventInvokeConfig
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = LambdaFunction(self, "example",
            dead_letter_config=LambdaFunctionDeadLetterConfig(
                target_arn=dlq.arn
            ),
            filename="function.zip",
            function_name="example_function",
            handler="index.handler",
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x"
        )
        aws_lambda_function_event_invoke_config_example =
        LambdaFunctionEventInvokeConfig(self, "example_1",
            destination_config=LambdaFunctionEventInvokeConfigDestinationConfig(
                on_failure=LambdaFunctionEventInvokeConfigDestinationConfigOnFailure(
                    destination=dlq.arn
                ),
                on_success=LambdaFunctionEventInvokeConfigDestinationConfigOnSuccess(
                    destination=success.arn
                )
            ),
            function_name=example.function_name,
            maximum_event_age_in_seconds=60,
            maximum_retry_attempts=2
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_event_invoke_config_example.override_logical_id("example")
```

### CloudWatch Logging and Permissions

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import VariableType, TerraformVariable, Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.cloudwatch_log_group import CloudwatchLogGroup
from imports.aws.iam_policy import IamPolicy
from imports.aws.iam_role import IamRole
from imports.aws.iam_role_policy_attachment import IamRolePolicyAttachment
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        # Terraform Variables are not always the best fit for getting inputs in the context of Terraform CDK.
        #     You can read more about this at https://cdk.tf/variables
        function_name = TerraformVariable(self, "function_name",
            default="example_function",
            description="Name of the Lambda function",
            type=VariableType.STRING
        )
        example = CloudwatchLogGroup(self, "example",
            name="/aws/lambda/${" + function_name.value + "}",
            retention_in_days=14,
            tags={
                "Environment": "production",
                "Function": function_name.string_value
            }
        )
        lambda_logging = IamPolicy(self, "lambda_logging",
            description="IAM policy for logging from Lambda",
            name="lambda_logging",
            path="/",
            policy=Token.as_string(
                Fn.jsonencode({
                    "Statement": [{
                        "Action": ["logs:CreateLogGroup", "logs:CreateLogStream", "logs:PutLogEvents"
                        ],
                        "Effect": "Allow",
                        "Resource": ["arn:aws:logs:*:*:*"]
                    }
                    ],
                    "Version": "2012-10-17"
                }))
        )
        aws_iam_role_example = IamRole(self, "example_3",
            assume_role_policy=Token.as_string(
                Fn.jsonencode({
                    "Statement": [{
                        "Action": "sts:AssumeRole",
                        "Effect": "Allow",
                        "Principal": {
                            "Service": "lambda.amazonaws.com"
                        }
                    }
                    ],
                    "Version": "2012-10-17"
                })),
            name="lambda_execution_role"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_iam_role_example.override_logical_id("example")
        lambda_logs = IamRolePolicyAttachment(self, "lambda_logs",
            policy_arn=lambda_logging.arn,
            role=Token.as_string(aws_iam_role_example.name)
        )
        aws_lambda_function_example = LambdaFunction(self, "example_5",
            depends_on=[lambda_logs, example],
            filename="function.zip",
            function_name=function_name.string_value,
            handler="index.handler",
            logging_config=LambdaFunctionLoggingConfig(
                application_log_level="INFO",
                log_format="JSON",
                system_log_level="WARN"
            ),
            role=Token.as_string(aws_iam_role_example.arn),
            runtime="nodejs20.x"
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_lambda_function_example.override_logical_id("example")
```

## Specifying the Deployment Package

AWS Lambda expects source code to be provided as a deployment package whose structure varies depending on which `runtime` is in use. See [Runtimes](https://docs.aws.amazon.com/lambda/latest/dg/API_CreateFunction.html#SSS-CreateFunction-request-Runtime) for the valid values of `runtime`. The expected structure of the deployment package can be found in [the AWS Lambda documentation for each runtime](https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html).

Once you have created your deployment package you can specify it either directly as a local file (using the `filename` argument) or indirectly via Amazon S3 (using the `s3_bucket`, `s3_key` and `s3_object_version` arguments). When providing the deployment package via S3 it may be useful to use [the `aws_s3_object` resource](s3_object.html) to upload it.

For larger deployment packages it is recommended by Amazon to upload via S3, since the S3 API has better support for uploading large files efficiently.

## Argument Reference

The following arguments are required:

* `function_name` - (Required) Unique name for your Lambda Function.
* `role` - (Required) ARN of the function's execution role. The role provides the function's identity and access to AWS services and resources.

The following arguments are optional:

* `architectures` - (Optional) Instruction set architecture for your Lambda function. Valid values are `["x86_64"]` and `["arm64"]`. Default is `["x86_64"]`. Removing this attribute, function's architecture stays the same.
* `code_signing_config_arn` - (Optional) ARN of a code-signing configuration to enable code signing for this function.
* `dead_letter_config` - (Optional) Configuration block for dead letter queue. [See below](#dead_letter_config-configuration-block).
* `description` - (Optional) Description of what your Lambda Function does.
* `environment` - (Optional) Configuration block for environment variables. [See below](#environment-configuration-block).
* `ephemeral_storage` - (Optional) Amount of ephemeral storage (`/tmp`) to allocate for the Lambda Function. [See below](#ephemeral_storage-configuration-block).
* `file_system_config` - (Optional) Configuration block for EFS file system. [See below](#file_system_config-configuration-block).
* `filename` - (Optional) Path to the function's deployment package within the local filesystem. Conflicts with `image_uri` and `s3_bucket`. One of `filename`, `image_uri`, or `s3_bucket` must be specified.
* `handler` - (Optional) Function entry point in your code. Required if `package_type` is `Zip`.
* `image_config` - (Optional) Container image configuration values. [See below](#image_config-configuration-block).
* `image_uri` - (Optional) ECR image URI containing the function's deployment package. Conflicts with `filename` and `s3_bucket`. One of `filename`, `image_uri`, or `s3_bucket` must be specified.
* `kms_key_arn` - (Optional) ARN of the AWS Key Management Service key used to encrypt environment variables. If not provided when environment variables are in use, AWS Lambda uses a default service key. If provided when environment variables are not in use, the AWS Lambda API does not save this configuration.
* `layers` - (Optional) List of Lambda Layer Version ARNs (maximum of 5) to attach to your Lambda Function.
* `logging_config` - (Optional) Configuration block for advanced logging settings. [See below](#logging_config-configuration-block).
* `memory_size` - (Optional) Amount of memory in MB your Lambda Function can use at runtime. Valid value between 128 MB to 10,240 MB (10 GB), in 1 MB increments. Defaults to 128.
* `package_type` - (Optional) Lambda deployment package type. Valid values are `Zip` and `Image`. Defaults to `Zip`.
* `publish` - (Optional) Whether to publish creation/change as new Lambda Function Version. Defaults to `false`.
* `region` - (Optional) Region where this resource will be [managed](https://docs.aws.amazon.com/general/latest/gr/rande.html#regional-endpoints). Defaults to the Region set in the [provider configuration](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#aws-configuration-reference).
* `replace_security_groups_on_destroy` - (Optional) Whether to replace the security groups on the function's VPC configuration prior to destruction. Default is `false`.
* `replacement_security_group_ids` - (Optional) List of security group IDs to assign to the function's VPC configuration prior to destruction. Required if `replace_security_groups_on_destroy` is `true`.
* `reserved_concurrent_executions` - (Optional) Amount of reserved concurrent executions for this lambda function. A value of `0` disables lambda from being triggered and `-1` removes any concurrency limitations. Defaults to Unreserved Concurrency Limits `-1`.
* `runtime` - (Optional) Identifier of the function's runtime. Required if `package_type` is `Zip`. See [Runtimes](https://docs.aws.amazon.com/lambda/latest/dg/API_CreateFunction.html#SSS-CreateFunction-request-Runtime) for valid values.
* `s3_bucket` - (Optional) S3 bucket location containing the function's deployment package. Conflicts with `filename` and `image_uri`. One of `filename`, `image_uri`, or `s3_bucket` must be specified.
* `s3_key` - (Optional) S3 key of an object containing the function's deployment package. Required if `s3_bucket` is set.
* `s3_object_version` - (Optional) Object version containing the function's deployment package. Conflicts with `filename` and `image_uri`.
* `skip_destroy` - (Optional) Whether to retain the old version of a previously deployed Lambda Layer. Default is `false`.
* `snap_start` - (Optional) Configuration block for snap start settings. [See below](#snap_start-configuration-block).
* `source_code_hash` - (Optional) Base64-encoded SHA256 hash of the package file. Used to trigger updates when source code changes.
* `source_kms_key_arn` - (Optional) ARN of the AWS Key Management Service key used to encrypt the function's `.zip` deployment package. Conflicts with `image_uri`.
* `tags` - (Optional) Key-value map of tags for the Lambda function. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.
* `timeout` - (Optional) Amount of time your Lambda Function has to run in seconds. Defaults to 3. Valid between 1 and 900.
* `tracing_config` - (Optional) Configuration block for X-Ray tracing. [See below](#tracing_config-configuration-block).
* `vpc_config` - (Optional) Configuration block for VPC. [See below](#vpc_config-configuration-block).

### dead_letter_config Configuration Block

* `target_arn` - (Required) ARN of an SNS topic or SQS queue to notify when an invocation fails.

### environment Configuration Block

* `variables` - (Optional) Map of environment variables available to your Lambda function during execution.

### ephemeral_storage Configuration Block

* `size` - (Required) Amount of ephemeral storage (`/tmp`) in MB. Valid between 512 MB and 10,240 MB (10 GB).

### file_system_config Configuration Block

* `arn` - (Required) ARN of the Amazon EFS Access Point.
* `local_mount_path` - (Required) Path where the function can access the file system. Must start with `/mnt/`.

### image_config Configuration Block

* `command` - (Optional) Parameters to pass to the container image.
* `entry_point` - (Optional) Entry point to your application.
* `working_directory` - (Optional) Working directory for the container image.

### logging_config Configuration Block

* `application_log_level` - (Optional) Detail level of application logs. Valid values: `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL`.
* `log_format` - (Required) Log format. Valid values: `Text`, `JSON`.
* `log_group` - (Optional) CloudWatch log group where logs are sent.
* `system_log_level` - (Optional) Detail level of Lambda platform logs. Valid values: `DEBUG`, `INFO`, `WARN`.

### snap_start Configuration Block

* `apply_on` - (Required) When to apply snap start optimization. Valid value: `PublishedVersions`.

### tracing_config Configuration Block

* `mode` - (Required) X-Ray tracing mode. Valid values: `Active`, `PassThrough`.

### vpc_config Configuration Block

~> **NOTE:** If `subnet_ids`, `security_group_ids` and `ipv6_allowed_for_dual_stack` are empty then `vpc_config` is considered to be empty or unset.

* `ipv6_allowed_for_dual_stack` - (Optional) Whether to allow outbound IPv6 traffic on VPC functions connected to dual-stack subnets. Default: `false`.
* `security_group_ids` - (Required) List of security group IDs associated with the Lambda function.
* `subnet_ids` - (Required) List of subnet IDs associated with the Lambda function.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN identifying your Lambda Function.
* `code_sha256` - Base64-encoded representation of raw SHA-256 sum of the zip file.
* `invoke_arn` - ARN to be used for invoking Lambda Function from API Gateway - to be used in [`aws_api_gateway_integration`](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_integration)'s `uri`.
* `last_modified` - Date this resource was last modified.
* `qualified_arn` - ARN identifying your Lambda Function Version (if versioning is enabled via `publish = true`).
* `qualified_invoke_arn` - Qualified ARN (ARN with lambda version number) to be used for invoking Lambda Function from API Gateway - to be used in [`aws_api_gateway_integration`](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_integration)'s `uri`.
* `signing_job_arn` - ARN of the signing job.
* `signing_profile_version_arn` - ARN of the signing profile version.
* `snap_start.optimization_status` - Optimization status of the snap start configuration. Valid values are `On` and `Off`.
* `source_code_size` - Size in bytes of the function .zip file.
* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).
* `version` - Latest published version of your Lambda Function.
* `vpc_config.vpc_id` - ID of the VPC.

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `10m`)
* `update` - (Default `10m`)
* `delete` - (Default `10m`)

## Import

In Terraform v1.12.0 and later, the [`import` block](https://developer.hashicorp.com/terraform/language/import) can be used with the `identity` attribute. For example:

```terraform
import {
  to = aws_lambda_function.example
  identity = {
    function_name = "example"
  }
}

resource "aws_lambda_function" "example" {
  ### Configuration omitted for brevity ###
}
```

### Identity Schema

#### Required

* `function_name` (String) Name of the Lambda function.

#### Optional

* `account_id` (String) AWS Account where this resource is managed.
* `region` (String) Region where this resource is managed.

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Lambda Functions using the `function_name`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.lambda_function import LambdaFunction
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        LambdaFunction.generate_config_for_import(self, "example", "example")
```

Using `terraform import`, import Lambda Functions using the `function_name`. For example:

```console
% terraform import aws_lambda_function.example example
```

<!-- cache-key: cdktf-0.20.8 input-f7ee325f11c59546f1e13ab7fc593a4066f6bcb79cf2c09f42d3b474f1cf35fd -->