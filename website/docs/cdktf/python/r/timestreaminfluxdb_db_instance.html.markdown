---
subcategory: "Timestream for InfluxDB"
layout: "aws"
page_title: "AWS: aws_timestreaminfluxdb_db_instance"
description: |-
  Terraform resource for managing an Amazon Timestream for InfluxDB Db Instance.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_timestreaminfluxdb_db_instance

Terraform resource for managing an Amazon Timestream for InfluxDB Db Instance.

## Example Usage

### Basic Usage

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        TimestreaminfluxdbDbInstance(self, "example",
            allocated_storage=20,
            bucket="example-bucket-name",
            db_instance_type="db.influx.medium",
            name="example-db-instance",
            organization="organization",
            password="example-password",
            username="admin",
            vpc_security_group_ids=[Token.as_string(aws_security_group_example.id)],
            vpc_subnet_ids=[exampleid]
        )
```

### Usage with Prerequisite Resources

All Timestream for InfluxDB instances require a VPC, subnet, and security group. The following example shows how these prerequisite resources can be created and used with `aws_timestreaminfluxdb_db_instance`.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.security_group import SecurityGroup
from imports.aws.subnet import Subnet
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
from imports.aws.vpc import Vpc
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = Vpc(self, "example",
            cidr_block="10.0.0.0/16"
        )
        aws_security_group_example = SecurityGroup(self, "example_1",
            name="example",
            vpc_id=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_security_group_example.override_logical_id("example")
        aws_subnet_example = Subnet(self, "example_2",
            cidr_block="10.0.1.0/24",
            vpc_id=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_subnet_example.override_logical_id("example")
        aws_timestreaminfluxdb_db_instance_example =
        TimestreaminfluxdbDbInstance(self, "example_3",
            allocated_storage=20,
            bucket="example-bucket-name",
            db_instance_type="db.influx.medium",
            name="example-db-instance",
            organization="organization",
            password="example-password",
            username="admin",
            vpc_security_group_ids=[Token.as_string(aws_security_group_example.id)],
            vpc_subnet_ids=[Token.as_string(aws_subnet_example.id)]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_timestreaminfluxdb_db_instance_example.override_logical_id("example")
```

### Usage with Public Internet Access Enabled

The following configuration shows how to define the necessary resources and arguments to allow public internet access on your Timestream for InfluxDB instance's endpoint on port `8086`. After applying this configuration, the instance's InfluxDB UI can be accessed by visiting your instance's endpoint at port `8086`.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, Op, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.internet_gateway import InternetGateway
from imports.aws.route import Route
from imports.aws.route_table_association import RouteTableAssociation
from imports.aws.security_group import SecurityGroup
from imports.aws.subnet import Subnet
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
from imports.aws.vpc import Vpc
from imports.aws.vpc_security_group_ingress_rule import VpcSecurityGroupIngressRule
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = Vpc(self, "example",
            cidr_block="10.0.0.0/16"
        )
        aws_internet_gateway_example = InternetGateway(self, "example_1",
            tags={
                "Name": "example"
            },
            vpc_id=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_internet_gateway_example.override_logical_id("example")
        Route(self, "test_route",
            destination_cidr_block="0.0.0.0/0",
            gateway_id=Token.as_string(aws_internet_gateway_example.id),
            route_table_id=example.main_route_table_id
        )
        RouteTableAssociation(self, "test_route_table_association",
            route_table_id=example.main_route_table_id,
            subnet_id=test_subnet.id
        )
        aws_security_group_example = SecurityGroup(self, "example_4",
            name="example",
            vpc_id=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_security_group_example.override_logical_id("example")
        aws_subnet_example = Subnet(self, "example_5",
            cidr_block="10.0.1.0/24",
            vpc_id=example.id
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_subnet_example.override_logical_id("example")
        aws_timestreaminfluxdb_db_instance_example =
        TimestreaminfluxdbDbInstance(self, "example_6",
            allocated_storage=20,
            bucket="example-bucket-name",
            db_instance_type="db.influx.medium",
            name="example-db-instance",
            organization="organization",
            password="example-password",
            publicly_accessible=True,
            username="admin",
            vpc_security_group_ids=[Token.as_string(aws_security_group_example.id)],
            vpc_subnet_ids=[Token.as_string(aws_subnet_example.id)]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_timestreaminfluxdb_db_instance_example.override_logical_id("example")
        aws_vpc_security_group_ingress_rule_example =
        VpcSecurityGroupIngressRule(self, "example_7",
            ip_protocol=Token.as_string(Op.negate(1)),
            referenced_security_group_id=Token.as_string(aws_security_group_example.id),
            security_group_id=Token.as_string(aws_security_group_example.id)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_vpc_security_group_ingress_rule_example.override_logical_id("example")
```

### Usage with S3 Log Delivery Enabled

You can use an S3 bucket to store logs generated by your Timestream for InfluxDB instance. The following example shows what resources and arguments are required to configure an S3 bucket for logging, including the IAM policy that needs to be set in order to allow Timestream for InfluxDB to place logs in your S3 bucket. The configuration of the required VPC, security group, and subnet have been left out of the example for brevity.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.s3_bucket import S3Bucket
from imports.aws.s3_bucket_policy import S3BucketPolicy
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example = S3Bucket(self, "example",
            bucket="example-s3-bucket"
        )
        aws_timestreaminfluxdb_db_instance_example =
        TimestreaminfluxdbDbInstance(self, "example_1",
            allocated_storage=20,
            bucket="example-bucket-name",
            db_instance_type="db.influx.medium",
            log_delivery_configuration=[TimestreaminfluxdbDbInstanceLogDeliveryConfiguration(
                s3_configuration=[TimestreaminfluxdbDbInstanceLogDeliveryConfigurationS3Configuration(
                    bucket_name=Token.as_string(example.name),
                    enabled=True
                )
                ]
            )
            ],
            name="example-db-instance",
            organization="organization",
            password="example-password",
            username="admin",
            vpc_security_group_ids=[Token.as_string(aws_security_group_example.id)],
            vpc_subnet_ids=[Token.as_string(aws_subnet_example.id)]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_timestreaminfluxdb_db_instance_example.override_logical_id("example")
        data_aws_iam_policy_document_example = DataAwsIamPolicyDocument(self, "example_2",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["s3:PutObject"],
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["timestream-influxdb.amazonaws.com"],
                    type="Service"
                )
                ],
                resources=["${" + example.arn + "}/*"]
            )
            ]
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        data_aws_iam_policy_document_example.override_logical_id("example")
        aws_s3_bucket_policy_example = S3BucketPolicy(self, "example_3",
            bucket=example.id,
            policy=Token.as_string(data_aws_iam_policy_document_example.json)
        )
        # This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.
        aws_s3_bucket_policy_example.override_logical_id("example")
```

### Usage with MultiAZ Deployment

To use multi-region availability, at least two subnets must be created in different availability zones and used with your Timestream for InfluxDB instance.

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.subnet import Subnet
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        example1 = Subnet(self, "example_1",
            availability_zone="us-west-2a",
            cidr_block="10.0.1.0/24",
            vpc_id=example.id
        )
        example2 = Subnet(self, "example_2",
            availability_zone="us-west-2b",
            cidr_block="10.0.2.0/24",
            vpc_id=example.id
        )
        TimestreaminfluxdbDbInstance(self, "example",
            allocated_storage=20,
            bucket="example-bucket-name",
            db_instance_type="db.influx.medium",
            deployment_type="WITH_MULTIAZ_STANDBY",
            name="example-db-instance",
            organization="organization",
            password="example-password",
            username="admin",
            vpc_security_group_ids=[Token.as_string(aws_security_group_example.id)],
            vpc_subnet_ids=[example1.id, example2.id]
        )
```

## Argument Reference

The following arguments are required:

* `allocated_storage` - (Required) Amount of storage in GiB (gibibytes). The minimum value is 20, the maximum value is 16384.
* `bucket` - (Required) Name of the initial InfluxDB bucket. All InfluxDB data is stored in a bucket. A bucket combines the concept of a database and a retention period (the duration of time that each data point persists). A bucket belongs to an organization. Along with `organization`, `username`, and `password`, this argument will be stored in the secret referred to by the `influx_auth_parameters_secret_arn` attribute.
* `db_instance_type` - (Required) Timestream for InfluxDB DB instance type to run InfluxDB on. Valid options are: `"db.influx.medium"`, `"db.influx.large"`, `"db.influx.xlarge"`, `"db.influx.2xlarge"`, `"db.influx.4xlarge"`, `"db.influx.8xlarge"`, `"db.influx.12xlarge"`, and `"db.influx.16xlarge"`.
* `name` - (Required) Name that uniquely identifies the DB instance when interacting with the Amazon Timestream for InfluxDB API and CLI commands. This name will also be a prefix included in the endpoint. DB instance names must be unique per customer and per region. The argument must start with a letter, cannot contain consecutive hyphens (`-`) and cannot end with a hyphen.
* `password` - (Required) Password of the initial admin user created in InfluxDB. This password will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `username`, and `organization`, this argument will be stored in the secret referred to by the `influx_auth_parameters_secret_arn` attribute.
* `organization` - (Required) Name of the initial organization for the initial admin user in InfluxDB. An InfluxDB organization is a workspace for a group of users. Along with `bucket`, `username`, and `password`, this argument will be stored in the secret referred to by the `influx_auth_parameters_secret_arn` attribute.
* `username` - (Required) Username of the initial admin user created in InfluxDB. Must start with a letter and can't end with a hyphen or contain two consecutive hyphens. This username will allow you to access the InfluxDB UI to perform various administrative tasks and also use the InfluxDB CLI to create an operator token. Along with `bucket`, `organization`, and `password`, this argument will be stored in the secret referred to by the `influx_auth_parameters_secret_arn` attribute.
* `vpc_security_group_ids` - (Required) List of VPC security group IDs to associate with the DB instance.
* `vpc_subnet_ids` - (Required) List of VPC subnet IDs to associate with the DB instance. Provide at least two VPC subnet IDs in different availability zones when deploying with a Multi-AZ standby.

The following arguments are optional:

* `db_parameter_group_identifier` - (Optional) ID of the DB parameter group assigned to your DB instance. If added to an existing Timestream for InfluxDB instance or given a new value, will cause an in-place update to the instance. However, if an instance already has a value for `db_parameter_group_identifier`, removing `db_parameter_group_identifier` will cause the instance to be destroyed and recreated.
* `db_storage_type` - (Default `"InfluxIOIncludedT1"`) Timestream for InfluxDB DB storage type to read and write InfluxDB data. You can choose between 3 different types of provisioned Influx IOPS included storage according to your workloads requirements: Influx IO Included 3000 IOPS, Influx IO Included 12000 IOPS, Influx IO Included 16000 IOPS. Valid options are: `"InfluxIOIncludedT1"`, `"InfluxIOIncludedT2"`, and `"InfluxIOIncludedT1"`. If you use `"InfluxIOIncludedT2" or "InfluxIOIncludedT3", the minimum value for `allocated_storage` is 400.
* `deployment_type` - (Default `"SINGLE_AZ"`) Specifies whether the DB instance will be deployed as a standalone instance or with a Multi-AZ standby for high availability. Valid options are: `"SINGLE_AZ"`, `"WITH_MULTIAZ_STANDBY"`.
* `log_delivery_configuration` - (Optional) Configuration for sending InfluxDB engine logs to a specified S3 bucket.
* `publicly_accessible` - (Default `false`) Configures the DB instance with a public IP to facilitate access. Other resources, such as a VPC, a subnet, an internet gateway, and a route table with routes, are also required to enabled public access, in addition to this argument. See "[Usage with Public Internet Access Enabled](#usage-with-public-internet-access-enabled)" for an example configuration with all required resources for public internet access.
* `tags` - (Optional) Map of tags assigned to the resource. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### Nested Fields

#### `log_delivery_configuration`

* `s3_configuration` - (Required) Configuration for S3 bucket log delivery.

#### `s3_configuration`

* `bucket_name` - (Required) Name of the S3 bucket to deliver logs to.
* `enabled` - (Required) Indicates whether log delivery to the S3 bucket is enabled.

**Note**: Only three arguments do updates in-place: `db_parameter_group_identifier`, `log_delivery_configuration`, and `tags`. Changes to any other argument after a DB instance has been deployed will cause destruction and re-creation of the DB instance. Additionally, when `db_parameter_group_identifier` is added to a DB instance or modified, the DB instance will be updated in-place but if `db_parameter_group_identifier` is removed from a DB instance, the DB instance will be destroyed and re-created.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN of the Timestream for InfluxDB Instance.
* `availability_zone` - Availability Zone in which the DB instance resides.
* `endpoint` - Endpoint used to connect to InfluxDB. The default InfluxDB port is 8086.
* `id` - ID of the Timestream for InfluxDB instance.
* `influx_auth_parameters_secret_arn` - ARN of the AWS Secrets Manager secret containing the initial InfluxDB authorization parameters. The secret value is a JSON formatted key-value pair holding InfluxDB authorization values: organization, bucket, username, and password. This secret will be read by the `aws_timestreaminfluxdb_db_instance` resource in order to support importing: deleting the secret or secret values can cause errors.
* `secondary_availability_zone` - Availability Zone in which the standby instance is located when deploying with a MultiAZ standby instance.
* `tags_all` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `30m`)
* `update` - (Default `30m`)
* `delete` - (Default `30m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Timestream for InfluxDB Db Instance using its identifier. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.timestreaminfluxdb_db_instance import TimestreaminfluxdbDbInstance
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        TimestreaminfluxdbDbInstance.generate_config_for_import(self, "example", "12345abcde")
```

Using `terraform import`, import Timestream for InfluxDB Db Instance using its identifier. For example:

```console
% terraform import aws_timestreaminfluxdb_db_instance.example 12345abcde
```

<!-- cache-key: cdktf-0.20.1 input-e7a4024a713ce39592a6e5abe74ddd27849a116450de48c1f638a5ee4d2a61c6 -->