---
subcategory: "Batch"
layout: "aws"
page_title: "AWS: aws_batch_job_definition"
description: |-
  Provides a Batch Job Definition resource.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_batch_job_definition

Provides a Batch Job Definition resource.

## Example Usage

### Job definition of type container

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.batch_job_definition import BatchJobDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        BatchJobDefinition(self, "test",
            container_properties=Token.as_string(
                Fn.jsonencode({
                    "command": ["ls", "-la"],
                    "environment": [{
                        "name": "VARNAME",
                        "value": "VARVAL"
                    }
                    ],
                    "image": "busybox",
                    "mount_points": [{
                        "container_path": "/tmp",
                        "read_only": False,
                        "source_volume": "tmp"
                    }
                    ],
                    "resource_requirements": [{
                        "type": "VCPU",
                        "value": "0.25"
                    }, {
                        "type": "MEMORY",
                        "value": "512"
                    }
                    ],
                    "ulimits": [{
                        "hard_limit": 1024,
                        "name": "nofile",
                        "soft_limit": 1024
                    }
                    ],
                    "volumes": [{
                        "host": {
                            "source_path": "/tmp"
                        },
                        "name": "tmp"
                    }
                    ]
                })),
            name="tf_test_batch_job_definition",
            type="container"
        )
```

### Job definition of type multinode

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Fn, Token, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.batch_job_definition import BatchJobDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        BatchJobDefinition(self, "test",
            name="tf_test_batch_job_definition_multinode",
            node_properties=Token.as_string(
                Fn.jsonencode({
                    "main_node": 0,
                    "node_range_properties": [{
                        "container": {
                            "command": ["ls", "-la"],
                            "image": "busybox",
                            "memory": 128,
                            "vcpus": 1
                        },
                        "target_nodes": "0:"
                    }, {
                        "container": {
                            "command": ["echo", "test"],
                            "image": "busybox",
                            "memory": 128,
                            "vcpus": 1
                        },
                        "target_nodes": "1:"
                    }
                    ],
                    "num_nodes": 2
                })),
            type="multinode"
        )
```

### Job Definitionn of type EKS

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.batch_job_definition import BatchJobDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        BatchJobDefinition(self, "test",
            eks_properties=BatchJobDefinitionEksProperties(
                pod_properties=BatchJobDefinitionEksPropertiesPodProperties(
                    containers=BatchJobDefinitionEksPropertiesPodPropertiesContainers(
                        command=["sleep", "60"],
                        image="public.ecr.aws/amazonlinux/amazonlinux:1",
                        resources=BatchJobDefinitionEksPropertiesPodPropertiesContainersResources(
                            limits={
                                "cpu": "1",
                                "memory": "1024Mi"
                            }
                        )
                    ),
                    host_network=True,
                    metadata=BatchJobDefinitionEksPropertiesPodPropertiesMetadata(
                        labels={
                            "environment": "test"
                        }
                    )
                )
            ),
            name=" tf_test_batch_job_definition_eks",
            type="container"
        )
```

### Fargate Platform Capability

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import Token, Fn, TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.batch_job_definition import BatchJobDefinition
from imports.aws.data_aws_iam_policy_document import DataAwsIamPolicyDocument
from imports.aws.iam_role import IamRole
from imports.aws.iam_role_policy_attachment import IamRolePolicyAttachment
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        assume_role_policy = DataAwsIamPolicyDocument(self, "assume_role_policy",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["ecs-tasks.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        ecs_task_execution_role = IamRole(self, "ecs_task_execution_role",
            assume_role_policy=Token.as_string(assume_role_policy.json),
            name="tf_test_batch_exec_role"
        )
        IamRolePolicyAttachment(self, "ecs_task_execution_role_policy",
            policy_arn="arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy",
            role=ecs_task_execution_role.name
        )
        BatchJobDefinition(self, "test",
            container_properties=Token.as_string(
                Fn.jsonencode({
                    "command": ["echo", "test"],
                    "execution_role_arn": ecs_task_execution_role.arn,
                    "fargate_platform_configuration": {
                        "platform_version": "LATEST"
                    },
                    "image": "busybox",
                    "job_role_arn": "arn:aws:iam::123456789012:role/AWSBatchS3ReadOnly",
                    "resource_requirements": [{
                        "type": "VCPU",
                        "value": "0.25"
                    }, {
                        "type": "MEMORY",
                        "value": "512"
                    }
                    ]
                })),
            name="tf_test_batch_job_definition",
            platform_capabilities=["FARGATE"],
            type="container"
        )
```

## Argument Reference

The following arguments are required:

* `name` - (Required) Specifies the name of the job definition.
* `type` - (Required) The type of job definition. Must be `container` or `multinode`.

The following arguments are optional:

* `container_properties` - (Optional) A valid [container properties](http://docs.aws.amazon.com/batch/latest/APIReference/API_RegisterJobDefinition.html) provided as a single valid JSON document. This parameter is only valid if the `type` parameter is `container`.
* `deregister_on_new_revision` - (Optional) When updating a job definition a new revision is created. This parameter determines if the previous version is `deregistered` (`INACTIVE`) or left  `ACTIVE`. Defaults to `true`.
* `node_properties` - (Optional) A valid [node properties](http://docs.aws.amazon.com/batch/latest/APIReference/API_RegisterJobDefinition.html) provided as a single valid JSON document. This parameter is required if the `type` parameter is `multinode`.
* `eks_properties` - (Optional) A valid [eks properties](#eks_properties). This parameter is only valid if the `type` parameter is `container`.
* `parameters` - (Optional) Specifies the parameter substitution placeholders to set in the job definition.
* `platform_capabilities` - (Optional) The platform capabilities required by the job definition. If no value is specified, it defaults to `EC2`. To run the job on Fargate resources, specify `FARGATE`.
* `propagate_tags` - (Optional) Specifies whether to propagate the tags from the job definition to the corresponding Amazon ECS task. Default is `false`.
* `retry_strategy` - (Optional) Specifies the retry strategy to use for failed jobs that are submitted with this job definition. Maximum number of `retry_strategy` is `1`.  Defined below.
* `scheduling_priority` - (Optional) The scheduling priority of the job definition. This only affects jobs in job queues with a fair share policy. Jobs with a higher scheduling priority are scheduled before jobs with a lower scheduling priority. Allowed values `0` through `9999`.
* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.
* `timeout` - (Optional) Specifies the timeout for jobs so that if a job runs longer, AWS Batch terminates the job. Maximum number of `timeout` is `1`. Defined below.

### `eks_properties`

* `pod_properties` - The properties for the Kubernetes pod resources of a job. See [`pod_properties`](#pod_properties) below.

### `pod_properties`

* `containers` - The properties of the container that's used on the Amazon EKS pod. See [containers](#containers) below.
* `dns_policy` - (Optional) The DNS policy for the pod. The default value is `ClusterFirst`. If the `host_network` argument is not specified, the default is `ClusterFirstWithHostNet`. `ClusterFirst` indicates that any DNS query that does not match the configured cluster domain suffix is forwarded to the upstream nameserver inherited from the node. For more information, see Pod's DNS policy in the Kubernetes documentation.
* `host_network` - (Optional) Indicates if the pod uses the hosts' network IP address. The default value is `true`. Setting this to `false` enables the Kubernetes pod networking model. Most AWS Batch workloads are egress-only and don't require the overhead of IP allocation for each pod for incoming connections.
* `metadata` - (Optional) Metadata about the Kubernetes pod.
* `service_account_name` - (Optional) The name of the service account that's used to run the pod.
* `volumes` - (Optional) Specifies the volumes for a job definition that uses Amazon EKS resources. AWS Batch supports [emptyDir](#eks_empty_dir), [hostPath](#eks_host_path), and [secret](#eks_secret) volume types.

### `containers`

* `image` - The Docker image used to start the container.
* `args` - An array of arguments to the entrypoint. If this isn't specified, the CMD of the container image is used. This corresponds to the args member in the Entrypoint portion of the Pod in Kubernetes. Environment variable references are expanded using the container's environment.
* `command` - The entrypoint for the container. This isn't run within a shell. If this isn't specified, the ENTRYPOINT of the container image is used. Environment variable references are expanded using the container's environment.
* `env` - The environment variables to pass to a container. See [EKS Environment](#eks_environment) below.
* `image_pull_policy` - The image pull policy for the container. Supported values are `Always`, `IfNotPresent`, and `Never`.
* `name` - The name of the container. If the name isn't specified, the default name "Default" is used. Each container in a pod must have a unique name.
* `resources` - The type and amount of resources to assign to a container. The supported resources include `memory`, `cpu`, and `nvidia.com/gpu`.
* `security_context` - The security context for a job.
* `volume_mounts` - The volume mounts for the container.

### `eks_environment`

* `name` - The name of the environment variable.
* `value` - The value of the environment variable.

### `eks_empty_dir`

* `medium` - (Optional) The medium to store the volume. The default value is an empty string, which uses the storage of the node.
* `size_limit` - The maximum size of the volume. By default, there's no maximum size defined.

### `eks_host_path`

* `path` - The path of the file or directory on the host to mount into containers on the pod.

### `eks_secret`

* `secret_name` - The name of the secret. The name must be allowed as a DNS subdomain name.
* `optional` - (Optional) Specifies whether the secret or the secret's keys must be defined.

### `retry_strategy`

* `attempts` - (Optional) The number of times to move a job to the `RUNNABLE` status. You may specify between `1` and `10` attempts.
* `evaluate_on_exit` - (Optional) The [evaluate on exit](#evaluate_on_exit) conditions under which the job should be retried or failed. If this parameter is specified, then the `attempts` parameter must also be specified. You may specify up to 5 configuration blocks.

#### `evaluate_on_exit`

* `action` - (Required) Specifies the action to take if all of the specified conditions are met. The values are not case sensitive. Valid values: `retry`, `exit`.
* `on_exit_code` - (Optional) A glob pattern to match against the decimal representation of the exit code returned for a job.
* `on_reason` - (Optional) A glob pattern to match against the reason returned for a job.
* `on_status_reason` - (Optional) A glob pattern to match against the status reason returned for a job.

### `timeout`

* `attempt_duration_seconds` - (Optional) The time duration in seconds after which AWS Batch terminates your jobs if they have not finished. The minimum value for the timeout is `60` seconds.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - The Amazon Resource Name of the job definition, includes revision (`:#`).
* `arn_prefix` - The ARN without the revision number.
* `revision` - The revision of the job definition.
* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Batch Job Definition using the `arn`. For example:

```python
# DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
from constructs import Construct
from cdktf import TerraformStack
#
# Provider bindings are generated by running `cdktf get`.
# See https://cdk.tf/provider-generation for more details.
#
from imports.aws.batch_job_definition import BatchJobDefinition
class MyConvertedCode(TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        BatchJobDefinition.generate_config_for_import(self, "test", "arn:aws:batch:us-east-1:123456789012:job-definition/sample")
```

Using `terraform import`, import Batch Job Definition using the `arn`. For example:

```console
% terraform import aws_batch_job_definition.test arn:aws:batch:us-east-1:123456789012:job-definition/sample
```

<!-- cache-key: cdktf-0.20.1 input-a601dba3c095da075f0b1e61565a10ccc796a5a15ab0385930fcb09cf34abb8c -->