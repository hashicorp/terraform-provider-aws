---
subcategory: "Data Pipeline"
layout: "aws"
page_title: "AWS: aws_datapipeline_pipeline_definition"
description: |-
  Provides a DataPipeline Definition.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_datapipeline_pipeline_definition

Provides a DataPipeline Pipeline Definition resource.

## Example Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { DatapipelinePipeline } from "./.gen/providers/aws/datapipeline-pipeline";
import { DatapipelinePipelineDefinition } from "./.gen/providers/aws/datapipeline-pipeline-definition";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const defaultVar = new DatapipelinePipeline(this, "default", {
      name: "tf-pipeline-default",
    });
    new DatapipelinePipelineDefinition(this, "example", {
      pipelineId: defaultVar.id,
      pipelineObject: [
        {
          field: [
            {
              key: "workerGroup",
              stringValue: "workerGroup",
            },
          ],
          id: "Default",
          name: "Default",
        },
        {
          field: [
            {
              key: "startDateTime",
              stringValue: "2012-12-12T00:00:00",
            },
            {
              key: "type",
              stringValue: "Schedule",
            },
            {
              key: "period",
              stringValue: "1 hour",
            },
            {
              key: "endDateTime",
              stringValue: "2012-12-21T18:00:00",
            },
          ],
          id: "Schedule",
          name: "Schedule",
        },
        {
          field: [
            {
              key: "type",
              stringValue: "ShellCommandActivity",
            },
            {
              key: "command",
              stringValue: "echo hello",
            },
            {
              key: "parent",
              stringValue: "Default",
            },
            {
              key: "schedule",
              stringValue: "Schedule",
            },
          ],
          id: "SayHello",
          name: "SayHello",
        },
      ],
    });
  }
}

```

## Argument Reference

The following arguments are required:

* `pipelineId` - (Required) ID of the pipeline.
* `pipelineObject` - (Required) Configuration block for the objects that define the pipeline. See below

The following arguments are optional:

* `parameterObject` - (Optional) Configuration block for the parameter objects used in the pipeline definition. See below
* `parameterValue` - (Optional) Configuration block for the parameter values used in the pipeline definition. See below

### `pipelineObject`

* `field` - (Required) Configuration block for Key-value pairs that define the properties of the object. See below
* `id` - (Required) ID of the object.
* `name` - (Required) ARN of the storage connector.

### `field`

* `key` - (Required) Field identifier.
* `refValue` - (Optional) Field value, expressed as the identifier of another object
* `stringValue` - (Optional) Field value, expressed as a String.

### `parameterObject`

* `attribute` - (Required) Configuration block for attributes of the parameter object. See below
* `id` - (Required) ID of the parameter object.

### `attribute`

* `key` - (Required) Field identifier.
* `stringValue` - (Required) Field value, expressed as a String.

### `parameterValue`

* `id` - (Required) ID of the parameter value.
* `stringValue` - (Required) Field value, expressed as a String.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - Unique ID of the datapipeline definition.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import `aws_datapipeline_pipeline_definition` using the id. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { DatapipelinePipelineDefinition } from "./.gen/providers/aws/datapipeline-pipeline-definition";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    DatapipelinePipelineDefinition.generateConfigForImport(
      this,
      "example",
      "df-1234567890"
    );
  }
}

```

Using `terraform import`, import `aws_datapipeline_pipeline_definition` using the id. For example:

```console
% terraform import aws_datapipeline_pipeline_definition.example df-1234567890
```

<!-- cache-key: cdktf-0.20.1 input-513fb767241e4c9deb0e2e131aa76eae7629b4160098b9555deea889ccb98bd7 -->