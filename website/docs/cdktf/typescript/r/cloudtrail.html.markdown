---
subcategory: "CloudTrail"
layout: "aws"
page_title: "AWS: aws_cloudtrail"
description: |-
  Provides a CloudTrail resource.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_cloudtrail

Provides a CloudTrail resource.

-> **Tip:** For a multi-region trail, this resource must be in the home region of the trail.

-> **Tip:** For an organization trail, this resource must be in the master account of the organization.

## Example Usage

### Basic

Enable CloudTrail to capture all compatible management events in region.
For capturing events from services like IAM, `includeGlobalServiceEvents` must be enabled.

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
import { DataAwsCallerIdentity } from "./.gen/providers/aws/data-aws-caller-identity";
import { DataAwsIamPolicyDocument } from "./.gen/providers/aws/data-aws-iam-policy-document";
import { DataAwsPartition } from "./.gen/providers/aws/data-aws-partition";
import { DataAwsRegion } from "./.gen/providers/aws/data-aws-region";
import { S3Bucket } from "./.gen/providers/aws/s3-bucket";
import { S3BucketPolicy } from "./.gen/providers/aws/s3-bucket-policy";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new S3Bucket(this, "example", {
      bucket: "tf-test-trail",
      forceDestroy: true,
    });
    const current = new DataAwsCallerIdentity(this, "current", {});
    const dataAwsPartitionCurrent = new DataAwsPartition(this, "current_2", {});
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsPartitionCurrent.overrideLogicalId("current");
    const dataAwsRegionCurrent = new DataAwsRegion(this, "current_3", {});
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsRegionCurrent.overrideLogicalId("current");
    const dataAwsIamPolicyDocumentExample = new DataAwsIamPolicyDocument(
      this,
      "example_4",
      {
        statement: [
          {
            actions: ["s3:GetBucketAcl"],
            condition: [
              {
                test: "StringEquals",
                values: [
                  "arn:${" +
                    dataAwsPartitionCurrent.partition +
                    "}:cloudtrail:${" +
                    dataAwsRegionCurrent.name +
                    "}:${" +
                    current.accountId +
                    "}:trail/example",
                ],
                variable: "aws:SourceArn",
              },
            ],
            effect: "Allow",
            principals: [
              {
                identifiers: ["cloudtrail.amazonaws.com"],
                type: "Service",
              },
            ],
            resources: [example.arn],
            sid: "AWSCloudTrailAclCheck",
          },
          {
            actions: ["s3:PutObject"],
            condition: [
              {
                test: "StringEquals",
                values: ["bucket-owner-full-control"],
                variable: "s3:x-amz-acl",
              },
              {
                test: "StringEquals",
                values: [
                  "arn:${" +
                    dataAwsPartitionCurrent.partition +
                    "}:cloudtrail:${" +
                    dataAwsRegionCurrent.name +
                    "}:${" +
                    current.accountId +
                    "}:trail/example",
                ],
                variable: "aws:SourceArn",
              },
            ],
            effect: "Allow",
            principals: [
              {
                identifiers: ["cloudtrail.amazonaws.com"],
                type: "Service",
              },
            ],
            resources: [
              "${" +
                example.arn +
                "}/prefix/AWSLogs/${" +
                current.accountId +
                "}/*",
            ],
            sid: "AWSCloudTrailWrite",
          },
        ],
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsIamPolicyDocumentExample.overrideLogicalId("example");
    const awsS3BucketPolicyExample = new S3BucketPolicy(this, "example_5", {
      bucket: example.id,
      policy: Token.asString(dataAwsIamPolicyDocumentExample.json),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsS3BucketPolicyExample.overrideLogicalId("example");
    const awsCloudtrailExample = new Cloudtrail(this, "example_6", {
      dependsOn: [awsS3BucketPolicyExample],
      includeGlobalServiceEvents: false,
      name: "example",
      s3BucketName: example.id,
      s3KeyPrefix: "prefix",
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsCloudtrailExample.overrideLogicalId("example");
  }
}

```

### Data Event Logging

CloudTrail can log [Data Events](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html) for certain services such as S3 objects and Lambda function invocations. Additional information about data event configuration can be found in the following links:

* [CloudTrail API DataResource documentation](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_DataResource.html) (for basic event selector).
* [CloudTrail API AdvancedFieldSelector documentation](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_AdvancedFieldSelector.html) (for advanced event selector).

#### Logging All Lambda Function Invocations By Using Basic Event Selectors

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    new Cloudtrail(this, "example", {
      eventSelector: [
        {
          dataResource: [
            {
              type: "AWS::Lambda::Function",
              values: ["arn:aws:lambda"],
            },
          ],
          includeManagementEvents: true,
          readWriteType: "All",
        },
      ],
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
  }
}

```

#### Logging All S3 Object Events By Using Basic Event Selectors

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    new Cloudtrail(this, "example", {
      eventSelector: [
        {
          dataResource: [
            {
              type: "AWS::S3::Object",
              values: ["arn:aws:s3"],
            },
          ],
          includeManagementEvents: true,
          readWriteType: "All",
        },
      ],
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
  }
}

```

#### Logging Individual S3 Bucket Events By Using Basic Event Selectors

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
import { DataAwsS3Bucket } from "./.gen/providers/aws/data-aws-s3-bucket";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    const importantBucket = new DataAwsS3Bucket(this, "important-bucket", {
      bucket: "important-bucket",
    });
    new Cloudtrail(this, "example", {
      eventSelector: [
        {
          dataResource: [
            {
              type: "AWS::S3::Object",
              values: ["${" + importantBucket.arn + "}/"],
            },
          ],
          includeManagementEvents: true,
          readWriteType: "All",
        },
      ],
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
  }
}

```

#### Logging All S3 Object Events Except For Two S3 Buckets By Using Advanced Event Selectors

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
import { DataAwsS3Bucket } from "./.gen/providers/aws/data-aws-s3-bucket";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    const notImportantBucket1 = new DataAwsS3Bucket(
      this,
      "not-important-bucket-1",
      {
        bucket: "not-important-bucket-1",
      }
    );
    const notImportantBucket2 = new DataAwsS3Bucket(
      this,
      "not-important-bucket-2",
      {
        bucket: "not-important-bucket-2",
      }
    );
    new Cloudtrail(this, "example", {
      advancedEventSelector: [
        {
          fieldSelector: [
            {
              equalTo: ["Data"],
              field: "eventCategory",
            },
            {
              field: "resources.ARN",
              notStartsWith: [
                "${" + notImportantBucket1.arn + "}/",
                "${" + notImportantBucket2.arn + "}/",
              ],
            },
            {
              equalTo: ["AWS::S3::Object"],
              field: "resources.type",
            },
          ],
          name: "Log all S3 objects events except for two S3 buckets",
        },
        {
          fieldSelector: [
            {
              equalTo: ["Management"],
              field: "eventCategory",
            },
          ],
          name: "Log readOnly and writeOnly management events",
        },
      ],
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
  }
}

```

#### Logging Individual S3 Buckets And Specific Event Names By Using Advanced Event Selectors

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
import { DataAwsS3Bucket } from "./.gen/providers/aws/data-aws-s3-bucket";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    const importantBucket1 = new DataAwsS3Bucket(this, "important-bucket-1", {
      bucket: "important-bucket-1",
    });
    const importantBucket2 = new DataAwsS3Bucket(this, "important-bucket-2", {
      bucket: "important-bucket-2",
    });
    const importantBucket3 = new DataAwsS3Bucket(this, "important-bucket-3", {
      bucket: "important-bucket-3",
    });
    new Cloudtrail(this, "example", {
      advancedEventSelector: [
        {
          fieldSelector: [
            {
              equalTo: ["Data"],
              field: "eventCategory",
            },
            {
              equalTo: ["PutObject", "DeleteObject"],
              field: "eventName",
            },
            {
              field: "resources.ARN",
              startsWith: [
                "${" + importantBucket1.arn + "}/",
                "${" + importantBucket2.arn + "}/",
              ],
            },
            {
              equalTo: ["false"],
              field: "readOnly",
            },
            {
              equalTo: ["AWS::S3::Object"],
              field: "resources.type",
            },
          ],
          name: "Log PutObject and DeleteObject events for two S3 buckets",
        },
        {
          fieldSelector: [
            {
              equalTo: ["Data"],
              field: "eventCategory",
            },
            {
              field: "eventName",
              startsWith: ["Delete"],
            },
            {
              equalTo: ["${" + importantBucket3.arn + "}/important-prefix"],
              field: "resources.ARN",
            },
            {
              equalTo: ["false"],
              field: "readOnly",
            },
            {
              equalTo: ["AWS::S3::Object"],
              field: "resources.type",
            },
          ],
          name: "Log Delete* events for one S3 bucket",
        },
      ],
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
  }
}

```

#### Sending Events to CloudWatch Logs

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
import { CloudwatchLogGroup } from "./.gen/providers/aws/cloudwatch-log-group";
interface MyConfig {
  name: any;
  s3BucketName: any;
}
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string, config: MyConfig) {
    super(scope, name);
    const example = new CloudwatchLogGroup(this, "example", {
      name: "Example",
    });
    const awsCloudtrailExample = new Cloudtrail(this, "example_1", {
      cloudWatchLogsGroupArn: "${" + example.arn + "}:*",
      name: config.name,
      s3BucketName: config.s3BucketName,
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsCloudtrailExample.overrideLogicalId("example");
  }
}

```

## Argument Reference

The following arguments are required:

* `name` - (Required) Name of the trail.
* `s3BucketName` - (Required) Name of the S3 bucket designated for publishing log files.

The following arguments are optional:

* `advancedEventSelector` - (Optional) Specifies an advanced event selector for enabling data event logging. Fields documented below. Conflicts with `eventSelector`.
* `cloudWatchLogsGroupArn` - (Optional) Log group name using an ARN that represents the log group to which CloudTrail logs will be delivered. Note that CloudTrail requires the Log Stream wildcard.
* `cloudWatchLogsRoleArn` - (Optional) Role for the CloudWatch Logs endpoint to assume to write to a userâ€™s log group.
* `enableLogFileValidation` - (Optional) Whether log file integrity validation is enabled. Defaults to `false`.
* `enableLogging` - (Optional) Enables logging for the trail. Defaults to `true`. Setting this to `false` will pause logging.
* `eventSelector` - (Optional) Specifies an event selector for enabling data event logging. Fields documented below. Please note the [CloudTrail limits](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/WhatIsCloudTrail-Limits.html) when configuring these. Conflicts with `advancedEventSelector`.
* `includeGlobalServiceEvents` - (Optional) Whether the trail is publishing events from global services such as IAM to the log files. Defaults to `true`.
* `insightSelector` - (Optional) Configuration block for identifying unusual operational activity. See details below.
* `isMultiRegionTrail` - (Optional) Whether the trail is created in the current region or in all regions. Defaults to `false`.
* `isOrganizationTrail` - (Optional) Whether the trail is an AWS Organizations trail. Organization trails log events for the master account and all member accounts. Can only be created in the organization master account. Defaults to `false`.
* `kmsKeyId` - (Optional) KMS key ARN to use to encrypt the logs delivered by CloudTrail.
* `s3KeyPrefix` - (Optional) S3 key prefix that follows the name of the bucket you have designated for log file delivery.
* `snsTopicName` - (Optional) Name of the Amazon SNS topic defined for notification of log file delivery.
* `tags` - (Optional) Map of tags to assign to the trail. If configured with a provider [`defaultTags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### event_selector

* `dataResource` - (Optional) Configuration block for data events. See details below.
* `excludeManagementEventSources` (Optional) -  A set of event sources to exclude. Valid values include: `kms.amazonaws.com` and `rdsdata.amazonaws.com`. `includeManagementEvents` must be set to`true` to allow this.
* `includeManagementEvents` - (Optional) Whether to include management events for your trail. Defaults to `true`.
* `readWriteType` - (Optional) Type of events to log. Valid values are `ReadOnly`, `WriteOnly`, `All`. Default value is `All`.

#### data_resource

* `type` - (Required) Resource type in which you want to log data events. You can specify only the following value: "AWS::S3::Object", "AWS::Lambda::Function" and "AWS::DynamoDB::Table".
* `values` - (Required) List of ARN strings or partial ARN strings to specify selectors for data audit events over data resources. ARN list is specific to single-valued `type`. For example, `arn:aws:s3:::<bucket name>/` for all objects in a bucket, `arn:aws:s3:::<bucket name>/key` for specific objects, `arn:aws:lambda` for all lambda events within an account, `arn:aws:lambda:<region>:<account number>:function:<function name>` for a specific Lambda function, `arn:aws:dynamodb` for all DDB events for all tables within an account, or `arn:aws:dynamodb:<region>:<account number>:table/<table name>` for a specific DynamoDB table.

### insight_selector

* `insightType` - (Optional) Type of insights to log on a trail. Valid values are: `ApiCallRateInsight` and `ApiErrorRateInsight`.

### Advanced Event Selector Arguments

* `fieldSelector` (Required) - Specifies the selector statements in an advanced event selector. Fields documented below.
* `name` (Optional) - Name of the advanced event selector.

#### Field Selector Arguments

* `field` (Required) - Field in an event record on which to filter events to be logged. You can specify only the following values: `readOnly`, `eventSource`, `eventName`, `eventCategory`, `resources.type`, `resources.ARN`.
* `endsWith` (Optional) - A list of values that includes events that match the last few characters of the event record field specified as the value of `field`.
* `equals` (Optional) - A list of values that includes events that match the exact value of the event record field specified as the value of `field`. This is the only valid operator that you can use with the `readOnly`, `eventCategory`, and `resources.type` fields.
* `notEndsWith` (Optional) - A list of values that excludes events that match the last few characters of the event record field specified as the value of `field`.
* `notEquals` (Optional) - A list of values that excludes events that match the exact value of the event record field specified as the value of `field`.
* `notStartsWith` (Optional) - A list of values that excludes events that match the first few characters of the event record field specified as the value of `field`.
* `startsWith` (Optional) - A list of values that includes events that match the first few characters of the event record field specified as the value of `field`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN of the trail.
* `homeRegion` - Region in which the trail was created.
* `id` - ARN of the trail.
* `tagsAll` - Map of tags assigned to the resource, including those inherited from the provider [`defaultTags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Cloudtrail Trails using the `arn`. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { Cloudtrail } from "./.gen/providers/aws/cloudtrail";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    Cloudtrail.generateConfigForImport(
      this,
      "sample",
      "arn:aws:cloudtrail:us-east-1:123456789012:trail/my-sample-trail"
    );
  }
}

```

Using `terraform import`, import Cloudtrails using the `arn`. For example:

```console
% terraform import aws_cloudtrail.sample arn:aws:cloudtrail:us-east-1:123456789012:trail/my-sample-trail
```

<!-- cache-key: cdktf-0.20.1 input-5ed397d637a150a8f46c866261ad00abfa51b67e2e83e6d4564b95a1f22de811 -->