---
subcategory: "AMP (Managed Prometheus)"
layout: "aws"
page_title: "AWS: aws_prometheus_scraper"
description: |-
  Manages an Amazon Managed Service for Prometheus (AMP) Scraper.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_prometheus_scraper

-> **Note:** If you change a Scraper's source (EKS cluster), Terraform
will delete the current Scraper and create a new one.

Provides an Amazon Managed Service for Prometheus fully managed collector
(scraper).

Read more in the [Amazon Managed Service for Prometheus user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector.html).

## Example Usage

### Basic Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, Fn, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { PrometheusScraper } from "./.gen/providers/aws/prometheus-scraper";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new PrometheusScraper(this, "example", {
      destination: [
        {
          amp: [
            {
              workspaceArn: Token.asString(awsPrometheusWorkspaceExample.arn),
            },
          ],
        },
      ],
      scrapeConfiguration:
        "global:\n  scrape_interval: 30s\nscrape_configs:\n  # pod metrics\n  - job_name: pod_exporter\n    kubernetes_sd_configs:\n      - role: pod\n  # container metrics\n  - job_name: cadvisor\n    scheme: https\n    authorization:\n      credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n    kubernetes_sd_configs:\n      - role: node\n    relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n      - replacement: kubernetes.default.svc:443\n        target_label: __address__\n      - source_labels: [__meta_kubernetes_node_name]\n        regex: (.+)\n        target_label: __metrics_path__\n        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n  # apiserver metrics\n  - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n    job_name: kubernetes-apiservers\n    kubernetes_sd_configs:\n    - role: endpoints\n    relabel_configs:\n    - action: keep\n      regex: default;kubernetes;https\n      source_labels:\n      - __meta_kubernetes_namespace\n      - __meta_kubernetes_service_name\n      - __meta_kubernetes_endpoint_port_name\n    scheme: https\n  # kube proxy metrics\n  - job_name: kube-proxy\n    honor_labels: true\n    kubernetes_sd_configs:\n    - role: pod\n    relabel_configs:\n    - action: keep\n      source_labels:\n      - __meta_kubernetes_namespace\n      - __meta_kubernetes_pod_name\n      separator: '/'\n      regex: 'kube-system/kube-proxy.+'\n    - source_labels:\n      - __address__\n      action: replace\n      target_label: __address__\n      regex: (.+?)(\\\\:\\\\d+)?\n      replacement: $1:10249\n\n",
      source: [
        {
          eks: [
            {
              clusterArn: Token.asString(dataAwsEksClusterExample.arn),
              subnetIds: Token.asList(
                Fn.lookupNested(dataAwsEksClusterExample.vpcConfig, [
                  "0",
                  "subnet_ids",
                ])
              ),
            },
          ],
        },
      ],
    });
  }
}

```

### Use default EKS scraper configuration

You can use the data source `aws_prometheus_scraper_configuration` to use a
service managed scrape configuration.

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, Fn, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { DataAwsPrometheusDefaultScraperConfiguration } from "./.gen/providers/aws/data-aws-prometheus-default-scraper-configuration";
import { PrometheusScraper } from "./.gen/providers/aws/prometheus-scraper";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new PrometheusScraper(this, "example", {
      destination: [
        {
          amp: [
            {
              workspaceArn: Token.asString(awsPrometheusWorkspaceExample.arn),
            },
          ],
        },
      ],
      scrapeConfiguration: Token.asString(
        dataAwsPrometheusScraperConfigurationExample.configuration
      ),
      source: [
        {
          eks: [
            {
              clusterArn: Token.asString(dataAwsEksClusterExample.arn),
              subnetIds: Token.asList(
                Fn.lookupNested(dataAwsEksClusterExample.vpcConfig, [
                  "0",
                  "subnet_ids",
                ])
              ),
            },
          ],
        },
      ],
    });
    const dataAwsPrometheusDefaultScraperConfigurationExample =
      new DataAwsPrometheusDefaultScraperConfiguration(this, "example_1", {});
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsPrometheusDefaultScraperConfigurationExample.overrideLogicalId(
      "example"
    );
  }
}

```

### Ignoring changes to Prometheus Workspace destination

A managed scraper will add a `AMPAgentlessScraper` tag to its Prometheus workspace
destination. To avoid Terraform state forcing removing the tag from the workspace,
you can add this tag to the destination workspace (preferred) or ignore tags
changes with `lifecycle`. See example below.

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, Fn, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { DataAwsEksCluster } from "./.gen/providers/aws/data-aws-eks-cluster";
import { PrometheusScraper } from "./.gen/providers/aws/prometheus-scraper";
import { PrometheusWorkspace } from "./.gen/providers/aws/prometheus-workspace";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new PrometheusWorkspace(this, "example", {
      tags: {
        AMPAgentlessScraper: "",
      },
    });
    new DataAwsEksCluster(this, "this", {
      name: "example",
    });
    const awsPrometheusScraperExample = new PrometheusScraper(
      this,
      "example_2",
      {
        destination: [
          {
            amp: [
              {
                workspaceArn: example.arn,
              },
            ],
          },
        ],
        scrapeConfiguration: "...",
        source: [
          {
            eks: [
              {
                clusterArn: Token.asString(dataAwsEksClusterExample.arn),
                subnetIds: Token.asList(
                  Fn.lookupNested(dataAwsEksClusterExample.vpcConfig, [
                    "0",
                    "subnet_ids",
                  ])
                ),
              },
            ],
          },
        ],
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsPrometheusScraperExample.overrideLogicalId("example");
  }
}

```

### Configure aws-auth

Your source Amazon EKS cluster must be configured to allow the scraper to access
metrics. Follow the [user guide](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-eks-setup)
to setup the appropriate Kubernetes permissions.

### Cross-Account Configuration

This setup allows the scraper, running in a source account, to remote write its collected metrics to a workspace in a target account. Note that:

- The target Role and target Workspace must be in the same account
- The source Scraper and target Workspace must be in the same Region

Follow [the AWS Best Practices guide](https://aws-observability.github.io/observability-best-practices/patterns/ampxa) to learn about the IAM roles configuration and overall setup.

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, Fn, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { PrometheusScraper } from "./.gen/providers/aws/prometheus-scraper";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new PrometheusScraper(this, "example", {
      destination: [
        {
          amp: [
            {
              workspaceArn: "<target_account_workspace_arn>",
            },
          ],
        },
      ],
      roleConfiguration: [
        {
          sourceRoleArn: source.arn,
          targetRoleArn: "arn:aws:iam::ACCOUNT-ID:role/target-role-name",
        },
      ],
      scrapeConfiguration: "...",
      source: [
        {
          eks: [
            {
              clusterArn: Token.asString(dataAwsEksClusterExample.arn),
              subnetIds: Token.asList(
                Fn.lookupNested(dataAwsEksClusterExample.vpcConfig, [
                  "0",
                  "subnet_ids",
                ])
              ),
            },
          ],
        },
      ],
    });
  }
}

```

## Argument Reference

The following arguments are required:

* `destination` - (Required) Configuration block for the managed scraper to send metrics to. See [`destination`](#destination).
* `scrapeConfiguration` - (Required) The configuration file to use in the new scraper. For more information, see [Scraper configuration](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-collector-how-to.html#AMP-collector-configuration).
* `source` - (Required) Configuration block to specify where the managed scraper will collect metrics from. See [`source`](#source).

The following arguments are optional:

* `alias` - (Optional) a name to associate with the managed scraper. This is for your use, and does not need to be unique.

* `roleConfiguration` - (Optional) Configuration block to enable writing to an Amazon Managed Service for Prometheus workspace in a different account. See [`roleConfiguration`](#role_configuration) below.

### `destination`

* `amp` - (Required) Configuration block for an Amazon Managed Prometheus workspace destination. See [`amp`](#amp).

### `amp`

* `workspaceArn` - (Required) The Amazon Resource Name (ARN) of the prometheus workspace.

### `source`

* `eks` - (Required) Configuration block for an EKS cluster source. See [`eks`](#eks).

#### `eks`

* `eksClusterArn` - (Required) The Amazon Resource Name (ARN) of the source EKS cluster.
* `subnetIds` - (Required) List of subnet IDs. Must be in at least two different availability zones.
* `securityGroupIds` - (Optional) List of the security group IDs for the Amazon EKS cluster VPC configuration.

### `roleConfiguration`

* `sourceRoleArn` - (Required) The Amazon Resource Name (ARN) of the source role configuration. Must be an IAM role ARN.
* `targetRoleArn` - (Required) The Amazon Resource Name (ARN) of the target role configuration. Must be an IAM role ARN.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - The Amazon Resource Name (ARN) of the new scraper.
* `roleArn` - The Amazon Resource Name (ARN) of the IAM role that provides permissions for the scraper to discover, collect, and produce metrics
* `status` - Status of the scraper. One of ACTIVE, CREATING, DELETING, CREATION_FAILED, DELETION_FAILED

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `30m`)
* `update` - (Default `2m`)
* `delete` - (Default `20m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import the Managed Scraper using the scraper
identifier. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { PrometheusScraper } from "./.gen/providers/aws/prometheus-scraper";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    PrometheusScraper.generateConfigForImport(
      this,
      "example",
      "s-0123abc-0000-0123-a000-000000000000"
    );
  }
}

```

Using `terraform import`, import the Managed Scraper using its identifier.
For example:

```console
% terraform import aws_prometheus_scraper.example s-0123abc-0000-0123-a000-000000000000
```

<!-- cache-key: cdktf-0.20.8 input-308e030908df024c72c6f06b9a8460963e8ab284b9de650ff8947d41912ef1d6 -->