---
subcategory: "EMR Containers"
layout: "aws"
page_title: "AWS: aws_emrcontainers_job_template"
description: |-
  Manages an EMR Containers (EMR on EKS) Job Template
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_emrcontainers_job_template

Manages an EMR Containers (EMR on EKS) Job Template.

## Example Usage

### Basic Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { EmrcontainersJobTemplate } from "./.gen/providers/aws/emrcontainers-job-template";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new EmrcontainersJobTemplate(this, "example", {
      jobTemplateData: {
        executionRoleArn: Token.asString(awsIamRoleExample.arn),
        jobDriver: {
          sparkSqlJobDriver: {
            entryPoint: "default",
          },
        },
        releaseLabel: "emr-6.10.0-latest",
      },
      name: "example",
    });
  }
}

```

## Argument Reference

The following arguments are required:

* `jobTemplateData` - (Required) The job template data which holds values of StartJobRun API request.
* `kmsKeyArn` - (Optional) The KMS key ARN used to encrypt the job template.
* `name` â€“ (Required) The specified name of the job template.
* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`defaultTags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### job_template_data Arguments

* `configurationOverrides` - (Optional) The configuration settings that are used to override defaults configuration.
* `executionRoleArn` - (Required) The execution role ARN of the job run.
* `jobDriver` - (Required) Specify the driver that the job runs on. Exactly one of the two available job drivers is required, either sparkSqlJobDriver or sparkSubmitJobDriver.
* `jobTags` - (Optional) The tags assigned to jobs started using the job template.
* `releaseLabel` - (Required) The release version of Amazon EMR.

#### configuration_overrides Arguments

* `applicationConfiguration` - (Optional) The configurations for the application running by the job run.
* `monitoringConfiguration` - (Optional) The configurations for monitoring.

##### application_configuration Arguments

* `classification` - (Required) The classification within a configuration.
* `configurations` - (Optional) A list of additional configurations to apply within a configuration object.
* `properties` - (Optional) A set of properties specified within a configuration classification.

##### monitoring_configuration Arguments

* `cloudWatchMonitoringConfiguration` - (Optional) Monitoring configurations for CloudWatch.
* `persistentAppUi` - (Optional)  Monitoring configurations for the persistent application UI.
* `s3MonitoringConfiguration` - (Optional) Amazon S3 configuration for monitoring log publishing.

###### cloud_watch_monitoring_configuration Arguments

* `logGroupName` - (Required) The name of the log group for log publishing.
* `logStreamNamePrefix` - (Optional) The specified name prefix for log streams.

###### s3_monitoring_configuration Arguments

* `logUri` - (Optional) Amazon S3 destination URI for log publishing.

#### job_driver Arguments

* `sparkSqlJobDriver` - (Optional) The job driver for job type.
* `sparkSubmitJobDriver` - (Optional) The job driver parameters specified for spark submit.

##### spark_sql_job_driver Arguments

* `entryPoint` - (Optional) The SQL file to be executed.
* `sparkSqlParameters` - (Optional) The Spark parameters to be included in the Spark SQL command.

##### spark_submit_job_driver Arguments

* `entryPoint` - (Required) The entry point of job application.
* `entryPointArguments` - (Optional) The arguments for job application.
* `sparkSubmitParameters` - (Optional) The Spark submit parameters that are used for job runs.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - ARN of the job template.
* `id` - The ID of the job template.
* `tagsAll` - Map of tags assigned to the resource, including those inherited from the provider [`defaultTags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import EKS job templates using the `id`. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { EmrcontainersJobTemplate } from "./.gen/providers/aws/emrcontainers-job-template";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    EmrcontainersJobTemplate.generateConfigForImport(
      this,
      "example",
      "a1b2c3d4e5f6g7h8i9j10k11l"
    );
  }
}

```

Using `terraform import`, import EKS job templates using the `id`. For example:

```console
% terraform import aws_emrcontainers_job_template.example a1b2c3d4e5f6g7h8i9j10k11l
```

<!-- cache-key: cdktf-0.20.1 input-40a45aaa72930deebb9754da5bddf771139ffc5f6fcddde32b7b2b44ae90f112 -->