---
subcategory: "FinSpace"
layout: "aws"
page_title: "AWS: aws_finspace_kx_cluster"
description: |-
  Terraform resource for managing an AWS FinSpace Kx Cluster.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_finspace_kx_cluster

Terraform resource for managing an AWS FinSpace Kx Cluster.

## Example Usage

### Basic Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { FinspaceKxCluster } from "./.gen/providers/aws/finspace-kx-cluster";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new FinspaceKxCluster(this, "example", {
      availabilityZoneId: "use1-az2",
      azMode: "SINGLE",
      cacheStorageConfigurations: [
        {
          size: 1200,
          type: "CACHE_1000",
        },
      ],
      capacityConfiguration: {
        nodeCount: 2,
        nodeType: "kx.s.2xlarge",
      },
      code: {
        s3Bucket: test.id,
        s3Key: object.key,
      },
      database: [
        {
          cache_configuration: [
            {
              cache_type: "CACHE_1000",
              db_paths: "/",
            },
          ],
          databaseName: Token.asString(awsFinspaceKxDatabaseExample.name),
        },
      ],
      environmentId: Token.asString(awsFinspaceKxEnvironmentExample.id),
      name: "my-tf-kx-cluster",
      releaseLabel: "1.0",
      type: "HDB",
      vpcConfiguration: {
        ipAddressType: "IP_V4",
        securityGroupIds: [Token.asString(awsSecurityGroupExample.id)],
        subnetIds: [Token.asString(awsSubnetExample.id)],
        vpcId: Token.asString(awsVpcTest.id),
      },
    });
  }
}

```

## Argument Reference

The following arguments are required:

* `azMode` - (Required) The number of availability zones you want to assign per cluster. This can be one of the following:
    * SINGLE - Assigns one availability zone per cluster.
    * MULTI - Assigns all the availability zones per cluster.
* `capacityConfiguration` - (Required) Structure for the metadata of a cluster. Includes information like the CPUs needed, memory of instances, and number of instances. See [capacity_configuration](#capacity_configuration).
* `environmentId` - (Required) Unique identifier for the KX environment.
* `name` - (Required) Unique name for the cluster that you want to create.
* `releaseLabel` - (Required) Version of FinSpace Managed kdb to run.
* `type` - (Required) Type of KDB database. The following types are available:
    * HDB - Historical Database. The data is only accessible with read-only permissions from one of the FinSpace managed KX databases mounted to the cluster.
    * RDB - Realtime Database. This type of database captures all the data from a ticker plant and stores it in memory until the end of day, after which it writes all of its data to a disk and reloads the HDB. This cluster type requires local storage for temporary storage of data during the savedown process. If you specify this field in your request, you must provide the `savedownStorageConfiguration` parameter.
    * GATEWAY - A gateway cluster allows you to access data across processes in kdb systems. It allows you to create your own routing logic using the initialization scripts and custom code. This type of cluster does not require a  writable local storage.
* `vpcConfiguration` - (Required) Configuration details about the network where the Privatelink endpoint of the cluster resides. See [vpc_configuration](#vpc_configuration).

The following arguments are optional:

* `autoScalingConfiguration` - (Optional) Configuration based on which FinSpace will scale in or scale out nodes in your cluster. See [auto_scaling_configuration](#auto_scaling_configuration).
* `availabilityZoneId` - (Optional) The availability zone identifiers for the requested regions. Required when `az_mode` is set to SINGLE.
* `cacheStorageConfigurations` - (Optional) Configurations for a read only cache storage associated with a cluster. This cache will be stored as an FSx Lustre that reads from the S3 store. See [cache_storage_configuration](#cache_storage_configuration).
* `code` - (Optional) Details of the custom code that you want to use inside a cluster when analyzing data. Consists of the S3 source bucket, location, object version, and the relative path from where the custom code is loaded into the cluster. See [code](#code).
* `commandLineArguments` - (Optional) List of key-value pairs to make available inside the cluster.
* `database` - (Optional) KX database that will be available for querying. Defined below.
* `description` - (Optional) Description of the cluster.
* `executionRole` - (Optional) An IAM role that defines a set of permissions associated with a cluster. These permissions are assumed when a cluster attempts to access another cluster.
* `initializationScript` - (Optional) Path to Q program that will be run at launch of a cluster. This is a relative path within .zip file that contains the custom code, which will be loaded on the cluster. It must include the file name itself. For example, somedir/init.q.
* `savedownStorageConfiguration` - (Optional) Size and type of the temporary storage that is used to hold data during the savedown process. This parameter is required when you choose `type` as RDB. All the data written to this storage space is lost when the cluster node is restarted. See [savedown_storage_configuration](#savedown_storage_configuration).
* `tags` - (Optional) Key-value mapping of resource tags. If configured with a provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### auto_scaling_configuration

The auto_scaling_configuration block supports the following arguments:

* `autoScalingMetric` - (Required) Metric your cluster will track in order to scale in and out. For example, CPU_UTILIZATION_PERCENTAGE is the average CPU usage across all nodes in a cluster.
* `minNodeCount` - (Required) Lowest number of nodes to scale. Must be at least 1 and less than the `max_node_count`. If nodes in cluster belong to multiple availability zones, then `min_node_count` must be at least 3.
* `maxNodeCount` - (Required) Highest number of nodes to scale. Cannot be greater than 5
* `metricTarget` - (Required) Desired value of chosen `auto_scaling_metric`. When metric drops below this value, cluster will scale in. When metric goes above this value, cluster will scale out. Can be set between 0 and 100 percent.
* `scaleInCooldownSeconds` - (Required) Duration in seconds that FinSpace will wait after a scale in event before initiating another scaling event.
* `scaleOutCooldownSeconds` - (Required) Duration in seconds that FinSpace will wait after a scale out event before initiating another scaling event.

### capacity_configuration

The capacity_configuration block supports the following arguments:

* `nodeType` - (Required) Determines the hardware of the host computer used for your cluster instance. Each node type offers different memory and storage capabilities. Choose a node type based on the requirements of the application or software that you plan to run on your instance.
  
  You can only specify one of the following values:
    * kx.s.large – The node type with a configuration of 12 GiB memory and 2 vCPUs.
    * kx.s.xlarge – The node type with a configuration of 27 GiB memory and 4 vCPUs.
    * kx.s.2xlarge – The node type with a configuration of 54 GiB memory and 8 vCPUs.
    * kx.s.4xlarge – The node type with a configuration of 108 GiB memory and 16 vCPUs.
    * kx.s.8xlarge – The node type with a configuration of 216 GiB memory and 32 vCPUs.
    * kx.s.16xlarge – The node type with a configuration of 432 GiB memory and 64 vCPUs.
    * kx.s.32xlarge – The node type with a configuration of 864 GiB memory and 128 vCPUs.
* `nodeCount` - (Required) Number of instances running in a cluster. Must be at least 1 and at most 5.

### cache_storage_configuration

The cache_storage_configuration block supports the following arguments:

* `type` - (Required) Type of cache storage . The valid values are:
    * CACHE_1000 - This type provides 1000 MB/s disk access throughput.
    * CACHE_250 - This type provides 250 MB/s disk access throughput.
    * CACHE_12 - This type provides 12 MB/s disk access throughput.
* `size` - (Required) Size of cache in Gigabytes.

### code

The code block supports the following arguments:

* `s3Bucket` - (Required) Unique name for the S3 bucket.
* `s3Key` - (Required) Full S3 path (excluding bucket) to the .zip file that contains the code to be loaded onto the cluster when it’s started.
* `s3ObjectVersion` - (Optional) Version of an S3 Object.

### database

The database block supports the following arguments:

* `databaseName` - (Required) Name of the KX database.
* `cacheConfigurations` - (Optional) Configuration details for the disk cache to increase performance reading from a KX database mounted to the cluster. See [cache_configurations](#cache_configurations).
* `changesetId` - (Optional) A unique identifier of the changeset that is associated with the cluster.

#### cache_configurations

The cache_configuration block supports the following arguments:

* `cacheType` - (Required) Type of disk cache.
* `dbPaths` - (Optional) Paths within the database to cache.

### savedown_storage_configuration

The savedown_storage_configuration block supports the following arguments:

* `type` - (Required) Type of writeable storage space for temporarily storing your savedown data. The valid values are:
    * SDS01 - This type represents 3000 IOPS and io2 ebs volume type.
* `size` - (Required) Size of temporary storage in gigabytes. Must be between 10 and 16000.

### vpc_configuration

The vpc_configuration block supports the following arguments:

* `vpcId` - (Required) Identifier of the VPC endpoint
* `securityGroupIds` - (Required) Unique identifier of the VPC security group applied to the VPC endpoint ENI for the cluster.
* `subnet_ids `- (Required) Identifier of the subnet that the Privatelink VPC endpoint uses to connect to the cluster.
* `ipAddressType` - (Required) IP address type for cluster network configuration parameters. The following type is available: IP_V4 - IP address version 4.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `arn` - Amazon Resource Name (ARN) identifier of the KX cluster.
* `createdTimestamp` - Timestamp at which the cluster is created in FinSpace. Value determined as epoch time in seconds. For example, the value for Monday, November 1, 2021 12:00:00 PM UTC is specified as 1635768000.
* `id` - A comma-delimited string joining environment ID and cluster name.
* `lastModifiedTimestamp` - Last timestamp at which the cluster was updated in FinSpace. Value determined as epoch time in seconds. For example, the value for Monday, November 1, 2021 12:00:00 PM UTC is specified as 1635768000.
* `tagsAll` - Map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](/docs/providers/aws/index.html#default_tags-configuration-block).

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `45m`)
* `update` - (Default `30m`)
* `delete` - (Default `60m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import an AWS FinSpace Kx Cluster using the `id` (environment ID and cluster name, comma-delimited). For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
  }
}

```

Using `terraform import`, import an AWS FinSpace Kx Cluster using the `id` (environment ID and cluster name, comma-delimited). For example:

```console
% terraform import aws_finspace_kx_cluster.example n3ceo7wqxoxcti5tujqwzs,my-tf-kx-cluster
```

<!-- cache-key: cdktf-0.19.0 input-f49ba79f2242b84e16df5a6a714b26006f2a9639ede46db32bec275901e7661a -->