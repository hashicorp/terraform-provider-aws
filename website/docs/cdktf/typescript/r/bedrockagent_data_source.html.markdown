---
subcategory: "Bedrock Agents"
layout: "aws"
page_title: "AWS: aws_bedrockagent_data_source"
description: |-
  Terraform resource for managing an AWS Agents for Amazon Bedrock Data Source.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_bedrockagent_data_source

Terraform resource for managing an AWS Agents for Amazon Bedrock Data Source.

## Example Usage

### Basic Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { BedrockagentDataSource } from "./.gen/providers/aws/bedrockagent-data-source";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new BedrockagentDataSource(this, "example", {
      dataSourceConfiguration: [
        {
          s3Configuration: [
            {
              bucketArn: "arn:aws:s3:::example-bucket",
            },
          ],
          type: "S3",
        },
      ],
      knowledgeBaseId: "EMDPPAYPZI",
      name: "example",
    });
  }
}

```

## Argument Reference

The following arguments are required:

* `dataSourceConfiguration` - (Required) Details about how the data source is stored. See [`dataSourceConfiguration` block](#data_source_configuration-block) for details.
* `knowledgeBaseId` - (Required) Unique identifier of the knowledge base to which the data source belongs.
* `name` - (Required, Forces new resource) Name of the data source.

The following arguments are optional:

* `dataDeletionPolicy` - (Optional) Data deletion policy for a data source. Valid values: `RETAIN`, `DELETE`.
* `description` - (Optional) Description of the data source.
* `serverSideEncryptionConfiguration` - (Optional) Details about the configuration of the server-side encryption. See [`serverSideEncryptionConfiguration` block](#server_side_encryption_configuration-block) for details.
* `vectorIngestionConfiguration` - (Optional, Forces new resource) Details about the configuration of the server-side encryption. See [`vectorIngestionConfiguration` block](#vector_ingestion_configuration-block) for details.

### `dataSourceConfiguration` block

The `dataSourceConfiguration` configuration block supports the following arguments:

* `type` - (Required) Type of storage for the data source. Valid values: `S3`.
* `s3Configuration` - (Optional) Details about the configuration of the S3 object containing the data source. See [`s3_data_source_configuration` block](#s3_data_source_configuration-block) for details.

### `s3_data_source_configuration` block

The `s3_data_source_configuration` configuration block supports the following arguments:

* `bucketArn` - (Required) ARN of the bucket that contains the data source.
* `bucketOwnerAccountId` - (Optional) Bucket account owner ID for the S3 bucket.
* `inclusionPrefixes` - (Optional) List of S3 prefixes that define the object containing the data sources. For more information, see [Organizing objects using prefixes](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-prefixes.html).

### `serverSideEncryptionConfiguration` block

The `serverSideEncryptionConfiguration` configuration block supports the following arguments:

* `kmsKeyArn` - (Optional) ARN of the AWS KMS key used to encrypt the resource.

### `vectorIngestionConfiguration` block

The `vectorIngestionConfiguration` configuration block supports the following arguments:

* `chunkingConfiguration` - (Optional, Forces new resource) Details about how to chunk the documents in the data source. A chunk refers to an excerpt from a data source that is returned when the knowledge base that it belongs to is queried. See [`chunkingConfiguration` block](#chunking_configuration-block) for details.
* `customTransformationConfiguration`- (Optional, Forces new resource) Configuration for custom transformation of data source documents.
* `parsingConfiguration` - (Optional, Forces new resource) Configuration for custom parsing of data source documents. See [`parsingConfiguration` block](#parsing_configuration-block) for details.

### `chunkingConfiguration` block

 The `chunkingConfiguration` configuration block supports the following arguments:

* `chunkingStrategy` - (Required, Forces new resource) Option for chunking your source data, either in fixed-sized chunks or as one chunk. Valid values: `FIXED_SIZE`, `HIERARCHICAL`, `SEMANTIC`, `NONE`.
* `fixedSizeChunkingConfiguration` - (Optional, Forces new resource) Configurations for when you choose fixed-size chunking. Requires chunking_strategy as `FIXED_SIZE`. See [`fixedSizeChunkingConfiguration`](#fixed_size_chunking_configuration-block) for details.
* `hierarchicalChunkingConfiguration` - (Optional, Forces new resource) Configurations for when you choose hierarchical chunking. Requires chunking_strategy as `HIERARCHICAL`. See [`hierarchicalChunkingConfiguration`](#hierarchical_chunking_configuration-block) for details.
* `semanticChunkingConfiguration` - (Optional, Forces new resource) Configurations for when you choose semantic chunking. Requires chunking_strategy as `SEMANTIC`. See [`semanticChunkingConfiguration`](#semantic_chunking_configuration-block) for details.

### `fixedSizeChunkingConfiguration` block

The `fixedSizeChunkingConfiguration` block supports the following arguments:

* `maxTokens` - (Required, Forces new resource) Maximum number of tokens to include in a chunk.
* `overlapPercentage` - (Optional, Forces new resource) Percentage of overlap between adjacent chunks of a data source.

### `hierarchicalChunkingConfiguration` block

The `hierarchicalChunkingConfiguration` block supports the following arguments:

* `levelConfiguration` - (Required, Forces new resource) Maximum number of tokens to include in a chunk. Must contain two `level_configurations`. See [`level_configurations`](#level_configuration-block) for details.
* `overlapTokens` - (Required, Forces new resource) The number of tokens to repeat across chunks in the same layer.

### `levelConfiguration` block

The `levelConfiguration` block supports the following arguments:

* `maxTokens` - (Required) The maximum number of tokens that a chunk can contain in this layer.

### `semanticChunkingConfiguration` block

The `semanticChunkingConfiguration` block supports the following arguments:

* `breakpointPercentileThreshold` - (Required, Forces new resource) The dissimilarity threshold for splitting chunks.
* `bufferSize` - (Required, Forces new resource) The buffer size.
* `maxTokens` - (Required, Forces new resource) The maximum number of tokens a chunk can contain.

### `customTransformationConfiguration` block

The `customTransformationConfiguration` block supports the following arguments:

* `intermediateStorage` - (Required, Forces new resource) The intermediate storage for custom transformation.
* `transformationFunction` - (Required) The configuration of transformation function.

### `intermediateStorage` block

The `intermediateStorage` block supports the following arguments:

* `s3Location` - (Required, Forces new resource) Configuration block for intermedia S3 storage.

### `s3Location` block

The `s3Location` block supports the following arguments:

* `uri` - (Required, Forces new resource) S3 URI for intermediate storage.

### `transformationFunction` block

The `transformationFunction` block supports the following arguments:

* `stepToApply` - (Required, Forces new resource) Currently only `POST_CHUNKING` is supported.
* `transformationLambdaConfiguration` - (Required, Forces new resource) The lambda configuration for custom transformation.

### `transformationLambdaConfiguration` block

The `transformationLambdaConfiguration` block supports the following arguments:

* `lambdaArn` - (Required, Forces new resource) The ARN of the lambda to use for custom transformation.

### `parsingConfiguration` block

The `parsingConfiguration` configuration block supports the following arguments:

* `parsingStrategy` - (Required) Currently only `BEDROCK_FOUNDATION_MODEL` is supported
* `bedrockFoundationModelConfiguration` - (Optional) Settings for a foundation model used to parse documents in a data source. See [`bedrockFoundationModelConfiguration` block](#bedrock_foundation_model_configuration-block) for details.

### `bedrockFoundationModelConfiguration` block

The `bedrockFoundationModelConfiguration` configuration block supports the following arguments:

* `modelArn` - (Required) The ARN of the model used to parse documents
* `parsingPrompt` - (Optional) Instructions for interpreting the contents of the document. See [`parsingPrompt` block](#parsing_prompt-block) for details.

### `parsingPrompt` block

The `parsingPrompt` configuration block supports the following arguments:

* `parsingPromptString` - (Required) Instructions for interpreting the contents of the document.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `dataSourceId` -  Unique identifier of the data source.
* `id` -  Identifier of the data source which consists of the data source ID and the knowledge base ID.

## Timeouts

[Configuration options](https://developer.hashicorp.com/terraform/language/resources/syntax#operation-timeouts):

* `create` - (Default `30m`)
* `delete` - (Default `30m`)

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Agents for Amazon Bedrock Data Source using the data source ID and the knowledge base ID. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { BedrockagentDataSource } from "./.gen/providers/aws/bedrockagent-data-source";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    BedrockagentDataSource.generateConfigForImport(
      this,
      "example",
      "GWCMFMQF6T,EMDPPAYPZI"
    );
  }
}

```

Using `terraform import`, import Agents for Amazon Bedrock Data Source using the data source ID and the knowledge base ID. For example:

```console
% terraform import aws_bedrockagent_data_source.example GWCMFMQF6T,EMDPPAYPZI
```

<!-- cache-key: cdktf-0.20.9 input-a6844c8d1576a70595f0eb27383ed66b24e7350d2c18bdf84a9bc5f9440c3698 -->