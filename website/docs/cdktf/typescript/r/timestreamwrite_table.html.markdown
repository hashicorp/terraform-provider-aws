---
subcategory: "Timestream Write"
layout: "aws"
page_title: "AWS: aws_timestreamwrite_table"
description: |-
  Provides a Timestream table resource.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_timestreamwrite_table

Provides a Timestream table resource.

## Example Usage

### Basic usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { TimestreamwriteTable } from "./.gen/providers/aws/timestreamwrite-table";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new TimestreamwriteTable(this, "example", {
      databaseName: Token.asString(
        awsTimestreamwriteDatabaseExample.databaseName
      ),
      tableName: "example",
    });
  }
}

```

### Full usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { TimestreamwriteTable } from "./.gen/providers/aws/timestreamwrite-table";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new TimestreamwriteTable(this, "example", {
      databaseName: Token.asString(
        awsTimestreamwriteDatabaseExample.databaseName
      ),
      retentionProperties: {
        magneticStoreRetentionPeriodInDays: 30,
        memoryStoreRetentionPeriodInHours: 8,
      },
      tableName: "example",
      tags: {
        Name: "example-timestream-table",
      },
    });
  }
}

```

### Customer-defined Partition Key

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { TimestreamwriteTable } from "./.gen/providers/aws/timestreamwrite-table";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    new TimestreamwriteTable(this, "example", {
      databaseName: Token.asString(
        awsTimestreamwriteDatabaseExample.databaseName
      ),
      schema: {
        compositePartitionKey: {
          enforcementInRecord: "REQUIRED",
          name: "attr1",
          type: "DIMENSION",
        },
      },
      tableName: "example",
    });
  }
}

```

## Argument Reference

This resource supports the following arguments:

* `databaseName` â€“ (Required) The name of the Timestream database.
* `magneticStoreWriteProperties` - (Optional) Contains properties to set on the table when enabling magnetic store writes. See [Magnetic Store Write Properties](#magnetic-store-write-properties) below for more details.
* `retentionProperties` - (Optional) The retention duration for the memory store and magnetic store. See [Retention Properties](#retention-properties) below for more details. If not provided, `magnetic_store_retention_period_in_days` default to 73000 and `memory_store_retention_period_in_hours` defaults to 6.
* `schema` - (Optional) The schema of the table. See [Schema](#schema) below for more details.
* `tableName` - (Required) The name of the Timestream table.
* `tags` - (Optional) Map of tags to assign to this resource. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### Magnetic Store Write Properties

The `magneticStoreWriteProperties` block supports the following arguments:

* `enableMagneticStoreWrites` - (Required) A flag to enable magnetic store writes.
* `magneticStoreRejectedDataLocation` - (Optional) The location to write error reports for records rejected asynchronously during magnetic store writes. See [Magnetic Store Rejected Data Location](#magnetic-store-rejected-data-location) below for more details.

#### Magnetic Store Rejected Data Location

The `magneticStoreRejectedDataLocation` block supports the following arguments:

* `s3Configuration` - (Optional) Configuration of an S3 location to write error reports for records rejected, asynchronously, during magnetic store writes. See [S3 Configuration](#s3-configuration) below for more details.

##### S3 Configuration

The `s3Configuration` block supports the following arguments:

* `bucketName` - (Optional) Bucket name of the customer S3 bucket.
* `encryptionOption` - (Optional) Encryption option for the customer s3 location. Options are S3 server side encryption with an S3-managed key or KMS managed key. Valid values are `SSE_KMS` and `SSE_S3`.
* `kmsKeyId` - (Optional) KMS key arn for the customer s3 location when encrypting with a KMS managed key.
* `objectKeyPrefix` - (Optional) Object key prefix for the customer S3 location.

### Retention Properties

The `retentionProperties` block supports the following arguments:

* `magneticStoreRetentionPeriodInDays` - (Required) The duration for which data must be stored in the magnetic store. Minimum value of 1. Maximum value of 73000.
* `memoryStoreRetentionPeriodInHours` - (Required) The duration for which data must be stored in the memory store. Minimum value of 1. Maximum value of 8766.

### Schema

The `schema` block supports the following arguments:

* `compositePartitionKey` - (Required) A non-empty list of partition keys defining the attributes used to partition the table data. The order of the list determines the partition hierarchy. The name and type of each partition key as well as the partition key order cannot be changed after the table is created. However, the enforcement level of each partition key can be changed. See [Composite Partition Key](#composite-partition-key) below for more details.

### Composite Partition Key

The `compositePartitionKey` block supports the following arguments:

* `enforcementInRecord` - (Optional) The level of enforcement for the specification of a dimension key in ingested records. Valid values: `REQUIRED`, `OPTIONAL`.
* `name` - (Optional) The name of the attribute used for a dimension key.
* `type` - (Required) The type of the partition key. Valid values: `DIMENSION`, `MEASURE`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - The `table_name` and `database_name` separated by a colon (`:`).
* `arn` - The ARN that uniquely identifies this table.
* `tagsAll` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Timestream tables using the `tableName` and `databaseName` separate by a colon (`:`). For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
  }
}

```

Using `terraform import`, import Timestream tables using the `tableName` and `databaseName` separate by a colon (`:`). For example:

```console
% terraform import aws_timestreamwrite_table.example ExampleTable:ExampleDatabase
```

<!-- cache-key: cdktf-0.19.0 input-f3b0a12c378c166ac42527e7ddfa6ae43b71b326a2b2a3f2abcf892be6820171 -->