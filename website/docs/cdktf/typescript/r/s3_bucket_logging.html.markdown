---
subcategory: "S3 (Simple Storage)"
layout: "aws"
page_title: "AWS: aws_s3_bucket_logging"
description: |-
  Provides an S3 bucket (server access) logging resource.
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_s3_bucket_logging

Provides an S3 bucket (server access) logging resource. For more information, see [Logging requests using server access logging](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ServerLogs.html)
in the AWS S3 User Guide.

~> **Note:** Amazon S3 supports server access logging, AWS CloudTrail, or a combination of both. Refer to the [Logging options for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/logging-with-S3.html)
to decide which method meets your requirements.

-> This resource cannot be used with S3 directory buckets.

## Example Usage

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { S3Bucket } from "./.gen/providers/aws/s3-bucket";
import { S3BucketAcl } from "./.gen/providers/aws/s3-bucket-acl";
import { S3BucketLoggingA } from "./.gen/providers/aws/s3-bucket-logging";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new S3Bucket(this, "example", {
      bucket: "my-tf-example-bucket",
    });
    const logBucket = new S3Bucket(this, "log_bucket", {
      bucket: "my-tf-log-bucket",
    });
    const awsS3BucketAclExample = new S3BucketAcl(this, "example_2", {
      acl: "private",
      bucket: example.id,
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsS3BucketAclExample.overrideLogicalId("example");
    new S3BucketAcl(this, "log_bucket_acl", {
      acl: "log-delivery-write",
      bucket: logBucket.id,
    });
    const awsS3BucketLoggingExample = new S3BucketLoggingA(this, "example_4", {
      bucket: example.id,
      targetBucket: logBucket.id,
      targetPrefix: "log/",
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsS3BucketLoggingExample.overrideLogicalId("example");
  }
}

```

## Argument Reference

This resource supports the following arguments:

* `bucket` - (Required, Forces new resource) Name of the bucket.
* `expectedBucketOwner` - (Optional, Forces new resource) Account ID of the expected bucket owner.
* `targetBucket` - (Required) Name of the bucket where you want Amazon S3 to store server access logs.
* `targetPrefix` - (Required) Prefix for all log object keys.
* `targetGrant` - (Optional) Set of configuration blocks with information for granting permissions. [See below](#target_grant).
* `targetObjectKeyFormat` - (Optional) Amazon S3 key format for log objects. [See below](#target_object_key_format).

### target_grant

The `targetGrant` configuration block supports the following arguments:

* `grantee` - (Required) Configuration block for the person being granted permissions. [See below](#grantee).
* `permission` - (Required) Logging permissions assigned to the grantee for the bucket. Valid values: `FULL_CONTROL`, `READ`, `WRITE`.

### grantee

The `grantee` configuration block supports the following arguments:

* `emailAddress` - (Optional) Email address of the grantee. See [Regions and Endpoints](https://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region) for supported AWS regions where this argument can be specified.
* `id` - (Optional) Canonical user ID of the grantee.
* `type` - (Required) Type of grantee. Valid values: `CanonicalUser`, `AmazonCustomerByEmail`, `Group`.
* `uri` - (Optional) URI of the grantee group.

### target_object_key_format

The `targetObjectKeyFormat` configuration block supports the following arguments:

* `partitionedPrefix` - (Optional) Partitioned S3 key for log objects. [See below](#partitioned_prefix).
* `simplePrefix` - (Optional) Use the simple format for S3 keys for log objects. To use, set `simple_prefix {}`.

### partitioned_prefix

The `partitionedPrefix` configuration block supports the following arguments:

* `partitionDateSource` - (Required) Specifies the partition date source for the partitioned prefix. Valid values: `EventTime`, `DeliveryTime`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - The `bucket` or `bucket` and `expectedBucketOwner` separated by a comma (`,`) if the latter is provided.

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import S3 bucket logging using the `bucket` or using the `bucket` and `expectedBucketOwner` separated by a comma (`,`). For example:

If the owner (account ID) of the source bucket is the same account used to configure the Terraform AWS Provider, import using the `bucket`:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { S3BucketLoggingA } from "./.gen/providers/aws/s3-bucket-logging";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    S3BucketLoggingA.generateConfigForImport(this, "example", "bucket-name");
  }
}

```

If the owner (account ID) of the source bucket differs from the account used to configure the Terraform AWS Provider, import using the `bucket` and `expectedBucketOwner` separated by a comma (`,`):

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { S3BucketLoggingA } from "./.gen/providers/aws/s3-bucket-logging";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    S3BucketLoggingA.generateConfigForImport(
      this,
      "example",
      "bucket-name,123456789012"
    );
  }
}

```

**Using `terraform import` to import** S3 bucket logging using the `bucket` or using the `bucket` and `expectedBucketOwner` separated by a comma (`,`). For example:

If the owner (account ID) of the source bucket is the same account used to configure the Terraform AWS Provider, import using the `bucket`:

```console
% terraform import aws_s3_bucket_logging.example bucket-name
```

If the owner (account ID) of the source bucket differs from the account used to configure the Terraform AWS Provider, import using the `bucket` and `expectedBucketOwner` separated by a comma (`,`):

```console
% terraform import aws_s3_bucket_logging.example bucket-name,123456789012
```

<!-- cache-key: cdktf-0.20.1 input-84005dc097b2a2ceb5d4b3077a825a1234cf23a38227e29e509ee3ce8851df2f -->