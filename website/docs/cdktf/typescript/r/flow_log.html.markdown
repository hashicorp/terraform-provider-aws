---
subcategory: "VPC (Virtual Private Cloud)"
layout: "aws"
page_title: "AWS: aws_flow_log"
description: |-
  Provides a VPC/Subnet/ENI Flow Log
---


<!-- Please do not edit this file, it is generated. -->
# Resource: aws_flow_log

Provides a VPC/Subnet/ENI/Transit Gateway/Transit Gateway Attachment Flow Log to capture IP traffic for a specific network
interface, subnet, or VPC. Logs are sent to a CloudWatch Log Group, a S3 Bucket, or Amazon Kinesis Data Firehose

## Example Usage

### CloudWatch Logging

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { CloudwatchLogGroup } from "./.gen/providers/aws/cloudwatch-log-group";
import { DataAwsIamPolicyDocument } from "./.gen/providers/aws/data-aws-iam-policy-document";
import { FlowLog } from "./.gen/providers/aws/flow-log";
import { IamRole } from "./.gen/providers/aws/iam-role";
import { IamRolePolicy } from "./.gen/providers/aws/iam-role-policy";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new CloudwatchLogGroup(this, "example", {
      name: "example",
    });
    const assumeRole = new DataAwsIamPolicyDocument(this, "assume_role", {
      statement: [
        {
          actions: ["sts:AssumeRole"],
          effect: "Allow",
          principals: [
            {
              identifiers: ["vpc-flow-logs.amazonaws.com"],
              type: "Service",
            },
          ],
        },
      ],
    });
    const dataAwsIamPolicyDocumentExample = new DataAwsIamPolicyDocument(
      this,
      "example_2",
      {
        statement: [
          {
            actions: [
              "logs:CreateLogGroup",
              "logs:CreateLogStream",
              "logs:PutLogEvents",
              "logs:DescribeLogGroups",
              "logs:DescribeLogStreams",
            ],
            effect: "Allow",
            resources: ["*"],
          },
        ],
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsIamPolicyDocumentExample.overrideLogicalId("example");
    const awsIamRoleExample = new IamRole(this, "example_3", {
      assumeRolePolicy: Token.asString(assumeRole.json),
      name: "example",
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsIamRoleExample.overrideLogicalId("example");
    const awsIamRolePolicyExample = new IamRolePolicy(this, "example_4", {
      name: "example",
      policy: Token.asString(dataAwsIamPolicyDocumentExample.json),
      role: Token.asString(awsIamRoleExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsIamRolePolicyExample.overrideLogicalId("example");
    const awsFlowLogExample = new FlowLog(this, "example_5", {
      iamRoleArn: Token.asString(awsIamRoleExample.arn),
      logDestination: example.arn,
      trafficType: "ALL",
      vpcId: Token.asString(awsVpcExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsFlowLogExample.overrideLogicalId("example");
  }
}

```

### Amazon Kinesis Data Firehose logging

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { DataAwsIamPolicyDocument } from "./.gen/providers/aws/data-aws-iam-policy-document";
import { FlowLog } from "./.gen/providers/aws/flow-log";
import { IamRole } from "./.gen/providers/aws/iam-role";
import { IamRolePolicy } from "./.gen/providers/aws/iam-role-policy";
import { KinesisFirehoseDeliveryStream } from "./.gen/providers/aws/kinesis-firehose-delivery-stream";
import { S3Bucket } from "./.gen/providers/aws/s3-bucket";
import { S3BucketAcl } from "./.gen/providers/aws/s3-bucket-acl";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new S3Bucket(this, "example", {
      bucket: "example",
    });
    const awsS3BucketAclExample = new S3BucketAcl(this, "example_1", {
      acl: "private",
      bucket: example.id,
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsS3BucketAclExample.overrideLogicalId("example");
    const assumeRole = new DataAwsIamPolicyDocument(this, "assume_role", {
      statement: [
        {
          actions: ["sts:AssumeRole"],
          effect: "Allow",
          principals: [
            {
              identifiers: ["firehose.amazonaws.com"],
              type: "Service",
            },
          ],
        },
      ],
    });
    const dataAwsIamPolicyDocumentExample = new DataAwsIamPolicyDocument(
      this,
      "example_3",
      {
        actions: [
          "logs:CreateLogDelivery",
          "logs:DeleteLogDelivery",
          "logs:ListLogDeliveries",
          "logs:GetLogDelivery",
          "firehose:TagDeliveryStream",
        ],
        effect: "Allow",
        resources: ["*"],
      }
    );
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    dataAwsIamPolicyDocumentExample.overrideLogicalId("example");
    const awsIamRoleExample = new IamRole(this, "example_4", {
      assumeRolePolicy: Token.asString(assumeRole.json),
      name: "firehose_test_role",
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsIamRoleExample.overrideLogicalId("example");
    const awsIamRolePolicyExample = new IamRolePolicy(this, "example_5", {
      name: "test",
      policy: Token.asString(dataAwsIamPolicyDocumentExample.json),
      role: Token.asString(awsIamRoleExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsIamRolePolicyExample.overrideLogicalId("example");
    const awsKinesisFirehoseDeliveryStreamExample =
      new KinesisFirehoseDeliveryStream(this, "example_6", {
        destination: "extended_s3",
        extendedS3Configuration: {
          bucketArn: example.arn,
          roleArn: Token.asString(awsIamRoleExample.arn),
        },
        name: "kinesis_firehose_test",
        tags: {
          LogDeliveryEnabled: "true",
        },
      });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsKinesisFirehoseDeliveryStreamExample.overrideLogicalId("example");
    const awsFlowLogExample = new FlowLog(this, "example_7", {
      logDestination: Token.asString(
        awsKinesisFirehoseDeliveryStreamExample.arn
      ),
      logDestinationType: "kinesis-data-firehose",
      trafficType: "ALL",
      vpcId: Token.asString(awsVpcExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsFlowLogExample.overrideLogicalId("example");
  }
}

```

### S3 Logging

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { FlowLog } from "./.gen/providers/aws/flow-log";
import { S3Bucket } from "./.gen/providers/aws/s3-bucket";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new S3Bucket(this, "example", {
      bucket: "example",
    });
    const awsFlowLogExample = new FlowLog(this, "example_1", {
      logDestination: example.arn,
      logDestinationType: "s3",
      trafficType: "ALL",
      vpcId: Token.asString(awsVpcExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsFlowLogExample.overrideLogicalId("example");
  }
}

```

### S3 Logging in Apache Parquet format with per-hour partitions

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { Token, TerraformStack } from "cdktf";
/*
 * Provider bindings are generated by running `cdktf get`.
 * See https://cdk.tf/provider-generation for more details.
 */
import { FlowLog } from "./.gen/providers/aws/flow-log";
import { S3Bucket } from "./.gen/providers/aws/s3-bucket";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
    const example = new S3Bucket(this, "example", {
      bucket: "example",
    });
    const awsFlowLogExample = new FlowLog(this, "example_1", {
      destinationOptions: {
        fileFormat: "parquet",
        perHourPartition: true,
      },
      logDestination: example.arn,
      logDestinationType: "s3",
      trafficType: "ALL",
      vpcId: Token.asString(awsVpcExample.id),
    });
    /*This allows the Terraform resource name to match the original name. You can remove the call if you don't need them to match.*/
    awsFlowLogExample.overrideLogicalId("example");
  }
}

```

## Argument Reference

~> **NOTE:** One of `eniId`, `subnetId`, `transitGatewayId`, `transitGatewayAttachmentId`, or `vpcId` must be specified.

This argument supports the following arguments:

* `trafficType` - (Required) The type of traffic to capture. Valid values: `ACCEPT`,`REJECT`, `ALL`.
* `deliverCrossAccountRole` - (Optional) ARN of the IAM role that allows Amazon EC2 to publish flow logs across accounts.
* `eniId` - (Optional) Elastic Network Interface ID to attach to
* `iamRoleArn` - (Optional) The ARN for the IAM role that's used to post flow logs to a CloudWatch Logs log group
* `logDestinationType` - (Optional) The type of the logging destination. Valid values: `cloud-watch-logs`, `s3`, `kinesis-data-firehose`. Default: `cloud-watch-logs`.
* `logDestination` - (Optional) The ARN of the logging destination. Either `log_destination` or `log_group_name` must be set.
* `logGroupName` - (Optional) **Deprecated:** Use `log_destination` instead. The name of the CloudWatch log group. Either `log_group_name` or `log_destination` must be set.
* `subnetId` - (Optional) Subnet ID to attach to
* `transitGatewayId` - (Optional) Transit Gateway ID to attach to
* `transitGatewayAttachmentId` - (Optional) Transit Gateway Attachment ID to attach to
* `vpcId` - (Optional) VPC ID to attach to
* `logFormat` - (Optional) The fields to include in the flow log record, in the order in which they should appear.
* `maxAggregationInterval` - (Optional) The maximum interval of time
  during which a flow of packets is captured and aggregated into a flow
  log record. Valid Values: `60` seconds (1 minute) or `600` seconds (10
  minutes). Default: `600`. When `transit_gateway_id` or `transit_gateway_attachment_id` is specified, `max_aggregation_interval` *must* be 60 seconds (1 minute).
* `destinationOptions` - (Optional) Describes the destination options for a flow log. More details below.
* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.

### destination_options

Describes the destination options for a flow log.

* `fileFormat` - (Optional) The format for the flow log. Default value: `plain-text`. Valid values: `plain-text`, `parquet`.
* `hiveCompatiblePartitions` - (Optional) Indicates whether to use Hive-compatible prefixes for flow logs stored in Amazon S3. Default value: `false`.
* `perHourPartition` - (Optional) Indicates whether to partition the flow log per hour. This reduces the cost and response time for queries. Default value: `false`.

## Attribute Reference

This resource exports the following attributes in addition to the arguments above:

* `id` - The Flow Log ID
* `arn` - The ARN of the Flow Log.
* `tagsAll` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

In Terraform v1.5.0 and later, use an [`import` block](https://developer.hashicorp.com/terraform/language/import) to import Flow Logs using the `id`. For example:

```typescript
// DO NOT EDIT. Code generated by 'cdktf convert' - Please report bugs at https://cdk.tf/bug
import { Construct } from "constructs";
import { TerraformStack } from "cdktf";
class MyConvertedCode extends TerraformStack {
  constructor(scope: Construct, name: string) {
    super(scope, name);
  }
}

```

Using `terraform import`, import Flow Logs using the `id`. For example:

```console
% terraform import aws_flow_log.test_flow_log fl-1a2b3c4d
```

<!-- cache-key: cdktf-0.19.0 input-379eebee0faf6ddc6b72192ea7791d99a401f706aaa6660a39aa2f4709546656 -->